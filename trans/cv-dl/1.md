# 1.计算机视觉和深度学习简介

> *远见是上帝给人类最好的礼物。*

从我们出生开始，视觉就允许我们发展有意识的思维。颜色、形状、物体和面孔都是我们世界的组成部分。这种自然的礼物对我们的感官来说非常重要。

计算机视觉是允许机器复制这种能力的能力之一。利用深度学习，我们正在增强我们的指挥能力，并在这一领域取得进展。

这本书将从深度学习的角度审视计算机视觉的概念。我们将研究神经网络的基本构件，通过基于案例研究的方法开发实用的用例，并比较和对比各种解决方案的性能。我们将讨论最佳实践，分享行业中遵循的技巧和见解，让您了解常见的陷阱，并开发设计神经网络的思维过程。

在整本书中，我们引入了一个概念，详细探讨了它，然后围绕它开发了一个 Python 用例。由于一章首先建立深度学习的基础，然后是它的实用用法，完整的知识使你能够设计一个解决方案，然后开发神经网络，以更好地做出决策。

为了更好地理解，需要一些 Python 和面向对象编程概念的知识。对数据科学有基本到中级的理解是可取的，尽管不是必要的要求。

在这一介绍性章节中，我们将使用 OpenCV 和深度学习来开发图像处理的概念。OpenCV 是一个很棒的库，广泛应用于机器人、人脸识别、手势识别、增强现实等等。此外，深度学习为开发图像处理用例提供了更高的复杂性和灵活性。我们将在本章中讨论以下主题:

1.  使用 OpenCV 进行图像处理

2.  深度学习的基础

3.  深度学习是如何工作的

4.  流行的深度学习库

## 1.1 技术要求

整本书我们都在用 Python 开发所有的解决方案；因此，需要安装最新版本的 Python。

所有的代码、数据集和各自的结果都被检查到位于 [https:// github 的代码库中。com/a press/computer-vision-using-deep-learning/tree/main/chapter 1](https://github.com/Apress/computer-vision-using-deep-learning/tree/main/Chapter1)。建议您与我们一起运行所有代码并复制结果。这将加强你对概念的理解。

## 1.2 使用 OpenCV 进行图像处理

图像也像任何其他数据点一样。在我们的电脑和手机上，它作为一个对象或图标出现在。jpeg，。bmp 还有。png 格式。因此，对于人类来说，以行列结构来可视化它变得很困难，就像我们可视化任何其他数据库一样。因此，它通常被称为*非结构化数据*。

为了让我们的计算机和算法分析图像并对其进行处理，我们必须以整数的形式表示图像。因此，我们一个像素一个像素地处理图像。数学上，表示每个像素的方法之一是 RGB(红、绿、蓝)值。我们使用这些信息来进行图像处理。

Info

获取任何颜色的 RGB 最简单的方法是在 Windows 操作系统中用画图打开它。将鼠标悬停在任何颜色上，获取相应的 RGB 值。在 Mac OS 中，您可以使用数码色度计。

深度学习允许我们开发使用传统图像处理技术解决的更加复杂的用例。例如，使用 OpenCV 也可以检测人脸，但要能够识别人脸需要深度学习。

在使用深度学习开发计算机视觉解决方案的过程中，我们首先准备我们的图像数据集。在准备过程中，我们可能需要对图像进行灰度处理，检测轮廓，裁剪图像，然后将它们输入神经网络。

OpenCV 是这类任务最著名的库。作为第一步，让我们开发这些图像处理方法的一些构件。我们将使用 OpenCV 创建三个解决方案。

Note

转到 [`www.opencv.org`](http://www.opencv.org) 并按照那里的说明在你的系统上安装 OpenCV。

用于解决方案的图像是常见的图像。建议您检查代码，并遵循完成的一步一步实现。我们将检测图像中的形状、颜色和人脸。

让我们一起进入令人兴奋的图像世界吧！

### 1.2.1 使用 OpenCV 进行颜色检测

当我们想到一幅图像时，它是由形状、大小和颜色组成的。具有检测图像中的形状、大小或颜色的能力可以使许多过程自动化并节省大量工作。在第一个例子中，我们将开发一个“颜色检测系统”

颜色检测在制造、汽车、电力、公用事业等领域和行业中具有广泛的用途。颜色检测可用于寻找正常行为的中断、失败和中断。我们可以训练传感器根据颜色做出特定的决定，并在需要时发出警报。

图像用像素表示，每个像素由 0 到 255 范围内的 RGB 值组成。我们将使用这个属性来识别图像中的蓝色(图 [1-1](#Fig1) )。您可以更改蓝色的相应值，并检测任何选择的颜色。

请遵循以下步骤:

1.  打开 Python Jupyter 笔记本。

2.  首先加载必要的库，`numpy`和`OpenCV`。

    ```
    import numpy as np
    import cv2

    ```

3.  加载图像文件。

    ```
    image = cv2.imread('Color.png')

    ```

    ![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig1_HTML.png](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig1_HTML.png)

    图 1-1

    用于颜色检测的原始图像。显示的图像有四种不同的颜色，OpenCV 解决方案将分别检测它们

4.  现在让我们将原始图像转换成 HSV(色调饱和度值)格式。它使我们能够从饱和和伪照明中分离出来。允许我们这样做。

    ```
    hsv_convert = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

    ```

5.  在此定义颜色的上限和下限。我们正在检测蓝色。从`numpy`库中，我们给出了蓝色各自的范围。

    ```
    lower_range = np.array([110,50,50]) upper_range = np.array([130,255,255])

    ```

6.  现在，让我们检测蓝色，并将其从图像的其余部分分离出来。

    ```
    mask_toput = cv2.inRange(hsv_convert, lower_range, upper_range) cv2.imshow('image', image) cv2.imshow('mask', mask_toput)
    while(True):
    k = cv2.waitKey(5)& 0xFF if k== 27: break

    ```

该代码的输出将如图 [1-2](#Fig2) 所示。

![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig2_HTML.jpg](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig2_HTML.jpg)

图 1-2

颜色检测系统的输出。我们想要检测蓝色，蓝色被检测并与图像的其余部分分离

可以看到，蓝色以白色突出显示，而图像的其余部分为黑色。通过在步骤 5 中更改范围，您可以检测自己选择的不同颜色。

完成颜色后，是时候检测图像中的形状了；我们开始吧！

## 1.3 使用 OpenCV 的形状检测

就像我们在上一节中检测蓝色一样，我们将检测图像中的三角形、正方形、矩形和圆形。形状检测允许您分离图像中的部分并检查图案。颜色和形状检测使解决方案变得非常具体。可用性存在于安全监控、生产线、汽车中心等等。

对于形状检测，我们得到每个形状的轮廓，检查元素的数量，然后进行相应的分类。例如，如果这个数字是三，它就是一个三角形。在本解决方案中，您还将观察如何对图像进行灰度处理并检测轮廓。

按照以下步骤检测形状:

1.  首先导入库。

    ```
    import numpy as np
    import cv2

    ```

2.  加载如图 [1-3](#Fig3) 所示的原始图像。

    ```
    shape_image = cv2.imread('shape.png')

    ```

    ![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig3_HTML.png](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig3_HTML.png)

    图 1-3

    用于检测圆形、三角形和矩形三种形状的原始输入图像

3.  接下来将图像转换为灰度。因为 RGB 是三维的，而灰度是二维的，所以进行灰度缩放是为了简单，并且转换为灰度简化了解决方案。这也使得代码高效。

    ```
    gray_image = cv2.cvtColor(shape_image, cv2.COLOR_BGR2GRAY) ret,thresh = cv2.threshold(gray_image,127,255,1)

    ```

4.  找到图像中的轮廓。

1.  使用`approxPolyDP`尝试逼近每个轮廓。此方法返回检测到的轮廓中的元素数量。然后，我们根据轮廓中元素的数量来决定形状。如果值为三，则为三角形；如果它是四，它是正方形；诸如此类。

    ```
    for cnt in contours:
        approx =
        cv2.approxPolyDP(cnt,0.01*cv2.arcLength(cnt,True),True)
    print (len(approx))
    if len(approx)==3:
        print ("triangle")
        cv2.drawContours(shape_image,[cnt],0,(0,255,0),-1)
    elif len(approx)==4:
        print ("square")
        cv2.drawContours(shape_image,[cnt],0,(0,0,255),-1)
    elif len(approx) > 15:
        print ("circle")
        cv2.drawContours(shape_image,[cnt],0,(0,255,255),-1)
    cv2.imshow('shape_image',shape_image)   cv2.waitKey(0)
    cv2.destroyAllWindows()

    ```

2.  The output of the preceding code is shown in Figure [1-4](#Fig4).

    ![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig4_HTML.jpg](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig4_HTML.jpg)

    图 1-4

    颜色检测系统的输出。圆形以黄色显示，正方形以红色显示，三角形以绿色显示

```
contours,h = cv2.findContours(thresh,1,2)

```

现在，您可以检测任何图像中的形状。我们已经检测到一个圆形、一个三角形和一个正方形。一个很好的挑战将是检测五边形或六边形；你愿意吗？

现在让我们做一些更有趣的事情吧！

### 1.3.1 使用 OpenCV 的人脸检测

人脸检测并不是一项新功能。每当我们看一张照片时，我们都能很容易地认出一张脸。我们的手机摄像头会在一张脸周围画出方框。或者在社交媒体上，围绕一张脸创建一个方形框。叫做*人脸检测*。

人脸检测是指在数字图像中定位人脸。人脸检测不同于人脸识别。在前一种情况下，我们只检测图像中的人脸，而在后一种情况下，我们也给人脸起名字，也就是说，照片中的人是谁。

大多数现代相机和手机都有检测人脸的内置功能。使用 OpenCV 可以开发类似的解决方案。它更容易理解和实现，并且是使用`Haar-cascade`算法构建的。在 Python 中使用这种算法时，我们将突出照片中的人脸和眼睛。

`Haar-cascade classifier`用于检测图像中的人脸和其他面部属性，如眼睛。这是一种机器学习解决方案，其中对大量图像进行训练，这些图像中有人脸和没有人脸。分类器学习各自的特征。然后我们使用相同的分类器为我们检测人脸。我们不需要在这里做任何训练，因为分类器已经训练好了，可以使用了。也省时省力！

Info

使用基于 Haar 的级联分类器的对象检测是由 Paul Viola 和 Michael Jones 在 2001 年他们的论文“使用简单特征的增强级联的快速对象检测”中提出的。建议您浏览这篇开创性的论文。

按照以下步骤检测人脸:

1.  首先导入库。

    ```
    import numpy as np
    import cv2

    ```

2.  加载分类器 xml 文件。的。xml 文件由 OpenCV 设计，由叠加在正面图像上的负面人脸的训练级联生成，因此可以检测人脸特征。

    ```
    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
    eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')

    ```

3.  接下来，加载图像(图 [1-5](#Fig5) )。

    ```
    img = cv2.imread('Vaibhav.jpg')

    ```

    ![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig5_HTML.jpg](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig5_HTML.jpg)

    图 1-5

    使用 Haar-cascade 解决方案进行人脸检测时使用的人脸原始输入图像

4.  将图像转换为灰度。

1.  执行以下代码来检测图像中的人脸。如果找到任何人脸，我们将检测到的人脸的位置作为 Rect(x，y，w，h)返回。随后，在脸部检测眼睛。

    ```
    faces = face_cascade.detectMultiScale(gray, 1.3, 5) for (x,y,w,h) in faces:
    image = cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2) roi_gr = gray[y:y+h, x:x+w] roi_clr = img[y:y+h, x:x+w]
    the_eyes = eye_cascade.detectMultiScale(roi_gr)
    for (ex,ey,ew,eh) in the_eyes:    cv2.rectangle(roi_clr,(ex,ey),(ex+ew,ey+eh),(0,255,0),2) cv2.imshow('img',image) cv2.waitKey(0) cv2.destroyAllWindows()

    ```

2.  The output is shown in Figure [1-6](#Fig6). Have a look how a blue box is drawn around the face and two green small boxes are around the eyes.

    ![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig6_HTML.jpg](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig6_HTML.jpg)

    图 1-6

    在图像中检测到的脸部和眼睛；眼睛周围有一个绿色方框，面部周围有一个蓝色方框

```
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

```

人脸检测允许我们在图像和视频中找到人脸。这是人脸识别的第一步。它广泛用于安全应用、考勤监控等。我们将在后续章节中使用深度学习开发人脸检测和识别。

我们已经学习了图像处理的一些概念。是时候检查和学习深度学习的概念了。这些是你踏上旅程的基石。

## 1.4 深度学习的基础

深度学习是机器学习的一个子领域。深度学习中的“深度”是具有连续的表现层；因此，模型的深度指的是人工神经网络(ANN)模型中的层数，本质上称为深度学习。

这是一种新颖的方法来分析历史数据，并从不断增加的有意义的表示的连续层中学习。深度学习项目中的典型过程类似于机器学习项目，如下所述，如图 [1-7](#Fig7) 所示。

![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig7_HTML.jpg](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig7_HTML.jpg)

图 1-7

从数据发现到最终开发解决方案的端到端机器学习过程。这里详细讨论了所有步骤，并在本书的第 [8](8.html) 章再次讨论

1.  数据接收:原始数据文件/图像/文本等被接收到系统中。它们用作训练和测试网络的输入数据。

2.  数据清理:在这一步，我们清理数据。通常，结构化数据集中存在太多噪音，如垃圾值、重复值、空值和离群值。所有这些数据点都必须在这个阶段进行处理。对于图像，我们可能需要去除图像中不必要的噪声。

3.  数据准备:我们为训练准备好数据。在这一步中，可能需要新的派生变量，或者如果我们正在处理图像数据集，我们可能需要旋转/裁剪图像。

4.  探索性数据分析:我们执行初步分析，以快速了解我们的数据集。

5.  网络设计和训练模型:我们在这里设计我们的神经网络，并决定隐藏层、节点、激活函数、损失函数等的数量。然后训练网络。

6.  检查准确性和迭代:我们测量网络的准确性。我们用混淆矩阵、AUC 值、精确度、召回率等等来衡量。然后我们调整超参数并进一步调整。

7.  最终的模型呈现给企业，我们得到反馈。

8.  我们迭代该模型，并根据收到的反馈对其进行改进，并创建最终解决方案。

9.  该模型被部署到生产中。然后定期对其进行维护和刷新。

在机器学习项目中，通常会遵循这些步骤。我们将在本书的最后一章中详细研究所有这些步骤。现在是了解神经网络的好时机。

### 1.4.1 神经网络背后的动机

人工神经网络(ann)据说是受人脑工作方式的启发。当我们看到一幅图片时，我们会把它和一个标签联系起来。我们训练我们的大脑和感官，当我们再次看到一张图片时，能够识别它，并正确地给它贴上标签。

ANN 通过学习或接受培训来学习执行类似的任务。这是通过查看各种历史数据点(如交易数据或图像)的示例来完成的，并且大多数情况下没有针对特定规则进行编程。例如，为了区分一辆汽车和一个人，一个人工神经网络在开始时对每一类的属性没有预先的理解和知识。然后，它从训练数据中生成属性和识别特征。然后，它学习这些属性，并在以后使用它们进行预测。

正式地说，人工神经网络环境中的“学习”是指调整网络内部的权重和偏差，以提高网络的后续准确性。一个显而易见的方法是减少误差项，它只不过是实际值和预测值之间的差异。为了测量错误率，我们定义了一个成本函数，在网络的学习阶段对其进行严格评估。我们将在下一节详细研究所有这些术语。

典型的神经网络如图 [1-8](#Fig8) 所示。

![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig8_HTML.png](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig8_HTML.png)

图 1-8

具有输入层、隐藏层和输出层的典型神经网络。每一层里面都有一些神经元。隐藏层充当网络的心脏和灵魂。输入层接受输入数据，输出层负责生成最终结果

前面显示的神经网络有三个输入单元、两个各有四个神经元的隐藏层和一个最终输出层。

现在让我们在随后的章节中讨论神经网络的各种组件。

### 1.4.2 神经网络中的层

基本的神经网络架构主要由三层组成:

*   输入层:顾名思义，它接收输入数据。考虑将原始图像/处理过的图像输入到输入层。这是神经网络的第一步。

*   隐藏层:它们是网络的核心和灵魂。所有的处理、特征提取、学习和训练都在这些层中完成。隐藏层将原始数据分解为属性和要素，并了解数据的细微差别。这种学习稍后在输出层中用于做出决定。

*   输出层:网络中的决策层和最终部分。它接受来自前面隐藏层的输出，然后对最终分类做出判断。

网络中最精细的构件是神经元。神经元是整个魔法发生的地方，这是我们接下来要讨论的。

### 1.4.3 神经元

神经元或人工神经元是神经网络的基础。整个复杂的计算只发生在一个神经元中。网络中的一层可以包含一个以上的神经元。

神经元接收来自先前层或输入层的输入，然后处理信息并共享输出。输入数据可以是来自前一个神经元的原始数据或经过处理的信息。然后，神经元将输入与它们自己的内部状态相结合，并使用激活函数达到一个值(我们稍后将讨论激活函数)。随后，使用 output 函数生成输出。

一个神经元可以被认为是图 [1-9](#Fig9) ，它接收各自的输入并计算输出。

![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig9_HTML.png](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig9_HTML.png)

图 1-9

一种神经元的表示，它接收来自前几层的输入，并使用激活函数来处理和给出输出。它是神经网络的组成部分

神经元的输入是从其前身的输出和它们各自的连接中接收的。接收到的输入被计算为加权和，并且通常还添加了偏差项。这是一个*传播函数*的功能。如图 [1-9](#Fig9) 所示，f 为激活函数，w 为权重项，b 为偏差项。计算完成后，我们接收输出。

例如，输入训练数据将具有原始图像或经处理的图像。这些图像将被输入到输入层。数据现在传输到隐藏层，在那里进行所有的计算。这些计算是由每一层的神经元完成的。

输出是需要完成的任务，例如，识别一个对象或者如果我们想要分类一个图像等等。

正如我们所讨论的，在很大程度上，神经网络能够自己提取信息，但我们仍然必须为训练网络的过程初始化一些参数。它们被称为*超参数*，我们接下来将对其进行讨论。

### 超参数

在训练网络期间，算法不断学习原始数据的属性。但是有一些参数是网络不能自己学习的，需要初始设置。超参数是人工神经网络不能自己学习的那些变量和属性。这些是决定神经网络结构的变量，以及对训练网络有用的各个变量。

超参数是在网络的实际训练之前设置的。学习速率、网络中隐藏层的数量、每层中神经元的数量、激活函数、时期的数量、批量大小、丢失和网络权重初始化都是超参数的例子。

调整超参数是基于其性能为超参数选择最佳值的过程。我们在验证集上测量网络的性能，然后调整超参数，然后重新评估和重新弱化，这个过程继续进行。我们将在下一节研究各种超参数。

### 1.4.5 安的连接和重量

人工神经网络由各种连接组成。每个连接都旨在接收输入并提供计算的输出。这个输出作为下一个神经元的输入。

此外，每个连接被分配一个代表其各自重要性的权重。值得注意的是，一个神经元可以有多个输入和输出连接，这意味着它可以接收输入和传递多个信号。

下一项也是一个重要的组成部分——偏差项。

### 偏置项

偏差就像给线性方程加上一个截距值。它是网络中额外的或附加的参数。

理解偏差的最简单方法是根据下面的等式:

y = mx + c

如果我们没有常数项 c，方程将通过(0，0)。如果我们有常数项 c，我们可以期待一个更好的拟合机器学习模型。

正如我们在图 [1-10](#Fig10) 中看到的，在左边，我们有一个没有偏置项的神经元，而在右边，我们增加了一个偏置项。因此，偏置允许我们调整输出以及输入的加权和。

![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig10_HTML.png](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig10_HTML.png)

图 1-10

偏差项有助于更好地拟合模型。左边没有偏差项，右边有偏差项。请注意，偏差项具有与之相关的权重

因此，偏差项类似于线性方程中的常数项，有助于更好地拟合数据。

我们现在将在下一节研究神经网络中最重要的属性之一——激活函数。

### 激活功能

激活函数的主要作用是决定神经元/感知器是否应该激活。它们在稍后阶段的网络训练期间在调整梯度方面起着核心作用。激活功能如图 [1-9](#Fig9) 所示。它们有时被称为*传递函数*。

激活函数的非线性行为允许深度学习网络学习复杂的行为。你将在第 [2](2.html) 章中考察什么是非线性行为。我们现在将研究一些常用的函数。

#### 1.4.7.1 Sigmoid 函数

Sigmoid 函数是一个有界的单调数学函数。它是一个具有 S 形曲线的可微函数，它的一阶导数函数是钟形的。它有一个非负导数函数，是为所有实输入值定义的。如果神经元的输出值在 0 和 1 之间，则使用 Sigmoid 函数。

数学上，sigmoid 函数如等式 1-1 所示。

![$$ S(x)=\frac{1}{1+{e}^{-x}}=\frac{e^x}{e^x+1} $$](../images/496201_1_En_1_Chapter/496201_1_En_1_Chapter_TeX_Equ1.png)

(方程式 1-1)

在图 [1-11](#Fig11) 中可以看到一个 sigmoid 函数的图形。注意函数的形状以及最大值和最小值。

![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig11_HTML.jpg](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig11_HTML.jpg)

图 1-11

一个 s 形函数；请注意，它不是以零为中心，其值介于 0 和 1 之间。乙状结肠面临着梯度消失的问题

Sigmoid 函数在复杂的学习系统中有其应用。当特定的数学模型不适合时，您通常会发现使用了 Sigmoid 函数。它通常用于二进制分类和网络的最终输出层。一个 Sigmoid 函数有一个消失梯度的问题，我们将在后面的章节中讨论。

#### 1.4.7.2 双曲正切函数

在数学中，正切双曲函数是可微的双曲函数。它是 Sigmoid 函数的缩放版本。这是一个平滑函数，其输入值在–1 到+1 的范围内。

与 Sigmoid 函数相比，它具有更稳定的梯度，更少的消失梯度问题。双曲正切函数可以表示为图 [1-12](#Fig12) 并且可以在等式 1-2 中看到。

![$$ Tanh(x)=\frac{e^x-{e}^{-x}}{e^x+{e}^{-x}} $$](../images/496201_1_En_1_Chapter/496201_1_En_1_Chapter_TeX_Equ2.png)

(方程式 1-2)

还显示了 tanh 的图形表示。注意 Sigmoid 函数和 tanh 函数的区别。观察 tanh 如何是 Sigmoid 函数的缩放版本。

![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig12_HTML.jpg](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig12_HTML.jpg)

图 1-12

双曲正切函数；注意，它通过零点，是 sigmoid 函数的缩放版本。其值介于–1 和+1 之间。与 sigmoid 类似，tanh 也有渐变消失的问题

双曲正切函数通常用于隐藏层。它使得平均值更接近于零，这使得网络中的下一层的训练更容易。这也被称为以数据为中心的*。双曲正切函数可以从 Sigmoid 函数导出，反之亦然。与 sigmoid 类似，双曲正切函数也存在梯度消失的问题，我们将在后续章节中讨论。*

我们现在研究最流行的激活函数——ReLU。

#### 1.4.7.3 校正线性单位

校正线性单元或 ReLU 是一个激活函数，它定义了一个自变量的正值。

ReLU 是一个简单的函数，计算成本最低，训练速度也快得多。它是无界的，并且不以零为中心。它在除零以外的所有地方都是可微的。由于 ReLU 函数可以更快地被训练，你会发现它被更频繁地使用。

我们可以检查 ReLU 函数和图 [1-13](#Fig13) 中的图形。该等式可以在等式 1-3 中看到。请注意，即使是负值，该值也是 0，从 0 开始，该值开始倾斜。

F(x) = max (0，x)，即如果为正，则输出为 x，否则为 0(等式 1-3)

![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig13_HTML.jpg](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig13_HTML.jpg)

图 1-13

ReLU 函数；注意，计算起来很简单，因此训练起来更快。它用于网络的隐藏层。ReLU 比 sigmoid 和 tanh 训练起来更快

由于 ReLU 函数不太复杂，计算成本较低，因此广泛用于隐藏层以更快地训练网络，我们在设计网络时也将使用 ReLU。现在，我们研究用于网络最后一层的 softmax 函数。

#### 1.4.7.4 软件最大值函数

softmax 函数用于神经网络的最后一层，以生成网络输出。输出可以是针对不同类别的图像的最终分类。

softmax 函数计算所有可能性中每个目标类的概率。它是一个激活函数，对于多类分类问题很有用，并强制神经网络输出 1 的和。

例如，如果输入是[1，2，3，4，4，3，2，1]，我们取一个 softmax，那么相应的输出将是[0.024，0.064，0.175，0.475，0.024，0.064，0.175]。该输出将最高权重分配给最高值，在本例中为 4。因此它可以用来突出显示最高值。一个更实际的例子是，如果图像的不同类别的数量是汽车、自行车或卡车，softmax 函数将为每个类别生成三个概率。获得最高概率的类别将是预测的类别。

我们已经研究了重要的活化函数。但是也可以有其他的激活函数，比如漏 ReLU、eLU 等等。我们将在整本书中遇到这些激活函数。表 [1-1](#Tab1) 显示了激活功能的汇总，以供快速参考。

表 1-1

主要激活功能及其各自的详细信息

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"></colgroup> 
| 

**激活功能**

 | 

**值**

 | 

**阳性**

 | 

**挑战**

 |
| --- | --- | --- | --- |
| 乙状结肠的 | [0,1] | ⑴非线性(2)易于使用(3)连续可微(4)单调性并且不会破坏激活 | (1)输出不在零中心(2)消失梯度问题(3)训练缓慢 |
| 双曲正切 | [-1,1] | (1)类似于 sigmoid 函数(2)梯度更强，但优于乙状结肠 | (1)消失梯度问题 |
| 线性单元 | [0，inf] | (1)非线性(2)易于计算，因此训练速度快(3)解决了梯度消失的问题 | (1)仅用于隐藏层(2)可以炸毁激活(3)对于 x<0 的区域，梯度将为零。因此，权重不会得到更新(垂死的 ReLU 问题) |
| 李奇注意到了 | 最大(0，x) | (ReLU 的变体(2)固定死亡继发问题 | (1)不能用于复杂的分类 |
| 埃卢 | [0，inf] | (ReLU 的替代方案(2)输出更加平滑 | (1)可以炸毁激活 |
| Softmax(软件最大值) | 计算概率 | 一般用于输出层 |   |

激活功能构成了网络的核心构件。在下一节中，我们将讨论指导网络如何学习和优化训练的学习率。

### 学习率

对于神经网络，*学习速率*将定义模型为减少误差而采取的校正步骤的大小。较高的学习率具有较低的准确度，但训练时间较短，而较低的学习率将需要较长的训练时间，但准确度较高。你必须达到它的最佳价值。

具体来说，学习率将决定在网络训练期间对权重的调整。学习速率将直接影响网络收敛并达到全局最小值所需的时间。在大多数情况下，0.01 的学习率是可以接受的。

我们现在将探索训练过程中可能最重要的过程——反向传播算法。

### 反向传播

我们在上一节学习了学习率。训练过程的目标是减少预测中的误差。虽然学习率定义了减少误差的校正步骤的大小，但是反向传播用于调整连接权重。这些权重基于误差向后更新。随后，重新计算误差，计算梯度下降，并调整各自的权重。

图 [1-14](#Fig14) 显示了信息从输出层流回隐藏层的反向传播过程。注意，与信息从左向右流动的前向传播相比，信息的流动是向后的。

![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig14_HTML.png](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig14_HTML.png)

图 1-14

神经网络中的反向传播。基于该误差，信息从输出反向流动，并且随后重新计算权重

让我们更详细地探索这个过程。

一旦网络做出了预测，我们就可以计算出预期值和预测值之间的误差。这被称为成本函数。基于成本值，神经网络然后调整其权重和偏差，以最接近实际值，或者换句话说，最小化误差。这是在反向传播期间完成的。

Note

建议你刷新微分学，更好的理解反向传播算法。

在反向传播期间，连接的参数被重复和迭代地更新和调整。调整的水平由成本函数相对于这些参数的梯度决定。梯度将告诉我们应该在哪个方向上调整权重以最小化成本。这些梯度是用链式法则计算的。使用链规则，一次计算一个图层的梯度，从最后一个图层到第一个图层反向迭代。这样做是为了避免链规则中中间项的冗余计算。

有时，我们在训练神经网络时会遇到梯度消失的问题。梯度消失问题是当梯度变得接近零时网络的初始层停止学习的现象。它使得网络不稳定，并且网络的初始层将不能学习任何东西。我们将在第 6 章[和第 8 章](6.html)[中再次探索消失渐变。](8.html)

我们现在讨论过度配合的问题，这是训练中最常见的问题之一。

### 过度装配

您知道网络使用训练数据来学习属性和模式。但我们希望我们的机器学习模型在看不见的数据上表现良好，这样我们就可以用它来进行预测。

为了衡量机器学习的准确性，我们必须评估训练和测试数据集的性能。通常，网络可以很好地模拟训练数据，并获得良好的训练准确性，而在测试/验证数据集上，准确性会下降。这叫做*过拟合*。简单地说，如果网络在训练数据集上工作得很好，但在看不见的数据集上不太好，这被称为过度拟合。

过度拟合是一件讨厌的事，我们必须与之斗争，对吗？为了解决过度拟合问题，您可以使用更多的训练数据来训练您的网络。或者降低网络的复杂性。通过降低复杂性，我们建议减少权重的数量、权重的值或网络本身的结构。

*批量标准化*和*剔除*是另外两种减轻过拟合问题的技术。

**批量归一化**是一种正则化方法。这是对平均值为零、标准差为一的图层的输出进行归一化的过程。它减少了对权重初始化的强调，从而减少了过拟合。

**辍学**是另一种解决过度适应问题的方法。这是一种正则化方法。在训练过程中，某些层的输出被随机丢弃或忽略。其效果是，对于每种组合，我们得到不同的神经网络。这也使得训练过程很吵。图 [1-15](#Fig15) 表示辍学的影响。左边的第一个图(图 [1-15(i)](#Fig15) )是一个标准的神经网络。右边的(图 [1-15(二)](#Fig15))是退学后的结果。

![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig15_HTML.png](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig15_HTML.png)

图 1-15

在退出之前，网络可能会过度拟合。在丢失之后，随机连接和神经元被移除，因此网络不会遭受过度拟合

借助 dropout，我们可以解决网络中的过度拟合问题，并获得一个更强大的解决方案。

接下来，我们将研究使用梯度下降的优化过程。

### 梯度下降

机器学习解决方案的目的是为我们的。我们希望减少训练阶段的损失，或者最大化精确度。梯度下降有助于达到这个目的。

梯度下降用于寻找函数的全局最小值或全局最大值。这是一种常用的优化技术。我们沿着最陡下降的方向迭代前进，最陡下降的方向由梯度的负值定义。

但是梯度下降在非常大的数据集上运行会很慢。这是因为梯度下降算法的一次迭代预测了训练数据集中的每个实例。因此，很明显，如果我们有成千上万的记录，这将需要很多时间。对于这样的情况，我们有*随机梯度下降*。

在随机梯度下降中，而不是在批次结束时，为每个训练实例更新系数，因此花费的时间较少。

图 [1-16](#Fig16) 显示了梯度下降的工作方式。请注意我们是如何朝着全局最小值向下发展的。

![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig16_HTML.png](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig16_HTML.png)

图 1-16

梯度下降的概念；注意它是如何达到全局最小值的。训练网络的目的是最小化遇到的错误

我们研究了如何使用梯度下降优化函数。检查机器学习模型有效性的方法是测量预测值与实际值有多远或多近。这是用我们现在讨论的损失来定义的。

### 损失函数

损失是衡量我们模型准确性的标准。简单来说就是实际值和预测值的差异。用于计算该损失的函数被称为*损失函数*。

不同的损失函数对相同的损失给出不同的值。由于损耗不同，相应型号的性能也会不同。

对于回归和分类问题，我们有不同的损失函数。交叉熵用于定义优化的损失函数。为了测量实际输出和期望输出之间的误差，通常使用均方误差。一些研究人员建议使用交叉熵误差来代替均方误差。表 [1-2](#Tab2) 给出了不同损失函数的快速总结。

表 1-2

各种损失函数，可与它们各自的方程和用法一起使用

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| 

**损失函数**

 | 

**损失方程**

 | 

**用于**

 |
| --- | --- | --- |
| 交叉熵 | -y(log(p) + (1-y) log(1-p)) | 分类 |
| 铰链损耗 | max(0，1- y *f(x)) | 分类 |
| 绝对误差 | y - f(x)&#124; | 回归 |
| 平方误差 | (y - f(x)) <sup>2</sup> | 回归 |
| 胡伯损失 | l<sub>=半(y-f(x))<sup><sup>，如果&#124;y-f(x) <</sup></sup></sub>else′y-f(x)&#124;-2′t1〖2〗 | 回归 |

我们现在已经检查了深度学习的主要概念。现在让我们研究一下神经网络是如何工作的。我们将理解不同的层如何相互作用，以及信息如何从一层传递到另一层。

我们开始吧！

## 1.5 深度学习如何工作？

你现在知道深度学习网络有不同的层次。你也经历了深度学习的概念。你可能想知道这些片段是如何组合在一起并协调整个学习过程的。可以对整个过程进行如下检查:

第一步

您可能想知道图层实际上做什么，图层实现什么，以及图层各自的权重中存储了什么。它只不过是一组数字。从技术上讲，由层实现的变换必须通过其权重来参数化，权重也被称为层的参数。

而学习是什么意思是下一个问题。神经网络的学习是为网络的所有层找到最佳的组合和权重值，以便我们可以达到最佳的准确性。由于深度神经网络可以有许多这样的参数值，我们必须找到所有参数的最佳值。考虑到改变一个价值会影响其他价值，这似乎是一项艰巨的任务。

让我们以图表的方式展示神经网络中的过程(图 [1-17](#Fig17) )。检查我们的输入数据层。两个数据变换层各自具有与其相关联的权重。然后我们有了对目标变量 y 的最终预测。

图像被输入到输入层，然后在数据变换层进行变换。

![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig17_HTML.png](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig17_HTML.png)

图 1-17

输入数据在数据变换层中进行变换，定义权重，并进行初始预测

第二步

我们已经在第一步创建了一个基本的框架。现在我们必须衡量这个网络的准确性。

我们想要控制神经网络的输出；我们必须比较和对比输出的准确性。

Info

准确性将指我们的预测与实际值的差距。简而言之，我们的预测与真实值的差距是衡量准确性的标准。

精度测量由网络的损耗函数完成，也称为*目标函数*。损失函数采用网络预测值和真实或实际目标值。这些实际值就是我们期望网络输出的值。损失函数计算距离得分，捕捉网络的表现。

让我们通过添加损失函数和相应的损失分数来更新我们在步骤 1 中创建的图表(图 [1-18](#Fig18) )。它有助于衡量网络的准确性。

![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig18_HTML.png](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig18_HTML.png)

图 1-18

增加一个损失函数来衡量精度；损失是实际值和预测值之间的差异。在这个阶段，我们根据误差项知道了网络的性能

第三步

如前所述，我们必须最大限度地提高精度或降低损耗。这将使解决方案在预测中更加稳健和准确。

为了不断降低损失，分数(预测-实际)然后被用作反馈信号，以稍微调整权重值，这是由优化器完成的。这项任务由*反向传播算法*完成，该算法有时被称为深度学习中的中心算法。

最初，一些随机值被分配给权重，因此网络正在实现一系列随机变换。从逻辑上讲，输出与我们预期的完全不同，因此损失分数非常高。毕竟，这是第一次尝试！

但这将会改善。在训练神经网络时，我们会不断遇到新的训练示例。对于每一个新的例子，权重会在正确的方向上调整一点，随后损失分数会降低。我们多次迭代这个训练循环，并且它产生最小化损失函数的最佳权重值。

然后我们实现我们的目标，这是一个训练有素的网络，损失最小。这意味着实际值和预测值非常接近。为了实现完整的解决方案，我们扩大了该机制，如图 [1-19](#Fig19) 所示。

请注意优化器，它提供定期和连续的反馈以达到最佳解决方案。

![../images/496201_1_En_1_Chapter/496201_1_En_1_Fig19_HTML.png](../images/496201_1_En_1_Chapter/496201_1_En_1_Fig19_HTML.png)

图 1-19

优化器给出反馈并优化权重；这就是反向传播的过程。这确保了误差被迭代地减小

一旦我们为我们的网络实现了最佳价值，我们就称我们的网络现在已经训练好了。我们现在可以用它对看不见的数据集进行预测。

现在你已经理解了深度学习的各个组成部分是什么，以及它们如何协同工作。现在是时候检查深度学习的所有工具和库了。

### 1.5.1 流行的深度学习库

有相当多的深度学习库可用。这些包允许我们以最小的努力更快地开发解决方案，因为大部分繁重的工作都是由这些库完成的。

我们在这里讨论最受欢迎的图书馆。

**TensorFlow** :由 Google 开发的 TensorFlow (TF)可以说是最流行、应用最广泛的深度学习框架之一。它于 2015 年推出，此后被全球许多企业和品牌使用。

Python 多用于 TF，但 C++、Java、C#、JavaScript、Julia 也可以。您必须在您的系统上安装 TF 库并导入该库。而且已经可以使用了！

Note

进入 [`www.tensorflow.org/install`](http://www.tensorflow.org/install) ，按照说明安装 TensorFlow。

如果对模型架构进行任何修改，必须对 TF 模型进行重新培训。它使用静态计算图进行操作，这意味着我们首先定义图，然后运行计算。

它很受欢迎，因为它是由谷歌开发的。它也可以在 iOS 和 Android 等移动设备上运行。

Keras :对于初学者来说，这是最简单的深度学习框架之一，对于简单概念的理解和原型制作来说，这是非常棒的。Keras 最初于 2015 年发布，是最值得推荐的了解神经网络细微差别的库之一。

Note

进入 [`https://keras.io`](https://keras.io) ，按照说明安装 Keras。Tf.keras 可以作为 API，在本书中会经常用到。

它是一个成熟的 API 驱动的解决方案。Keras 中的原型制作被简化到了极限。使用 Python 生成器的序列化/反序列化 API、回调和数据流已经非常成熟。Keras 中的大规模模型被简化为单行函数，这使得它成为一个不太可配置的环境。

**PyTorch** :脸书的大脑儿童 PyTorch 于 2016 年发布，是广受欢迎的深度学习库之一。我们可以在 PyTorch 中使用调试器，比如 pdb 或者 PyCharm。PyTorch 使用动态更新的图形进行操作，并允许数据并行和分布式学习模型。对于小型项目和原型开发，PyTorch 应该是您的选择；然而，对于跨平台解决方案，TensorFlow 是众所周知的更好。

**十四行诗** : DeepMind 的十四行诗是使用并在 TF 之上开发的。Sonnet 是为复杂的神经网络应用和架构设计的。

Sonnet 创建对应于神经网络(NN)特定部分的主要 Python 对象。在这之后，这些 Python 对象被独立地连接到计算张量流图。它简化了设计，这是由于创建对象和将它们与图形相关联的过程的分离。此外，拥有高级面向对象库的能力是有利的，因为当我们开发机器学习算法时，它有助于抽象。

**MXNet** : Apache 的 MXNet 是一个高可扩展性的深度学习工具，简单易用，有详细的文档。MXNet 支持大量的语言，如 C++、Python、R、Julia、JavaScript、Scala、Go 和 Perl。

还有其他的框架，像 Swift、Gluon、Chainer、DL4J 等等；然而，我们在这本书里只讨论了流行的。表 [1-3](#Tab3) 给出了所有框架的概述。

表 1-3

主要的深度学习框架及其各自的属性

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| 

**框架**

 | 

**来源**

 | 

**属性**

 |
| --- | --- | --- |
| TensorFlow | 开放源码 | 最流行的，也可以在手机上工作，TensorBoard 提供可视化 |
| 硬 | 开放源码 | API 驱动的成熟解决方案，非常好用 |
| PyTorch | 开放源码 | 允许数据并行，非常适合快速产品构建 |
| 十四行诗 | 开放源码 | 简化设计，创建高级对象 |
| mxnet 系统 | 开放源码 | 高度可扩展，易于使用 |
| 矩阵实验室 | 得到许可的 | 高度可配置，提供部署功能 |

## 1.6 摘要

深度学习是一种持续的学习体验，需要自律、严谨和投入。你已经迈出了学习旅程的第一步。在第一章中，我们学习了图像处理和深度学习的概念。它们是整本书和你未来道路的基石。我们使用 OpenCV 开发了三种解决方案。

在下一章中，您将深入研究 TensorFlow 和 Keras。您将使用卷积神经网络开发您的第一个解决方案。从设计网络、培训网络到实施网络。所以保持专注！

Review Exercises

1.  图像处理的各个步骤是什么？

2.  使用 OpenCV 开发一个对象检测解决方案。

3.  训练一个深度学习网络的过程是怎样的？

4.  什么是过度拟合，我们如何解决它？

5.  什么是各种激活功能？

### 进一步阅读

1.  OpenCV 简介: [`https://ieeexplore.ieee.org/document/6240859`](https://ieeexplore.ieee.org/document/6240859) 。

2.  用于计算机视觉应用的 OpenCV:[`www.researchgate.net/publication/301590571_OpenCV_for_Computer_Vision_Applications`](https://www.researchgate.net/publication/301590571_OpenCV_for_Computer_Vision_Applications)。

3.  OpenCV 文档可以在 [`https://docs.opencv.org/`](https://docs.opencv.org/2.4/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html) 访问。

4.  浏览以下文件:
    1.  [T2`www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf`](https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf)

    2.  [T2`https://arxiv.org/pdf/1404.7828.pdf`](https://arxiv.org/pdf/1404.7828.pdf)