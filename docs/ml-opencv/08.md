# 利用无监督学习发现隐藏结构

到目前为止，我们的注意力完全集中在监督学习问题上，其中数据集中的每个数据点都有一个已知的标签或目标值。然而，当没有已知的输出或没有老师监督学习算法时，我们该怎么办？

这就是**无监督学习**的意义所在。在无监督学习中，学习过程仅在输入数据中显示，并被要求从该数据中提取知识，而无需进一步指导。我们已经讨论了无监督学习的众多形式之一——**降维**。另一个流行的领域是**聚类分析**，旨在将数据划分为相似项目的不同组。

聚类技术可能有用的一些问题是文档分析、图像检索、查找垃圾邮件、识别假新闻、识别犯罪活动等。

在这一章中，我们想了解如何使用不同的聚类算法来提取简单、未标记的数据集中的隐藏结构。无论是用于特征提取、图像处理，还是作为监督学习任务的预处理步骤，这些隐藏结构都有很多好处。作为一个具体的例子，我们将学习如何将聚类应用于图像，以将其颜色空间减少到 16 位。

更具体地说，我们将涵盖以下主题:

*   **k 均值聚类**和**期望最大化**并在 OpenCV 中实现
*   在层次树中安排聚类算法，这样做有什么好处
*   使用无监督学习进行预处理、图像处理和分类

我们开始吧！

# 使用 TF-IDF 来改进结果

它被称为**术语频率-逆文档频率** ( **TF** **-IDF** )，我们在[第 4 章](04.html)、*中遇到了它，代表数据和工程特性*。如果您还记得，TF-IDF 所做的基本上是通过衡量单词在整个数据集中出现的频率来衡量单词数。这种方法的一个有用的副作用是 IDF 部分——单词出现的频率相反。这就保证了频繁词，如***但*在分类中只占很小的权重。**

 **我们通过调用现有特征矩阵`X`上的`fit_transform`将 TF-IDF 应用于特征矩阵:

```
In [24]: tfidf = feature_extraction.text.TfidfTransformer()In [25]: X_new = tfidf.fit_transform(X)
```

别忘了拆分数据；还有，...

# 摘要

在这一章中，我们第一次看了概率论，学习了随机变量和条件概率，这让我们得以一窥贝叶斯定理——朴素贝叶斯分类器的基础。我们讨论了离散和连续随机变量之间的区别，可能性和概率，先验和证据，以及正常和朴素贝叶斯分类器。

最后，如果我们不把理论知识应用到实际例子中，它将毫无用处。我们获得原始电子邮件消息的数据集，对其进行解析，并在其上训练贝叶斯分类器，以使用各种特征提取方法将电子邮件分类为垃圾邮件或垃圾邮件(非垃圾邮件)。

在下一章中，我们将转换话题，这一次，讨论如果我们不得不处理未标记的数据该怎么办。

# 技术要求

可以从以下链接查阅本章代码:[https://github . com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/chapter 08](https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter08)。

以下是软件和硬件要求的总结:

*   您将需要 OpenCV 版本 4.1.x (4.1.0 或 4.1.1 都可以)。
*   您将需要 Python 3.6 版本(任何 Python 3 . x 版本都可以)。
*   您将需要 Anaconda Python 3 来安装 Python 和所需的模块。
*   除了这本书，你可以使用任何操作系统——苹果操作系统、视窗操作系统和基于 Linux 的操作系统。我们建议您的系统中至少有 4 GB 内存。
*   你不需要一个图形处理器来运行本书提供的代码。

# 理解无监督学习

无监督学习可能有多种形式，但目标总是将原始数据转换为更丰富、更有意义的表示，无论这意味着让人类更容易理解还是让机器学习算法更容易解析。

无监督学习的一些常见应用包括:

*   **降维**:这是对由许多特征组成的数据进行高维表示，并试图压缩数据，使其主要特征可以用少量信息丰富的特征来解释。例如，当应用于波士顿附近的房价时，降维也许可以告诉我们，我们最应该关注的指标是房产税和附近的犯罪率。
*   **因素分析**:这是试图找出产生观测数据的隐藏原因或未观测到的成分。例如，当应用于 20 世纪 70 年代电视剧《T2》的所有剧集时，史酷比-杜，你在哪里！，因子分析或许能告诉我们(剧透预警！)节目中的每一个鬼魂或怪物本质上都是一些心怀不满的伯爵在镇上精心设计的骗局。

*   **聚类分析**:这试图将数据划分为相似项目的不同组。这就是我们将在本章重点讨论的无监督学习类型。例如，当应用于网飞的所有电影时，聚类分析可能能够自动将它们分成不同的类型。

为了让事情变得更复杂，这些分析必须在没有标签的数据上进行，我们事先不知道正确的答案应该是什么。因此，无监督学习的一个主要挑战是确定一个算法是做得好还是学到了什么有用的东西。通常，评估无监督学习算法结果的唯一方法是手动检查它，并手动确定结果是否有意义。

也就是说，无监督学习非常有用，例如，作为预处理或特征提取步骤。你可以把无监督学习想象成一种**数据转换**——一种将数据从其原始表示转换成信息更丰富的形式的方法。学习一种新的表示可能会让我们对数据有更深入的了解，有时，它甚至可能会提高监督学习算法的准确性。

# 理解 k-均值聚类

OpenCV 提供的基本聚类算法是*k*-意味着聚类，它从未标记的多维数据中搜索预定数量的 *k-* 聚类(或组)。

它通过使用关于最佳聚类应该是什么样子的两个简单假设来实现这一点:

*   每个聚类的中心基本上是属于该聚类的所有点的平均值，也称为质心。
*   该集群中的每个数据点都比所有其他集群中心更靠近其中心。

看一个具体的例子最容易理解算法。

# 实现我们的第一个 k 均值示例

首先，让我们生成一个包含四个不同斑点的 2D 数据集。为了强调这是一种无监督的方法，我们将把标签排除在可视化之外:

1.  我们将继续使用`matplotlib`来实现我们所有的可视化目的:

```
In [1]: import matplotlib.pyplot as plt
...     %matplotlib inline
...     plt.style.use('ggplot')
```

2.  遵循前面章节中的相同方法，我们将创建总共 300 个斑点(`n_samples=300`)属于四个不同的集群(`centers=4`):

```
In [2]: from sklearn.datasets.samples_generator import make_blobs
...     X, y_true = make_blobs(n_samples=300, centers=4,
...                            cluster_std=1.0, random_state=10)
...     plt.scatter(X[:, 0], X[:, 1], s=100);
```

这将生成以下图表:

![](Images/1479c696-e19b-4992-bbfe-1d4e38a58124.png)

上图显示了由 300 个未标记点组成的示例数据集，这些点被组织成四个不同的集群。即使没有给数据分配目标标签，也可以通过肉眼直接识别出四个聚类。*k*-意味着算法也可以做到这一点，而不需要任何关于目标标签或底层数据分布的信息。

3.  虽然 *k* -means 当然是一个统计模型，但是在 OpenCV 中，它不是通过`ml`模块和常见的`train`和`predict` API 调用来的。而是直接作为`cv2.kmeans`提供。为了使用该模型，我们必须指定一些参数，例如终止条件和一些初始化标志。这里，只要误差小于 1.0 ( `cv2.TERM_CRITERIA_EPS`)或者已经执行了十次迭代(`cv2.TERM_CRITERIA_MAX_ITER`)我们就告诉算法终止:

```
In [3]: import cv2
...     criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,
...                 10, 1.0)
...     flags = cv2.KMEANS_RANDOM_CENTERS
```

4.  然后，我们可以将前面的数据矩阵(`X`)传递给`cv2.means`。我们还指定了聚类的数量(`4`)以及算法在不同的随机初始猜测下应该进行的尝试次数(`10`)，如下面的代码片段所示:

```
In [4]: import numpy as np
...     compactness, labels, centers = cv2.kmeans(X.astype(np.float32),
...                                               4, None, criteria,
...                                               10, flags)
```

返回三个不同的变量。

5.  第一个，`compactness`返回从每个点到它们对应的聚类中心的平方距离的总和。高紧密度分数表示所有点都接近它们的聚类中心，而低紧密度分数表示不同的聚类可能没有很好地分开:

```
In [5]: compactness
Out[5]: 527.01581170992
```

6.  当然，这个数字很大程度上取决于`X`中的实际值。如果点与点之间的距离很大，首先，我们不能期望一个任意小的紧凑性分数。因此，绘制数据点的图更有意义，这些数据点被着色为它们分配的聚类标签:

```
In [6]: plt.scatter(X[:, 0], X[:, 1], c=labels, s=50, cmap='viridis')
...     plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200,
...                 alpha=0.5);
```

7.  这将生成所有数据点的散点图，这些数据点根据它们所属的聚类进行着色，相应的聚类中心在每个聚类的中心用较暗的斑点表示:

![](Images/9305c4e4-b92e-45a9-865b-ffd047e3ca5e.png)

上图为 *k* 的结果-表示 *k=4* 的聚类。这里的好消息是*k*-意思是算法(至少在这个简单的例子中)将点分配给聚类，非常类似于我们可能做的，如果我们用眼睛做的话。但是算法是如何这么快找到这些不同的聚类的呢？毕竟，集群分配的可能组合的数量与数据点的数量成指数关系！用手，尝试所有可能的组合肯定需要很长时间。

幸运的是，没有必要进行彻底的搜索。取而代之的是， *k* -means 采用的典型方法是使用迭代算法，也称为**期望最大化**。

# 理解期望最大化

*k*-意味着聚类只是被称为期望最大化的更一般算法的一个具体应用。简而言之，该算法的工作原理如下:

1.  从一些随机的集群中心开始。
2.  重复直到收敛:
    *   **期望步骤**:将所有数据点分配到它们最近的聚类中心。
    *   **最大化步骤**:取聚类中所有点的平均值更新聚类中心。

这里，期望步骤如此命名，因为它涉及更新我们对数据集中每个点属于哪个聚类的期望。最大化步骤之所以如此命名，是因为它涉及最大化定义聚类中心位置的适应度函数。在 *k* 的情况下-意味着，最大化...

# 实现我们的期望最大化解决方案

期望最大化算法很简单，我们可以自己编码。为此，我们将定义一个函数`find_clusters(X, n_clusters, rseed=5)`，该函数将一个数据矩阵(`X`)、我们想要发现的聚类数(`n_clusters`)和一个随机种子(可选，`rseed`)作为输入。很快就会明白，scikit-learn 的`pairwise_distances_argmin`功能将派上用场:

```
In [7]: from sklearn.metrics import pairwise_distances_argmin
...     def find_clusters(X, n_clusters, rseed=5):
```

我们可以通过五个基本步骤来实现 *k* 的期望最大化:

1.  **初始化**:随机选择若干个集群中心，`n_clusters`。我们不只是选择任何随机数，而是选择实际的数据点作为聚类中心。我们通过沿着第一个轴排列`X`并在这个随机排列中选择第一个`n_clusters`点来实现:

```
        ...         rng = np.random.RandomState(rseed)
        ...         i = rng.permutation(X.shape[0])[:n_clusters]
        ...         centers = X[i]
```

2.  **`while`永远循环**:根据最近的聚类中心分配标签。在这里，scikit-learn 的`pairwise_distance_argmin`功能正是我们想要的。它为`X`中的每个数据点计算`centers`中最近的聚类中心的索引:

```
        ...         while True:
        ...         labels = pairwise_distances_argmin(X, centers)
```

3.  **寻找新的聚类中心**:这一步我们要取`X`中属于特定聚类(`X[labels == i]`)的所有数据点的算术平均值:

```
        ...          new_centers = np.array([X[labels ==
                     i].mean(axis=0)
```

4.  **检查收敛情况，必要时打破** `while` **循环**:这是最后一步，确保一旦工作完成，我们就停止算法的执行。我们通过检查所有新的集群中心是否与旧的集群中心相等来确定工作是否完成。如果这是真的，我们退出循环；否则，我们继续循环:

```
        ...             for i in range(n_clusters)])
        ...             if np.all(centers == new_centers):
        ...                break
        ...             centers = new_centers
```

5.  退出函数并返回结果:

```
        ...             return centers, labels
```

我们可以将我们的函数应用于前面我们创建的数据矩阵`X`。既然我们知道数据是什么样的，我们就知道我们在寻找四个集群:

```
In [8]: centers, labels = find_clusters(X, 4)
...     plt.scatter(X[:, 0], X[:, 1], c=labels, s=100, cmap='viridis');
```

这将生成下面的图。从下图中观察到的要点是，在应用 *k* 均值聚类之前，所有数据点都被归类为同一种颜色；然而，在使用*k*-意味着聚类之后，每种颜色是不同的聚类(相似的数据点被聚类或分组为一种颜色) :

![](Images/9b09ee68-3da7-4eaf-b90b-324b62fa1266.png)

上图展示了我们自制 *k* 的结果——意味着使用期望最大化。我们可以看到，我们自制的算法完成了任务！诚然，这个特定的集群例子相当简单，而且大多数 T2 k 的实际实现意味着集群在幕后会做得更多。但现在，我们很幸福。

# 了解期望最大化的局限性

尽管简单，期望最大化在一系列场景中表现得非常好。也就是说，我们需要注意一些潜在的限制:

*   期望最大化不能保证我们会找到全局最优解。
*   我们必须事先知道期望的簇的数量。
*   算法的决策边界是线性的。
*   对于大型数据集，该算法速度较慢。

让我们快速详细地讨论一下这些潜在的警告。

# 第一个警告——不能保证找到全局最优

尽管数学家已经证明期望最大化步骤在每一步都改善了结果，但仍然不能保证最终我们会找到全局最优解。例如，如果我们在我们的简单示例中使用不同的随机种子(例如使用种子`10`而不是`5`，我们会突然得到非常差的结果:

```
In [9]: centers, labels = find_clusters(X, 4, rseed=10)
...     plt.scatter(X[:, 0], X[:, 1], c=labels, s=100, cmap='viridis');
```

这将生成以下图表:

![](Images/ec702b4a-9401-4088-b676-9f5b5149ee5d.png)

上图显示了 *k* 的一个例子——意味着错过了全局最优。发生了什么事？

简单地说，集群中心的随机初始化是不幸的。它导致黄色星系团的中心在两个顶端星系团之间移动，基本上将它们合并成一个。结果，其他集群变得混乱，因为他们突然不得不将两个视觉上不同的斑点分成三个集群。

由于这个原因，算法在多个初始状态下运行是很常见的。实际上，OpenCV 默认会这样做(由可选的`attempts`参数设置)。

# 第二个警告——我们必须事先选择集群的数量

另一个潜在的限制是*k*-意味着不能从数据中学习聚类的数量。相反，我们必须事先告诉它我们期望有多少个集群。您可以看到，对于您尚未完全理解的复杂现实数据，这可能会有问题。

从 *k* 的角度来看，意味着没有错误或无意义的簇数。例如，如果我们要求算法在前面部分生成的数据集中识别六个聚类，它将愉快地继续并找到最佳的六个聚类:

```
In [10]: criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,...                  10, 1.0)...      flags = cv2.KMEANS_RANDOM_CENTERS... compactness, labels, centers ...
```

# 第三个警告——集群边界是线性的

*k* -means 算法基于一个简单的假设，即点会比其他点更靠近自己的聚类中心。因此，*k*-意味着总是假设集群之间的线性边界，这意味着每当集群的几何形状比这更复杂时，它就会失败。

通过生成稍微复杂一点的数据集，我们看到了这种局限性。我们希望将数据组织成两个重叠的半圆，而不是从高斯斑点生成数据点。我们可以使用 scikit-learn 的`make_moons`来做到这一点。这里，我们选择属于两个半圆的 200 个数据点，并结合一些高斯噪声:

```
In [14]: from sklearn.datasets import make_moons
...      X, y = make_moons(200, noise=.05, random_state=12)
```

这一次，我们告诉*k*-意思是寻找两个集群:

```
In [15]: criteria = (cv2.TERM_CRITERIA_EPS +
...                  cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
...      flags = cv2.KMEANS_RANDOM_CENTERS
...      compactness, labels, centers = cv2.kmeans(X.astype(np.float32),
...                                                2, None, criteria,
...                                                10, flags)
...      plt.scatter(X[:, 0], X[:, 1], c=labels, s=100, cmap='viridis');
```

得到的散点图如下图所示:

![](Images/305edf9a-f7c3-491e-8a1e-10c6427d1917.png)

上图展示了 *k* 的一个例子——意思是在非线性数据中寻找线性边界。从图中可以明显看出，*k*-表示未能识别两个半圆，而是用看起来像对角线的直线分割数据(从左下角到右上角)。

这种情况应该会让人想起。当我们在[第 6 章](06.html)*中讨论使用支持向量机检测行人时，我们遇到了同样的问题。*当时的想法是利用核技巧将数据转换成更高维的特征空间。我们能在这里做同样的事情吗？

我们当然可以。有一种内核化的形式*k*-意思是类似于支持向量机的内核技巧，叫做**谱聚类**。不幸的是，OpenCV 没有提供谱聚类的实现。幸运的是，scikit-learn 做到了:

```
In [16]: from sklearn.cluster import SpectralClustering
```

该算法使用与所有其他统计模型相同的 API:我们在构造函数中设置可选参数，然后对数据调用`fit_predict`。在这里，我们希望使用最近邻居的图来计算数据的更高维表示，然后使用 *k* 来分配标签-意思是:

```
In [17]: model = SpectralClustering(n_clusters=2,
...                                 affinity='nearest_neighbors',
...                                 assign_labels='kmeans')
...      labels = model.fit_predict(X)
...      plt.scatter(X[:, 0], X[:, 1], c=labels, s=100, cmap='viridis');
```

光谱聚类的输出如下所示:

![](Images/3c51c11b-66f9-408d-b404-ae809e59bb5b.png)

我们看到光谱聚类完成了工作。或者，我们可以自己将数据转换成更合适的表示，然后对其应用 OpenCV 的线性 *k* -means。所有这一切的教训是，也许，再次，功能工程拯救了这一天。

# 第四个警告——对于大量样本来说，k 均值是缓慢的

*k*-的最后一个限制是，对于大数据集来说相对较慢。你可以想象，相当多的算法可能会遇到这个问题。但是， *k* -means 受到的影响尤其严重: *k* -means 的每次迭代都必须访问数据集中的每个数据点，并将其与所有聚类中心进行比较。

您可能想知道在每次迭代期间访问所有数据点的需求是否真的有必要。例如，您可以只使用数据的子集在每个步骤更新集群中心。事实上，这正是一种叫做**基于批次的 *k* 的算法变体的基本思想——意思是**。不幸的是，这个算法没有实现...

# 使用 k 均值压缩颜色空间

*k* -means 的一个有趣的用例是图像颜色空间的压缩。例如，标准的**彩色图像**具有 24 位色深，总共提供 16，777，216 种颜色。然而，在大多数图像中，大量的颜色将不会被使用，并且图像中的许多像素将具有相似的值。然后，压缩后的图像可以以更快的速度通过互联网发送，在接收端，它可以被解压缩以恢复原始图像。因此，降低了存储和传输成本。但是，图像色彩空间压缩将是**有损的**，并且您可能不会注意到压缩后图像中的细微细节。

或者，我们也可以使用*k*-手段来减少调色板。这里的想法是把集群中心想象成减少的调色板。然后，*k*-表示将原始图像中的数百万种颜色组织成适当数量的颜色。

# 可视化真彩色调色板

通过执行以下步骤，您将能够可视化彩色图像的真彩色调色板:

1.  让我们来看看一个特殊的图像:

```
In [1]: import cv2...     import numpy as np...     lena = cv2.imread('data/lena.jpg', cv2.IMREAD_COLOR)
```

2.  现在，我们知道如何在睡眠中启动 Matplotlib:

```
In [2]: import matplotlib.pyplot as plt...     %matplotlib inline...     plt.style.use('ggplot')
```

3.  但是，这一次，我们希望禁用`ggplot`选项通常在图像上显示的网格线:

```
In [3]: plt.rc('axes', **{'grid': False})
```

4.  然后，我们可以使用以下命令来可视化 Lena(不要忘记将颜色通道的 BGR 顺序切换到 RGB):

```
In [4]: plt.imshow(cv2.cvtColor(lena, cv2.COLOR_BGR2RGB)) ...
```

# 使用 k 均值缩小调色板

通过参考以下步骤，您将能够使用*k*-意味着聚类将彩色图像投影到缩小的调色板中:

1.  现在，让我们通过指示 *k* 来将 1600 万种颜色减少到仅仅 16 种，这意味着将所有 1600 万种颜色变化聚类成 16 个不同的聚类。我们将使用前面提到的过程，但现在将 16 定义为集群数:

```
In [9]: criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,
...                 10, 1.0)
...     flags = cv2.KMEANS_RANDOM_CENTERS
...     img_data = img_data.astype(np.float32)
...     compactness, labels, centers = cv2.kmeans(img_data,
...                                               16, None, criteria,
...                                               10, flags)
```

2.  缩小调色板中的 16 种不同颜色对应于生成的簇。`centers`数组的输出显示所有颜色都有三个条目— `B`、`G`和`R`—值介于 0 和 1 之间:

```
In [10]: centers
Out[10]: array([[ 0.29973754,  0.31500012,  0.48251548],
                [ 0.27192295,  0.35615689,  0.64276862],
                [ 0.17865284,  0.20933454,  0.41286203],
                [ 0.39422086,  0.62827665,  0.94220853],
                [ 0.34117648,  0.58823532,  0.90196079],
                [ 0.42996961,  0.62061119,  0.91163337],
                [ 0.06039202,  0.07102439,  0.1840712 ],
                [ 0.5589878 ,  0.6313886 ,  0.83993536],
                [ 0.37320262,  0.54575169,  0.88888896],
                [ 0.35686275,  0.57385623,  0.88954246],
                [ 0.47058824,  0.48235294,  0.59215689],
                [ 0.34346411,  0.57483661,  0.88627452],
                [ 0.13815609,  0.12984112,  0.21053818],
                [ 0.3752504 ,  0.47029912,  0.75687987],
                [ 0.31909946,  0.54829341,  0.87378371],
                [ 0.40409693,  0.58062142,  0.8547557 ]], dtype=float32)
```

3.  `labels`向量包含对应于 16 簇`labels`的 16 种颜色。因此，标签为 0 的所有数据点将根据`centers`数组中的第 0 行进行着色；同样，标签为 1 的所有数据点将根据`centers`数组中的第 1 行进行着色，以此类推。因此，我们希望使用`labels`作为`centers`数组中的索引—这些是我们的新颜色:

```
In [11]: new_colors = centers[labels].reshape((-1, 3))
```

4.  我们可以再次绘制数据，但这一次，我们将使用`new_colors`对数据点进行相应的着色:

```
In [12]: plot_pixels(img_data, colors=new_colors, 
...      title="Reduce color space: 16 colors")   
```

结果是原始像素的重新着色，其中每个像素被分配其最近的聚类中心的颜色:

![](Images/f3b6e0d8-5b3b-4c4f-98fc-c75abe2aefe1.png)

5.  为了观察重新着色的效果，我们必须将`new_colors`绘制为图像。我们展平了之前的图像，从图像到数据矩阵。现在回到图像，我们需要做反，就是根据 Lena 图像的形状重塑`new_colors`:

```
In [13]: lena_recolored = new_colors.reshape(lena.shape)
```

6.  然后，我们可以像任何其他图像一样可视化重新着色的 Lena 图像:

```
In [14]: plt.figure(figsize=(10, 6))
...      plt.imshow(cv2.cvtColor(lena_recolored, cv2.COLOR_BGR2RGB));
...      plt.title('16-color image')
```

结果是这样的:

![](Images/db7c60af-4276-454d-9f22-a32cda3bdb5e.png)

很棒，对吧？

总的来说，前面的截图非常清晰可辨，尽管有些细节可能丢失了。假设您将图像压缩了大约 100 万倍，这是非常了不起的。

您可以对任意数量的颜色重复此过程。

Another way to reduce the color palette of images involves the use of **bilateral filters**. The resulting images often look like cartoon versions of the original image. You can find an example of this in the book, *OpenCV with Python Blueprints*, by M. Beyeler, Packt Publishing.

*k* -means 的另一个潜在应用是您可能没有想到的:将其用于图像分类。

# 用 k-均值对手写数字进行分类

虽然上一个应用程序非常有创意地使用了 *k* -means，但我们还可以做得更好。我们之前已经讨论过*k*-意思是在无监督学习的背景下，我们试图发现数据中的一些隐藏结构。

然而，同样的概念难道不适用于大多数分类任务吗？假设我们的任务是对手写数字进行分类。如果不是一样的话，大多数零看起来不都是相似的吗？所有的 0 看起来不是和所有可能的 1 完全不同吗？这不正是我们着手用无监督学习去发现的那种*隐藏结构*吗？这不意味着我们也可以使用聚类进行分类吗？

让我们一起去发现。在本节中，我们将尝试...

# 正在加载数据集

从前面的章节中，您可能还记得 scikit-learn 通过其`load_digits`实用功能提供了一系列手写数字。数据集由 1，797 个样本组成，每个样本具有 64 个特征，其中每个特征在*8×8*图像中具有一个像素的亮度:

```
In [1]: from sklearn.datasets import load_digits
...     digits = load_digits()
...     digits.data.shape
Out[1]: (1797, 64)
```

# 运行 k 均值

设置*k*-意味着工作方式与前面的例子完全相同。我们告诉算法最多执行 10 次迭代，如果我们对聚类中心的预测在`1.0`距离内没有改善，则停止该过程:

```
In [2]: import cv2...     criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,...                 10, 1.0)...     flags = cv2.KMEANS_RANDOM_CENTERS
```

然后，我们像以前一样对数据应用 *k* -means。由于有 10 个不同的数字(0-9)，我们告诉算法寻找 10 个不同的聚类:

```
In [3]: import numpy as np...     digits.data = digits.data.astype(np.float32)...     compactness, clusters, centers = cv2.kmeans(digits.data, 10, None,...                                                 criteria, 10, flags)
```

我们结束了！

类似于*N×3*矩阵...

# 将集群组织为分层树

替代 *k* 的方法是**层次聚类**。层次聚类的一个优点是，它允许我们在层次结构中组织不同的聚类(也称为**树图**，这可以使结果更容易解释。另一个有用的优点是，我们不需要预先指定集群的数量。

# 理解层次聚类

分层聚类有两种方法:

*   在**凝聚层次聚类**中，我们从每个数据点可能是它自己的聚类开始，然后我们合并最接近的聚类对，直到只剩下一个聚类。
*   在**分裂的层次聚类**中，情况正好相反；我们首先将所有数据点分配给同一个集群，然后将集群分成更小的集群，直到每个集群只包含一个样本。

当然，如果我们愿意，我们可以指定所需集群的数量。在下面的截图中，我们要求算法总共找到三个聚类:

前面的截图显示了一个凝聚的分步示例...

# 实现聚集层次聚类

虽然 OpenCV 没有提供凝聚层次聚类的实现，但它是一种流行的算法，应该属于我们的机器学习技能集:

1.  我们从生成 10 个随机数据点开始，就像前面的截图一样:

```
In [1]: from sklearn.datasets import make_blobs
...     X, y = make_blobs(random_state=100, n_samples=10)
```

2.  使用熟悉的统计建模应用编程接口，我们导入`AgglomerativeClustering`算法并指定所需的聚类数:

```
In [2]: from sklearn import cluster
...     agg = cluster.AgglomerativeClustering(n_clusters=3)
```

3.  像往常一样，通过`fit_predict`方法将模型拟合到数据:

```
In [3]: labels = agg.fit_predict(X)
```

4.  我们可以生成散点图，其中每个数据点都根据预测的标签进行着色:

```
In [4]: import matplotlib.pyplot as plt
... %matplotlib inline
... plt.style.use('ggplot')
... plt.scatter(X[:, 0], X[:, 1], c=labels, s=100)
```

生成的聚类相当于下图:

![](Images/1c9d3311-d0f0-4f90-89aa-f93c45af9b60.png)

最后，在我们结束本章之前，让我们看看如何比较聚类算法，并为您拥有的数据选择正确的聚类算法！

# 比较聚类算法

`sklearn`库中大约有十三种不同的聚类算法。有十三种不同的选择，问题是:你应该使用什么样的聚类算法？答案是你的数据。你有什么类型的数据，你想在其上应用哪个聚类，这就是你如何选择算法。话虽如此，有许多可能的算法可能对你的问题和数据有用。`sklearn`中的十三个类中的每一个都专门用于特定的任务(如共聚类和双聚类或聚类特征而不是数据点)。专门用于文本聚类的算法将是聚类文本数据的正确选择。因此，如果...

# 摘要

在这一章中，我们讨论了一些无监督学习算法，包括 *k* -means、球形聚类和凝聚层次聚类。我们看到 *k* -means 只是更一般的期望最大化算法的一个具体应用，我们讨论了它的潜在局限性。此外，我们将 *k* -means 应用于两个特定的应用，即减少图像的调色板和对手写数字进行分类。

在下一章中，我们将回到监督学习的世界，并谈论一些当前最强大的机器学习算法:神经网络和深度学习。**