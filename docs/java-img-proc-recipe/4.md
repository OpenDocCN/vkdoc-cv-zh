# 四、实时视频

到目前为止，这本书一直专注于让读者快速处理图像和生成的图形艺术。您现在应该对介绍的方法非常有信心，并且您有很多想法的空间。

太好了！

我们可以继续扩展和解释 OpenCV 的其他方法，但我们将在第 [4](4.html) 章中做一些其他事情，因为我们切换到实时视频分析，将前几章学到的知识应用到视频流领域。

你可能会问:什么是实时视频分析，我为什么要这么做？OpenCV 使查看视频流和关注视频内容变得轻而易举。例如，现在有多少人在视频流上显示？这个视频里有猫吗？这是一场网球比赛吗，所有问题的根源，今天是晴天吗？

OpenCV 已经为您实现了许多这样的算法，更好的是，Origami 添加了一点甜蜜的糖，所以您可以直接开始，并以一种简单的方式将块放在一起。

在这一章中，我们将从第一个配方开始，它将向您展示为视频流做好准备需要多少东西。

然后，我们转移到更实质性的主题，像人脸识别，背景区分，寻找橙子，最重要的是，身体肥皂。

## 4.1 视频流入门

### 问题

你有图像处理的 Origami 装置；现在，你想知道视频处理的 Origami 设置。

### 解决办法

坏消息是没有额外的项目设置。所以，我们几乎已经可以关闭这个食谱了。

好消息是 Origami 提供了两个功能，但是在使用它们之前，我们将介绍底层处理是如何工作的。

首先，我们将从 origami opencv3.video 包中创建一个 **videocapture** 对象，并用它开始/停止一个流。

第二，既然我们认为这肯定更容易使用，我们将介绍为您做所有事情的函数: **u/simple-cam-window** 。

最后，我们将回顾 **u/cams-window，**它可以轻松地组合来自不同来源的多个流。

### 它是如何工作的

#### 自己动手视频流

你可以跳过食谱中的这一小部分，但是知道幕后是什么实际上是非常有益的。

视频流操作的简单思想始于创建一个 opencv videocapture 对象来访问可用的视频设备。

然后，该对象可以返回一个 mat 对象，就像您到目前为止使用的所有 mat 对象一样。然后可以对 mat 对象进行操作，在最简单的情况下，在屏幕上的一个框架中显示 mat。

Origami 使用类似于 **u/imshow** 的东西来显示视频中的垫子，但是对于第一个例子，让我们简单地使用 u/imshow 来显示垫子。

这里，我们确实需要另一个名称空间: **[opencv3.video :as v]** ，但是稍后您将会看到这一步并不是必需的，只有在直接使用 opencv video 函数时，您才会需要额外的 video 名称空间。

让我们通过下面的代码示例来看看它是如何进行的。

首先，我们创建 videocapture 对象，它可以访问您的主机系统的所有网络摄像头。

然后我们打开 ID 为 0 的相机。这可能是您的环境中的默认设置，但是我们将在后面看到如何使用多个设备。

(def capture (v/new-videocapture)) (.open capture 0)

我们需要一个窗口来显示从设备记录的帧，毫无疑问，我们将创建一个名为 window 的绑定。该窗口将被设置为黑色背景。

(def window  (u/show (new-mat 200 200 CV_8UC3 rgb/black)))

然后，我们创建一个缓冲区来接收视频数据，就像一个普通的 OpenCV mat 一样。

(def buffer (new-mat))

核心视频循环将使用捕获对象上的 **read** 函数将内容复制到缓冲区，然后使用 **u/re-show** 函数在窗口中显示缓冲区。

(dotimes [_ 100]  (.read capture buffer)  (u/re-show window buffer)) At this stage, you should see frames showing up in a window on your screen, as in Figure [4-1](#Fig1).![img/459821_1_En_4_Fig1_HTML.jpg](Images/459821_1_En_4_Fig1_HTML.jpg) Figure 4-1

我最喜欢的沐浴露

最后，当循环结束时，使用捕获对象上的**释放**功能释放网络摄像头。

(.release capture)

这也应该有关闭你的计算机的照相机 LED 的效果。在这个小练习的最后要考虑的一件事是…是的，这是一个标准的 mat 对象，它被用作显示循环中的缓冲区，所以，是的，你可以在显示它之前插入一些文本或颜色转换。

#### 单功能网络摄像头

既然你已经理解了底层的网络摄像头处理是如何完成的，这里有另一个稍微短一点的方法让你得到同样的结果，使用 **u/simple-cam-window** 。

在这一小节中，我们想快速回顾一下如何获取流并使用该函数对其进行操作。

在其最简单的形式中，simple-cam-window 与作为参数的身份函数一起使用。如您所知，identity 接受一个元素并按原样返回它。

(u/simple-cam-window identity)

如果您连接了网络摄像头，这将启动相同的流视频，流的内容显示在一个框架中。

该函数采用单个参数，该参数是在垫子显示在框架内之前应用于垫子的函数。

太好了。我们将在几秒钟后回到它，但是现在，这里是你将发现的:简单地将记录帧转换成不同的颜色图，你可以只使用 **apply-color-map 传递一个匿名函数！**。

(u/simple-cam-window #(apply-color-map! % COLORMAP_HOT)) With the immediate result showing in Figure [4-2](#Fig2).![img/459821_1_En_4_Fig2_HTML.jpg](Images/459821_1_En_4_Fig2_HTML.jpg) Figure 4-2

热身体皂

在第二个版本的 **u/simple-cam-window** 中，您可以指定帧和视频录制的设置，所有这些都是作为第一个参数传递给 simple-cam-window 的简单映射。

例如:

(u/simple-cam-window **{:frame {:color "#ffcc88", :title "video", :width 350, :height 300}**   **:video {:device 0, :width 100, :height 120}}**   identity)

在映射中，视频键指定设备 ID、获取流的设备以及要记录的帧的大小。请注意，如果大小不符合设备的能力，设置将被忽略。

在同一个参数映射中，帧键可以指定参数，如前一章所见，包括背景颜色、标题和窗口大小。

好，太好了；一切都准备好了。让我们玩一会儿。

#### 变换函数

identity 函数接受一个元素并按原样返回它。通过返回 opencv 框架记录的 mat，我们看到了 identity 在第一次使用 cam 时是如何工作的。

Now, say you would like to write a function that

*   拿个垫子

*   以 0.5 为因子调整垫子的大小

*   将颜色贴图更改为冬季

*   将当前日期添加为白色覆盖

以你目前所掌握的知识来看，这并不困难。我们在一个函数 **my-fn 里写一个小 Origami 流水线吧！**进行图像转换:

(defn my-fn![mat]   (-> mat     (u/resize-by 0.5)     (apply-color-map! COLORMAP_WINTER)     (put-text! (str (java.util.Date.)) (new-point 10 50) FONT_HERSHEY_PLAIN 1 rgb/white 1)  ))

请注意，此处流水线返回转换后的 mat。现在让我们在一个静态图像上使用这个新创建的流水线。

(-> "resources/chapter03/ai5.jpg"     imread     my-fn!     u/mat-view) And let’s enjoy a simple winter feline output (Figure [4-3](#Fig3)).![img/459821_1_En_4_Fig3_HTML.jpg](Images/459821_1_En_4_Fig3_HTML.jpg) Figure 4-3

酷猫

然后，如果你在星巴克使用笔记本电脑摄像头，你可以使用新功能 my-fn！通过将它作为一个参数传递给 simple-cam-window。

(u/simple-cam-window my-fn!) Which would give you something like Figure [4-4](#Fig4).![img/459821_1_En_4_Fig4_HTML.jpg](Images/459821_1_En_4_Fig4_HTML.jpg) Figure 4-4

星巴克冰咖啡笔芯

#### 来自同一输入源的两帧或更多帧

当试图从同一个源应用两个或多个函数时，这是一种方便的方法。这实际上只是使用克隆函数来避免与源缓冲区的内存冲突的问题。

这里，我们创建了一个函数，它将缓冲区作为输入，然后连接从同一个缓冲区创建的两个图像。左边的第一个图像将是流的黑白版本，而右边的图像将是缓冲区的翻转版本。

 (u/simple-cam-window     (fn [buffer]     (vconcat! [      (-> buffer          clone          (cvt-color! COLOR_RGB2GRAY)          (cvt-color! COLOR_GRAY2RGB))      (-> buffer clone (flip! -1)) ]))) Note that we use the clone twice for each side of the concatenation (Figure [4-5](#Fig5)).![img/459821_1_En_4_Fig5_HTML.jpg](Images/459821_1_En_4_Fig5_HTML.jpg) Figure 4-5

灰色左，翻转右，但它仍然是身体肥皂

您可以通过任意多次克隆输入缓冲区来进一步推广这个方法；为了突出这一点，下面是另一个在同一个输入缓冲区上应用不同颜色映射三次的例子。

(u/simple-cam-window     (fn [buffer]     (hconcat! [      (-> buffer clone (apply-color-map! COLORMAP_JET))      (-> buffer clone (apply-color-map! COLORMAP_BONE))      (-> buffer clone (apply-color-map! COLORMAP_PARULA))]))) And the result is shown in Figure [4-6](#Fig6).![img/459821_1_En_4_Fig6_HTML.jpg](Images/459821_1_En_4_Fig6_HTML.jpg) Figure 4-6

黑玉，骨头和帕鲁拉，但这仍然是沐浴露

## 4.2 组合多个视频流

### 问题

您尝试从同一个缓冲区创建许多输出，但如果能够插入多个摄像机并将它们的缓冲区组合在一起，那就更好了。

### 解决办法

Origami 附带了一个 u/simple-cam-window 的兄弟函数，名为 **u/cams-window，**，这是一个增强版本，您可以合并来自相同或多个源的多个流。

### 它是如何工作的

**u/cams-window** 是一个获取设备列表的函数，每个设备从一个 ID 定义一个设备，并且通常是一个转换函数。

该函数还采用一个视频函数来连接两个或多个设备输出，最后采用一个帧元素来定义窗口的常用参数，如大小和标题。

(u/cams-window    {:devices [      {:device 0 :width 300 :height 200 :fn identity}      {:device 1 :width 300 :height 200 :fn identity}]     :video { :fn              #(hconcat! [                 (-> %1 (resize! (new-size 300 200)))                 (-> %2 (resize! (new-size 300 200))) ])}       :frame      {:width 650 :height 250 :title "OneOfTheSame"}})

图 [4-7](#Fig7) 显示了两种针对同一种沐浴露的设备，但角度不同。

The left frame takes input from the device with ID 0, and the right frame input from the device with ID 1.![img/459821_1_En_4_Fig7_HTML.jpg](Images/459821_1_En_4_Fig7_HTML.jpg) Figure 4-7

更多人体香皂图片

请注意，即使为每个设备指定了大小，实际上仍然需要调整大小，因为设备可以使用非常特定的高度和宽度组合，因此使用不同的设备可能有点困难。

尽管如此，调整大小！调用合成视频功能并不觉得不合适，之后一切都很顺利。

## 4.3 扭曲视频

### 问题

这个方法是关于使用变换来扭曲视频流的缓冲区，但也是关于实时更新变换。

### 解决办法

扭曲转换本身将使用 opencv 的**get-perspective-transform**从核心名称空间完成。

实时更新将使用 Clojure atom 和软件事务内存来完成，在这里很适合更新进行转换所需的矩阵值，而显示循环正在读取该矩阵的内容，因此总是获得最新的值。

### 它是如何工作的

为了执行透视变换，我们需要一个扭曲矩阵。扭曲矩阵包含在一个原子中，并首先初始化为零。

(def mt      (atom nil))

用于进行变换的扭曲矩阵可以从四个点创建，具有它们在变换之前和之后的位置。

我们将使用 **reset 来更新 atom 值，而不是对本地绑定进行操作！**。

(def points1   [[100 10]    [200 100]    [28 200]    [389 390]]) (def points2   [[70 10]    [200 140]    [20 200]    [389 390]]) (reset! mt   (get-perspective-transform    (u/matrix-to-matofpoint2f points1)    (u/matrix-to-matofpoint2f points2)))

请记住，您仍然可以转储 warp matrix，它是一个常规的 3×3 mat，方法是对它使用一个解引用调用，使用@或 **deref** 。

(dump @mt)

利用前面定义的点，这给出了下面的双精度矩阵。

[1.789337561985906 0.3234215275201738 -94.5799621372129] [0.7803091692375479 1.293303360247406 -78.45137776386103] [0.002543030309135725 -3.045754676722361E-4 1]

现在让我们使用保存在 mt atom 中的矩阵创建一个扭曲垫子的函数。

(defn warp! [ buffer ]   (-> buffer     (warp-perspective! @mt (size buffer ))))

记住这个函数仍然可以应用于标准图像；例如，如果您想要扭曲猫，您可以编写以下 Origami 流水线:

(-> "resources/chapter03/ai5.jpg"     imread     (u/resize-by 0.7)     warp!     u/imshow) And the two cats from before would be warping as in Figure [4-8](#Fig8).![img/459821_1_En_4_Fig8_HTML.jpg](Images/459821_1_En_4_Fig8_HTML.jpg) Figure 4-8

扭曲的猫

现在让我们使用 **warp 将该功能应用于视频流！**作为 u/simple-cam 窗口的参数。

(u/simple-cam-window warp!)

身体皂已经翘了！(图 [4-9](#Fig9)

Obviously, the book is not doing too much to express the difference between a still cat image and the body soap stream , so you can plug in your own stream there.![img/459821_1_En_4_Fig9_HTML.jpg](Images/459821_1_En_4_Fig9_HTML.jpg) Figure 4-9

扭曲的身体肥皂

## 4.4 使用人脸识别

### 问题

虽然 OpenCV 人脸识别功能在静态图片上工作得非常好，但在视频流上工作就不同了，因为要寻找实时显示的移动人脸，以及计算人数等。

### 解决办法

第一步是加载一个分类器:opencv 对象，它将能够找出 mat 上的匹配元素。

使用 origami 函数 **new-cascadeclassifier** 从 xml 定义中加载分类器。

然后，使用该分类器和 mat 调用 **detectMultiScale** 将返回匹配 rect 对象的列表。

然后，这些 rect 对象可以用于用矩形突出显示找到的面，或者用于创建 submat。

### 它是如何工作的

完成这项工作不需要额外的 Clojure 名称空间，因为 new-cascadeclassifier 函数已经在核心名称空间中。

如果 xml 文件在文件系统上，那么可以用

(def detector   (new-cascadeclassifier     "resources/lbpcascade_frontalface.xml"))

如果 xml 作为资源存储在 jar 文件中，那么可以用

(def detector   (new-cascadeclassifier     (.getPath (clojure.java.io/resource "lbpcascade_frontalface.xml"))))

需要绘制由分类器找到的矩形对象。分类器的 detect 函数返回一个矩形列表，所以让我们编写一个函数，简单地遍历 rect 对象列表，并在每个 rect 上绘制一个蓝色的边框。

(defn draw-rects! [buffer rects]  (doseq [rect (.toArray rects)]   (rectangle    buffer    (new-point (.-x rect) (.-y rect))    (new-point (+ (.-width rect) (.-x rect)) (+ (.-height rect) (.-y rect)))    rgb/blue    5))    buffer)

然后让我们定义第二个函数， **find-faces！** **，**调用分类器上的 detectMultiScale 方法并使用 draw-rects 绘制矩形！前面定义的函数。

(defn find-faces![buffer]   (let [rects (new-matofrect)]     (.detectMultiScale detector buffer rects)     (-> buffer         (draw-rects! rects)         (u/resize-by 0.7))))

我们又把所有的积木都放在这里了，现在只需要简单地调用 **find-faces 就可以了！**通过**u/简单凸轮窗口**。

(u/simple-cam-window find-faces!) And if you find yourself in Starbucks one morning on a terrace, the image could be something like Figure [4-10](#Fig10).![img/459821_1_En_4_Fig10_HTML.jpg](Images/459821_1_En_4_Fig10_HTML.jpg) Figure 4-10

安静令人印象深刻的早晨咖啡脸

抽屉！函数实际上可以是任何东西，因为你可以访问一个缓冲对象。

比如这个第二版的 **draw-rects！**对找到的面的矩形创建的子贴图应用不同的颜色贴图。

(defn draw-rects! [buffer rects]    (doseq [r (.toArray rects)]      (-> buffer       (submat r)       (apply-color-map! COLORMAP_COOL)       (copy-to (submat buffer r))))      (put-text! buffer (str (count (.toArray rects) ) )       (new-point 30 100) FONT_HERSHEY_PLAIN 5 rgb/magenta-2 2)) And reusing the created building blocks, this gives the cool face from Figure [4-11](#Fig11).![img/459821_1_En_4_Fig11_HTML.jpg](Images/459821_1_En_4_Fig11_HTML.jpg) Figure 4-11

凉爽的早晨咖啡脸

这最后一个画人脸的例子采用第一个找到的人脸，在视频流的右边画一个大特写。

(defn draw-rects! [buffer rects]   (if (> (count (.toArray rects)) 0)     (let [r (first (.toArray rects))           s (-> buffer clone (submat r) (resize! (.size buffer)))]           (hconcat! [buffer s]))     buffer)) Obviously, Figure [4-12](#Fig12) will quickly get you convinced that this should really only be used for house BBQs, in order to show everyone who has been eating all the meat.![img/459821_1_En_4_Fig12_HTML.jpg](Images/459821_1_En_4_Fig12_HTML.jpg) Figure 4-12

同一视频窗口上的概览和特写

## 4.5 与基础图像的差异

### 问题

您想要获取一个 mat 映像，将其定义为一个基础映像，并发现对该基础映像所做的更改。

### 解决办法

这是一个非常短的配方，但它本身对理解后面更复杂的运动配方很有帮助。

为了创建一个图像和它的基底的 diff，我们在这里首先创建两段视频回调代码:一个将背景图片存储在 Clojure 原子中，另一个将使用该基底原子进行 diff。

然后，结果的灰色版本将通过简单的阈值函数，以准备用于附加形状识别和/或进一步处理的结果。

### 它是如何工作的

为了计算一个图像与另一个图像的差异，你需要两个垫子:一个用于基底，另一个是更新版本，其中有(我们希望)新的额外形状。

我们首先定义 Clojure 原子，并启动一个视频流来创建一个引用背景图像的原子。

只要 cam-window 在运行，来自视频流的最新缓冲垫就会存储在 atom 中。

(def base-image (atom nil)) (u/simple-cam-window   (fn [buffer] (swap! base-image (fn[_] buffer) ) ))

一旦你对背景满意了，你可以停止 cam 窗口，用 imshow 和 atom 的一个 deref 版本检查当前存储的图片背景。

(u/imshow @base-image) This time, the image is a typical one of a busy home workplace (Figure [4-13](#Fig13)).![img/459821_1_En_4_Fig13_HTML.jpg](Images/459821_1_En_4_Fig13_HTML.jpg) Figure 4-13

心形和扬声器

现在，下一步是定义一个新的流回调来使用 simple-cam-window，它将与 Clojure 原子中存储的 mat 不同。

diff 是通过 opencv 函数 **absdiff** 完成的，它需要三个 mat，即 diff 的两个输入和输出。

(defn diff-with-bg [buffer]    (let[ output (new-mat)]      (absdiff buffer @base-image output)      output)) (u/simple-cam-window diff-with-bg)

显然，在开始第二个流和引入新的形状之前，您应该停止第一个记录流。

This would give something like Figure [4-14](#Fig14), where the added body soap is clearly being recognized.![img/459821_1_En_4_Fig14_HTML.jpg](Images/459821_1_En_4_Fig14_HTML.jpg) Figure 4-14

办公室里的沐浴露！

现在通常，下一步是清理显示在背景顶部的形状，方法是将差异贴图变为灰色，并在模糊后应用非常高的阈值。

; diff in gray (defn diff-in-gray [buffer]  (-> buffer   clone   (cvt-color! COLOR_RGB2GRAY)   (median-blur! 7)   (threshold! 10 255 1)))

对于同一个缓冲区，我们有两个处理函数，在 Clojure 中，将它们与 **comp** 结合起来实际上是相当容易的，所以现在让我们尝试一下。

记住 **comp** 从右到左组合函数，意味着第一个被应用的函数是最右边的一个。

(u/simple-cam-window (comp diff-in-gray diff-with-bg )) See the composition result and the shape of the body soap showing in Figure [4-15](#Fig15).![img/459821_1_En_4_Fig15_HTML.jpg](Images/459821_1_En_4_Fig15_HTML.jpg) Figure 4-15

添加的形状有助于更多处理

在这里，您可以编译所有的步骤，从前面添加的 shape mat 创建一个简单的遮罩，并使用该遮罩来突出显示不同的部分。

所有这些都不奇怪，除了按位非！来电，总结在亮点——新！功能。

(defn highlight-new! [buffer]  (let [output (u/mat-from buffer) w (-> buffer   clone   diff-with-bg                                           (cvt-color! COLOR_RGB2GRAY)   (median-blur! 7)   (threshold! 10 255 1)   (bitwise-not!))]  (set-to output rgb/black)  (copy-to buffer output w)  output)) And the body soap output shows in Figure [4-16](#Fig16).![img/459821_1_En_4_Fig16_HTML.jpg](Images/459821_1_En_4_Fig16_HTML.jpg) Figure 4-16

回到沐浴露

这些溪流是在凌晨 3 点左右的严重时差中拍摄的，因此光线条件会在身体肥皂的底部产生一点噪音，但你可以通过更新遮罩以不包括桌子木材的颜色来尝试消除这种噪音。轮到你了！

## 4.6 寻找运动

### 问题

您希望识别并突出显示视频流中的移动和移动形状。

### 解决办法

在清理缓冲区之后，我们从累加缓冲区的浮点值开始。这是通过函数**累加加权**完成的。

然后，我们在缓冲区的灰色版本和计算的平均 mat 之间做一个 diff，我们检索一个 delta 的 mask mat，就像在前面的配方中快速呈现的那样。

最后，我们在 delta 上应用一个阈值，用一点膨胀清理结果，并将 mat 转换回彩色模式以显示在屏幕上。

这其实比听起来容易！

### 它是如何工作的

在这里，我们想在垫子上展示运动产生的三角洲。

#### 在黑白中寻找运动

第一步是取一个缓冲区，创建一个干净的(通过模糊)灰色版本。

我们对展示这张垫子不感兴趣，而只是对它进行算术运算；我们将 mat 转换为 32 位浮点 mat，或者用 opencv 语言 **CV_32F** 。

(defn gray-clean! [buffer]   (-> buffer       clone       (cvt-color! COLOR_BGR2GRAY)       (gaussian-blur! (new-size 3 3) 0)       (convert-to! CV_32F)))

此功能将用于准备灰色版本的垫子。现在让我们来计算累计平均值以及平均值和最近缓冲区之间的差值。

我们将创建另一个函数， **find-movement** ，它将以黑白方式突出显示图片中最近的移动。

该函数将获得一个 Clojure 原子， **avg** ，作为跟踪视频传入 mat 对象平均值的参数。第二个参数是传递给回调的常用缓冲垫。该功能将显示帧增量。

在第一个 if 开关中，我们确保存储在 atom 中的 average mat 用来自传入流的适当值进行初始化。

然后使用 absdiff 计算 diff，我们在其上应用一个短的 threshold-explain-CVT-color 流水线来直接显示运动。

(defn find-movement [ avg buffer]   (let [gray (gray-clean! buffer) frame-delta (new-mat)]    (if (nil? @avg)     (reset! avg gray))    ; compute the absolute diff on the weighted average    (accumulate-weighted gray @avg 0.05 (new-mat))    (absdiff gray @avg frame-delta)    ; apply threshold and convert back to RGB for display    (-> frame-delta     (threshold! 35 255 THRESH_BINARY)     (dilate! (new-mat))     (cvt-color! COLOR_GRAY2RGB)     (u/resize-by 0.8))))

我们最后定义一个函数，用一个内嵌的 Clojure 原子包装 find-movement 函数。该原子将包含 mat 对象的平均值。

(def find-movements!   (partial find-movement (atom nil)))

是时候用 u/simple-cam-window 来实现这些功能了。

(u/simple-cam-window find-movements!) This is shown in Figure [4-17](#Fig17).![img/459821_1_En_4_Fig17_HTML.jpg](Images/459821_1_En_4_Fig17_HTML.jpg) Figure 4-17

检测到移动！

我们想在这里显示运动，但因为打印所需的黑色墨水量会吓到出版商，所以让我们添加一个按位运算来进行黑白转换，看看实时进展如何。

让我们用一个按位非来更新查找移动函数！呼叫框架-三角垫。在此之前，我们需要使用 opencv 的 convert-to 将矩阵转换回我们可以处理的内容。函数，类型 target CV_8UC3，这是我们通常使用的。

(defn find-movement [ avg buffer]   (let [gray (gray-clean! buffer) frame-delta (new-mat)]    ...    (-> frame-delta     (threshold! 35 255 THRESH_BINARY)     (dilate! (new-mat))     (convert-to! CV_8UC3)     (bitwise-not!)     (cvt-color! COLOR_GRAY2RGB)     (u/resize-by 0.8)))) Good; let’s call simple-cam again. Wow. Figure [4-18](#Fig18) now looks a bit scary.![img/459821_1_En_4_Fig18_HTML.jpg](Images/459821_1_En_4_Fig18_HTML.jpg) Figure 4-18

可怕的黑白运动

And if you stop getting agitated in front of your computer, the movement highlights are stabilizing and slowly moving to a fully white mat, as shown in the progression of Figure [4-19](#Fig19).![img/459821_1_En_4_Fig19_HTML.jpg](Images/459821_1_En_4_Fig19_HTML.jpg) Figure 4-19

稳定运动

#### 查找并绘制轮廓

在这个阶段，很容易找到并绘制轮廓来突出显示原始彩色缓冲区上的运动。

让我们来看看你做的漂亮的运动垫的轮廓。

在查找移动函数中增加了几行，特别是在 delta mat 上查找轮廓和在 color mat 上绘图。

在前一章中，您已经看到了所有这些寻找轮廓的动作，所以让我们来看看更新后的代码。

(defn find-movement [ avg buffer]   (let [ gray (base-gray! buffer)          frame-delta (new-mat)          **contours (new-arraylist)**]     (if (nil? @avg)       (reset! avg gray))     (accumulate-weighted gray @avg 0.05 (new-mat))     (absdiff gray @avg frame-delta)     (-> frame-delta      (threshold! 35 255 THRESH_BINARY)      (dilate! (new-mat))      (convert-to! CV_8UC3)      **(find-contours contours (new-mat) RETR_EXTERNAL CHAIN_APPROX_SIMPLE))**     (-> frame-delta         (bitwise-not!)      (cvt-color! COLOR_GRAY2RGB)      (u/resize-by 0.8))     **(-> buffer**      ; (u/draw-contours-with-rect! contours )      **(u/draw-contours-with-line! contours)**      **(u/resize-by 0.8))**     **(hconcat! [frame-delta buffer])** )) Calling this new version of the find-movement function gives something like Figure [4-20](#Fig20), but you can probably be way more creative from there.![img/459821_1_En_4_Fig20_HTML.jpg](Images/459821_1_En_4_Fig20_HTML.jpg) Figure 4-20

用蓝色突出显示移动部件

## 4.7 使用 Grabcut 将前景与背景分离

### 问题

Grabcut 是另一种 opencv 方法，可用于将图像的前景与背景分开。但它能像在视频流上一样实时使用吗？

### 解决办法

确实有一个抓取-剪切功能，可以轻松地将正面与背景分开。这个函数只需要一点点的理解就可以看到它运行所需要的不同的遮罩，所以我们将首先关注于理解静止图像上的事情是如何工作的。

然后，我们将继续讨论实时流解决方案。这将很快导致速度问题，因为抓取-剪切比实时处理花费更多的时间。

因此，我们将使用一个小技巧，通过调低工作区的分辨率来将 grab-cut 所用的时间降到最低；然后，我们将在执行其余处理时使用全分辨率，产生一个 grabcut。

### 它是如何工作的

#### 在静止图像上

这里我们想调用 grabcut，将一个*深度*的图层从其他图层中分离出来。

grabcut 的想法是准备在输入图片上使用矩形或遮罩，并将其传递给 grabcut 函数。

存储在单个输出掩膜中的结果将包含一组 1.0、2.0 或 3.0 标量值，具体取决于 grabcut 认为哪些是每个不同图层的一部分。

然后我们使用 opencv **比较这个遮罩和我们想要检索的层的标量值的另一个固定的 1×1 遮罩上的**。我们只为感兴趣的层获得一个掩模。

最后，我们使用步骤 2 中创建的蒙版在输出垫上复制原始图像。

准备好了吗？让我们举一个猫的例子。

首先，我们加载一个我们非常喜欢的猫图片，并将其转换为一个合适的工作大小的 mat 对象。

(def source "resources/chapter03/ai6.jpg") (def img (-> source imread (u/resize-by 0.5))) The loaded cat picture is shown in Figure [4-21](#Fig21).![img/459821_1_En_4_Fig21_HTML.jpg](Images/459821_1_En_4_Fig21_HTML.jpg) Figure 4-21

给你一个猫吻

然后，我们定义一个 **mask** mat，它将接收 grabcut 调用的输出，即关于图层信息的每像素信息。

我们还为感兴趣的区域(ROI)定义了一个矩形，我们希望在这个矩形中执行 grabcut，这里几乎是完整的图片，大部分只是删除了边界。

(def mask (new-mat)) (def rect   (new-rect     (new-point 10 10)     (new-size (- (.width img) 30) (- (.height img) 30 ))))

现在我们有了 grabcut 所需的所有输入，让我们用掩码、ROI 和 **grabcut 初始化参数**来调用它，这里是 GC_INIT_WITH_RECT。另一个可用的方法是使用 **GC_INIT_WITH_MASK** ，正如您可能已经猜到的，它是用 MASK 而不是 rect 初始化的。

(grab-cut img mask rect (new-mat) (new-mat) 11 GC_INIT_WITH_RECT)

Grabcut 已被调用。为了了解输出中检索到的内容，让我们快速查看一下 mask 的一个小 submat 上的矩阵内容。

(dump (submat mask (new-rect (new-point 10 10) (new-size 5 5))))

如果你亲自尝试，你会看到这样的价值观

[2 2 2 2 2] [2 2 2 2 2] [2 2 2 2 2] [2 2 2 2 2] [2 2 2 2 2]

mat 中其他地方的另一个 submat 转储给出了不同的结果:

(dump (submat mask (new-rect (new-point 150 150) (new-size 5 5))))

反过来，这给了

[3 3 3 3 3] [3 3 3 3 3] [3 3 3 3 3] [3 3 3 3 3] [3 3 3 3 3]

我们可以从这个不同的矩阵中猜测出层是不同的。

这里的想法是检索由所有相同值组成的遮罩，所以现在让我们从第 3 层中包含的所有像素创建一个遮罩，这意味着它们由 3.0 值组成。

我们称之为 fg-mask，前景遮罩。

(def fg-mask (clone mask)) (def source1 (new-mat 1 1 CV_8U (new-scalar 3.0))) (compare mask source1 fg-mask CMP_EQ) (u/mat-view fg-mask) The cat foreground mask is shown in Figure [4-22](#Fig22).![img/459821_1_En_4_Fig22_HTML.jpg](Images/459821_1_En_4_Fig22_HTML.jpg) Figure 4-22

前景遮罩

然后，我们可以使用复制到原始输入图像，并在与输入相同大小的新黑色垫上使用 fg-mask。

(def fg_foreground (-> img (u/mat-from)  (set-to rgb/black))) (copy-to img fg_foreground fg-mask) (u/mat-view fg_foreground) And we get the mat of Figure [4-23](#Fig23).![img/459821_1_En_4_Fig23_HTML.jpg](Images/459821_1_En_4_Fig23_HTML.jpg) Figure 4-23

只有猫吻的前景

请注意，我们是如何得到两只小猫相互交配的近似结果的，但总的来说，结果是相当有效的。

在继续之前，让我们通过聚焦在标量值为 2.0 的层上来快速检索互补蒙版，即背景蒙版。

首先，我们再次创建一个掩码来接收输出，这次是 **bg-mask** 。

(def bg-mask (clone mask)) (def source2 (new-mat 1 1 CV_8U (new-scalar 2.0))) (compare mask source2 bg-mask CMP_EQ) (u/mat-view bg-mask) The result for the background mask is shown in Figure [4-24](#Fig24).![img/459821_1_En_4_Fig24_HTML.jpg](Images/459821_1_En_4_Fig24_HTML.jpg) Figure 4-24

背景遮罩

然后，简单地复制一个类似的前景。

(def bg_foreground (-> img (u/mat-from)  (set-to (new-scalar 0 0 0)))) (copy-to img bg_foreground bg-mask) (u/mat-view bg_foreground) And the result is shown in Figure [4-25](#Fig25).![img/459821_1_En_4_Fig25_HTML.jpg](Images/459821_1_En_4_Fig25_HTML.jpg) Figure 4-25

背景层的 Mat

既然你已经看到了如何分离静止图像上的不同层，让我们继续视频流。

#### 在视频流上

您可能已经注意到，前面示例中的 grabcut 步骤非常慢，主要是因为为了实现不同层的清晰分离而进行了大量繁重的计算。但是有多糟糕呢？

让我们快速尝试一下第一个哑版本的实时 grabcut。

我们将调用这个函数**在前面-** **慢**，基本上只是在一个函数中编译我们刚刚在静态例子中看到的步骤。

(defn in-front-slow [buffer]     (let [         img (clone buffer)         rect (new-rect           (new-point 5 5)           (new-size (- (.width buffer) 5) (- (.height buffer) 5 )))         mask (new-mat)         pfg-mask (new-mat)         source1 (new-mat 1 1 CV_8U (new-scalar 3.0))         pfg_foreground (-> buffer (u/mat-from)  (set-to rgb/black))]     (grab-cut img mask rect (new-mat) (new-mat) 7 GC_INIT_WITH_RECT)     (compare mask source1 pfg-mask CMP_EQ)     (copy-to buffer pfg_foreground pfg-mask)     pfg_foreground))

然后，让我们使用这个函数作为对我们现在熟悉的 **u/simple-cam-window** 的回调。

(u/simple-cam-window in-front-slow) This slowly gives the output seen in Figure [4-26](#Fig26).![img/459821_1_En_4_Fig26_HTML.jpg](Images/459821_1_En_4_Fig26_HTML.jpg) Figure 4-26

慢点，慢点，慢点

您很快就会意识到，这不像在视频流中那样非常有用。

这里的技巧实际上是降低输入缓冲区的分辨率，在分辨率较低的 mat 上进行 grabcut，并获得 grabcut 掩码。然后，使用全尺寸图片和从 grabcut 获取的低分辨率蒙版进行复制。

这一次，我们将创建一个**前置**函数，这将是前面的一个略微更新的版本，但是现在包括一个围绕 grabcut 调用的 pyr-down-pyr-up 舞蹈(图 [4-27](#Fig27) )。

为了使这更容易，我们将设置舞蹈的迭代次数作为回调的参数。

(defn in-front [resolution-factor buffer]     (let [         img (clone buffer)         rect (new-rect           (new-point 5 5)           (new-size (- (.width buffer) 5) (- (.height buffer) 5 )))         mask (new-mat)         pfg-mask (new-mat)         source1 (new-mat 1 1 CV_8U (new-scalar 3.0))         pfg_foreground (-> buffer (u/mat-from)  (set-to (new-scalar 0 0 0)))]     **(dotimes [_ resolution-factor] (pyr-down! img))**     (grab-cut img mask rect (new-mat) (new-mat) 7 GC_INIT_WITH_RECT)     **(dotimes [_ resolution-factor] (pyr-up! mask))**     (compare mask source1 pfg-mask CMP_EQ)     (copy-to buffer pfg_foreground pfg-mask)     pfg_foreground))

然后，用这个新的回调函数调用 simple-cam-window。

(u/simple-cam-window (partial in-front 2))

仅仅通过阅读是很难获得速度感的，所以一定要在本地尝试一下。

Usually, a factor of 2 for the resolution-down dance is enough, but it depends on both your video hardware and the speed of the underlying processor.![img/459821_1_En_4_Fig27_HTML.jpg](Images/459821_1_En_4_Fig27_HTML.jpg) Figure 4-27

想多快就多快，宝贝

## 4.8 实时寻找橙子

### 问题

你想检测和跟踪视频流中的桔子。它也可以是一个柠檬，但是作者用完了柠檬，所以我们将使用一个橙子。

### 解决办法

在这里，我们将使用你以前见过的技术，像**霍夫圆**或**寻找轮廓**，并将它们应用于实时流。我们将在实时流上绘制移动的橙子的形状。

对于这两种解决方案，您可能还记得缓冲区需要一些小的预处理来检测橙色。这里，为了简单起见，我们将在 hsv 颜色空间中进行简单的**范围内**处理。

### 它是如何工作的

#### 使用霍夫圆

首先，我们将通过拍摄橙子的一张照片来集中寻找合适的 hsv 范围。

First, let’s put the orange on the table (Figure [4-28](#Fig28)).![img/459821_1_En_4_Fig28_HTML.jpg](Images/459821_1_En_4_Fig28_HTML.jpg) Figure 4-28

餐桌上的橘子，法国安纳西

我们首先切换到 hsv 颜色空间，然后应用范围内函数，最后将找到的橙色形状放大一点，以便更容易进行霍夫圆调用。

在 Origami 艺术中，这给了

(def hsv (-> img clone (cvt-color! COLOR_RGB2HSV))) (def thresh-image (new-mat)) (in-range hsv (new-scalar 70 100 100) (new-scalar 103 255 255) thresh-image) (dotimes [_ 1]  (dilate! thresh-image (new-mat)))

现在，你会记得如何从第 [3](3.html) 章开始做霍夫循环，所以这里不需要花太多时间。这一部分最重要的是要有合适的半径范围，这里我们用 10-50 像素的直径来识别橙色。

(def circles (new-mat)) (def minRadius 10) (def maxRadius 50) (hough-circles thresh-image circles CV_HOUGH_GRADIENT 1 minRadius 120 15 minRadius maxRadius)

在这个阶段，你应该只有一个橙色的匹配圆。这一步非常重要，直到找到一个圆。

作为检查，打印圆形垫应得到 1×1 垫，如下所示:

#object[org.opencv.core.Mat 0x3547aa31 Mat [ 1*1*CV_32FC3, isCont=true, isSubmat=false, nativeObj=0x7ff097ca7460, dataAddr=0x7ff097c4b980 ]]

一旦你把垫子钉好了，让我们在原图上画一个粉红色的圆圈(图 [4-29](#Fig29) )。

(def output (clone img)) (dotimes [i (.cols circles)]   (let [ circle (.get circles 0 i) x (nth circle 0) y (nth circle 1) r (nth circle 2)  p (new-point x y)]   (opencv3.core/circle output p (int r) color/ color/magenta- 3))) ![img/459821_1_En_4_Fig29_HTML.jpg](Images/459821_1_En_4_Fig29_HTML.jpg) Figure 4-29

橙色和洋红色

所有的东西都在那里，所以让我们把我们的发现作为一个单一的函数来处理来自视频流的缓冲区；我们称这个函数为 my-orange！，是前面步骤的回顾。

(defn my-orange! [img]   (u/resize-by img 0.5)   (let [ hsv (-> img clone (cvt-color! COLOR_RGB2HSV))          thresh-image (new-mat)          circles (new-mat)          minRadius 10          maxRadius 50          output (clone img)] (in-range hsv (new-scalar 70 100 100) (new-scalar 103 255 255) thresh-image) (dotimes [_ 1]  (dilate! thresh-image (new-mat))) (hough-circles thresh-image circles CV_HOUGH_GRADIENT 1 minRadius 120 15 minRadius maxRadius) (dotimes [i (.cols circles)]   (let [ circle (.get circles 0 0) x (nth circle 0) y (nth circle 1) r (nth circle 2)  p (new-point x y)]   (opencv3.core/circle output p (int r) color/magenta- 3))) output))

现在只需再次将回调函数传递给简单的 cam 窗口。

(u/simple-cam-window my-orange!) Figures [4-30](#Fig30) and [4-31](#Fig31) show how the orange is found properly, even in low-light conditions. Winter in the French Alps after a storm did indeed make the evening light, and everything under it, a bit orange.![img/459821_1_En_4_Fig30_HTML.jpg](Images/459821_1_En_4_Fig30_HTML.jpg) Figure 4-30

打印机上的橙色

![img/459821_1_En_4_Fig31_HTML.jpg](Images/459821_1_En_4_Fig31_HTML.jpg) Figure 4-31

梅和橘子

#### 使用查找轮廓

不是寻找一个完美的圆，你可能会寻找一个稍微扭曲的形状，这是当使用查找轮廓实际上比霍夫圆给出更好的结果。

这里，我们结合几分钟前发现的相同 hsv 范围来选择橙色，并应用第 [3](3.html) 章中的轮廓查找技术。

寻找我的橘子！回调带回了熟悉的查找轮廓和绘制轮廓函数调用。请注意，只有当找到的形状比预期的最小橙子大时，我们才绘制它们的轮廓。

(defn find-my-orange! [img ]  (let[ hsv (-> img clone (cvt-color! COLOR_RGB2HSV))       thresh-image (new-mat)       contours (new-arraylist)       output (clone img)]  (in-range hsv (new-scalar 70 100 100) (new-scalar 103 255 255) thresh-image)  (find-contours   thresh-image   contours   (new-mat)  ; mask   RETR_LIST   CHAIN_APPROX_SIMPLE)  (dotimes [ci (.size contours)]  (if (> (contour-area (.get contours ci)) 100 )   (draw-contours output contours ci color/pink-1 FILLED)))   output)) Giving this callback to simple-cam-window shows Mei playing around with a pink-colored orange in Figure [4-32](#Fig32).![img/459821_1_En_4_Fig32_HTML.jpg](Images/459821_1_En_4_Fig32_HTML.jpg) Figure 4-32

梅和粉橙，在附近的剧院演出

## 4.9 在视频流中查找图像

### 问题

您希望在流中找到图像的精确副本。

### 解决办法

OpenCV 附带了您可以使用的特性检测功能。不幸的是，这些特性大多是面向 Java 的。

这个菜谱将展示如何在 Java 和 Origami 之间架起桥梁，以及使用 Clojure 如何通过减少样板代码有所帮助。

Here we will use three main OpenCV objects :

*   特征检测器，

*   DescriptorExtractor，

*   描述符匹配器。

特征提取通过使用特征检测器找到输入图片和待发现图像的关键点来工作。然后，使用描述符提取器从两组点中的每一组计算描述符。

一旦有了描述符，就可以将这些描述符作为输入传递给描述符匹配器，描述符匹配器给出一组匹配结果，每个匹配都通过一个距离属性给出一个分数。

然后，我们最终可以筛选出最相关的点，并将它们画在流上。

代码清单比通常要长一点，但是让我们把最后一个方法也用在您的机器上吧！

### 它是如何工作的

在这个例子中，我们将在静态图像和实时图像中寻找我最喜欢的沐浴露，桉树香水。

Figure [4-33](#Fig33) shows the concerned body soap.![img/459821_1_En_4_Fig33_HTML.jpg](Images/459821_1_En_4_Fig33_HTML.jpg) Figure 4-33

小马赛人

#### 静止图像

The first test is to be able to find the body soap in a simple still picture, like the one in Figure [4-34](#Fig34).![img/459821_1_En_4_Fig34_HTML.jpg](Images/459821_1_En_4_Fig34_HTML.jpg) Figure 4-34

卡门，我的沐浴露在哪里？

首先，我们还需要几个 Java 对象导入，即检测器和提取器，我们将在进行任何处理之前直接初始化它们。

(ns wandering-moss   (:require     [opencv3.core :refer :all]     [opencv3.utils :as u])   (:import     [org.opencv.features2d Features2d DescriptorExtractor DescriptorMatcher FeatureDetector])) (def detector (FeatureDetector/create FeatureDetector/AKAZE)) (def extractor  (DescriptorExtractor/create DescriptorExtractor/AKAZE))

基本设置完成；然后，我们通过一个短的 Origami 流水线加载人体肥皂背景，并要求检测器检测其上的点。

(def original   (-> "resources/chapter04/bodysoap_bg.png" imread (u/resize-by 0.3))) (def mat1 (clone original)) (def points1 (new-matofkeypoint)) (.detect detector mat1 points1)

接下来的步骤并不是必须的，但是画出找到的关键点可以让我们知道匹配者认为重要的点在哪里。

(def show-keypoints1 (new-mat)) (Features2d/drawKeypoints mat1 points1 show-keypoints1 (new-scalar 255 0 0) 0) (u/mat-view show-keypoints1) This gives a bunch of blue circles, as shown in Figure [4-35](#Fig35).![img/459821_1_En_4_Fig35_HTML.jpg](Images/459821_1_En_4_Fig35_HTML.jpg) Figure 4-35

沐浴露背景要点

当然，在检索关键点之前清理和移除缺陷可能是有用的，但是让我们检查一下匹配是如何在 raw mat 上工作的。

注意点的强度在身体肥皂本身上已经相当强了。

我们现在对仅含沐浴露的垫子重复同样的步骤。

(def mat2   (-> "resources/chapter04/bodysoap.png" imread (u/resize-by 0.3))) (def points2 (new-matofkeypoint)) (.detect detector mat2 points2)

同样，这个绘图点部分不是必需的，但它有助于更好地理解正在发生的事情。

(def show-keypoints2 (new-mat)) (Features2d/drawKeypoints mat2 points2 show-keypoints2 (new-scalar 255 0 0) 0) (u/mat-view show-keypoints2) The detector result is in Figure [4-36](#Fig36), and again, the keypoints look to be focused on the label of the body soap.![img/459821_1_En_4_Fig36_HTML.jpg](Images/459821_1_En_4_Fig36_HTML.jpg) Figure 4-36

香皂的检测结果

下一步是提取两个特征集，然后用于匹配器。

这只是用上一步中找到的点集在提取器上调用 compute 的问题。

(def desc1 (new-mat)) (.compute extractor mat1 points1 desc1) (def desc2 (new-mat)) (.compute extractor mat2 points2 desc2)

现在，进入匹配步骤。我们通过 DescriptorMatcher 创建一个匹配器，并给它一个找出匹配的方法。

在这种情况下，强力总是寻找解决方案的推荐方法。尝试每一种解决方案，看看是否有匹配的。

(def matcher   (DescriptorMatcher/create DescriptorMatcher/BRUTEFORCE_HAMMINGLUT)) (def matches (new-matofdmatch)) (.match matcher desc1 desc2 matches)

正如解决方案摘要中所述，每个匹配都是通过其**距离**值来评定的。

如果打印出来，每个匹配看起来如下所示:

#object[org.opencv.core.DMatch 0x38dedaa8 "DMatch [queryIdx=0, trainIdx=82, imgIdx=0, distance=136.0]"]

对于距离值，匹配本身的分数通常显示为 0 到 300 之间的值。

所以现在，让我们创建一个快速的 Clojure 函数来排序和过滤好的匹配。这可以简单地通过过滤它们的距离属性来实现。我们将过滤低于 50 的匹配。根据录制的质量，您可以根据需要减少或增加该值。

(defn best-n-dmatches2[dmatches]   (new-matofdmatch     (into-array org.opencv.core.DMatch       (filter #(< (.-distance %) 50) (.toArray dmatches)))))

**draw-matches** 方法是一场编码噩梦，但它可以被看作是 OpenCV 中噩梦般的 drawMatches Java 方法的包装。

我们通常使用 Java interop 和对每个参数的一些清理来传递参数。我们还创建了更大的输出 mat，这样我们可以将背景图片和人体肥皂放在同一个 mat 上。

(defn draw-matches [_mat1 _points1 _mat2 _points2 _matches]   (let[ output (new-mat           (* 2 (.rows _mat1))           (* 2 (.cols _mat1))           (.type _mat1))         _sorted-matches (best-n-dmatches2 _matches)]     (Features2d/drawMatches               _mat1               _points1               _mat2               _points2               _sorted-matches               output               (new-scalar 255 0 0)               (new-scalar 0 0 255)               (new-matofbyte)               Features2d/NOT_DRAW_SINGLE_POINTS)       output))

现在，有了所有这些，我们可以使用前面的函数绘制匹配器找到的匹配。

我们将第一个和第二个垫子，以及它们各自找到的关键点和匹配集传递给它。

(u/mat-view   (draw-matches mat1 points1 mat2 points2 matches)) This, surprisingly after all the obscure coding, works very well, as shown in Figure [4-37](#Fig37).![img/459821_1_En_4_Fig37_HTML.jpg](Images/459821_1_En_4_Fig37_HTML.jpg) Figure 4-37

绘画比赛

#### 视频流

与你刚刚经历的相比，视频流版本会让你感觉像呼吸了一口新鲜空气。

我们将创造一个**我的身体在哪里的肥皂！**函数将重用前面定义的匹配器，并在缓冲垫上的流回调中运行检测器、提取器和**匹配**。

之前定义的 draw-matches 函数也被重用来绘制实时流上的匹配。

(defn where-is-my-body-soap! [buffer]   (let[ mat1 (clone buffer)         points1 (new-matofkeypoint)         desc1 (new-mat)         matches (new-matofdmatch)]    (.detect detector mat1 points1)    (.compute extractor mat1 points1 desc1)    (.match matcher desc1 desc2 matches)    (draw-matches mat1 points1 mat2 points2 matches)))

你可以用这个回调函数来调用 simple-cam-window，但是……啊！似乎梅在配方特征检测可以运行之前已经找到了沐浴露！

Figure [4-38](#Fig38) shows both on the video stream.![img/459821_1_En_4_Fig38_HTML.jpg](Images/459821_1_En_4_Fig38_HTML.jpg) Figure 4-38

谢谢你找到沐浴露，梅！

这使得这份食谱，这一章，这本书的卑微的结束。我们真的希望这给了你很多想法，让你通过玩 Origami 框架来尝试，并为你的创作带来光明。

For now, “Hello Goodnight”:

> *搜索天空*
> 
> *我发誓我看到影子* *坠落*
> 
> *可能是幻觉*
> 
> *一声暗藏的警告*
> 
> 名声将永远让我欲罢不能
> 
> *想要*
> 
> *好了，没事了*
> 
> *我一直很好*
> 
> *你好你好晚安*
> 
> [妈妈枪](https://muzikum.eu/en/120-15939/mamas-gun/biography.html)“你好晚安”