# 7.斯奎泽尼

在接下来的几章中，我们将探讨专为运行在移动设备(主要是手机)上而设计的卷积神经网络。许多研究已经进入使用越来越大的计算机集群来构建更复杂的模型，以尝试和提高 ImageNet 问题的准确性。手机/边缘设备是机器学习的一个领域，尚未被深入探索，但在我看来极其重要。我们的直接目标是让设备在现实世界的设备上工作，但对我来说，特别有趣的是，在寻找降低高端方法的复杂性以实现更简单的方法的过程中，我们可以发现允许我们建立更大网络的技术。

基于上一章中瓶颈层的概念，我们将牺牲一些网络结果的质量来生产 SqueezeNet，这是一种可以在计算能力有限的设备上运行的微型神经网络，如电话。

## 斯奎泽尼

几年前，康奈尔大学发表了一篇讨论 SqueezeNet 和 AlexNet 级精度的论文。

> SqueezeNet: AlexNet 级精度，参数减少 50 倍，模型大小小于 0.5MB

```py
> https://arxiv.org/abs/1602.07360

```

本文的目的是尽可能减小网络的规模。

有些技术不适用于现代手机，但许多想法对你来说是有价值的。从概念上来说，SqueezeNet 做的关键事情是使用上一章的瓶颈模块的一个更激进的版本，叫做 fire 模块。

### 消防模块

每个 fire 模块接受输入并将其压缩(例如，在开始时应用 1×1 卷积)，然后以两种不同的方式将其扩展(例如，并行的 3×3 conv 和 1×1 conv)，然后将这两个扩展层的结果连接在一起以产生最终结果。从概念上讲，在块的第二部分可以从中学习之前，数据会显著减少。这是一个破坏性的操作，但另一方面，它大大减少了网络中的参数数量。

>密集连接的卷积网络

```py
> https://arxiv.org/abs/1608.06993

```

将多组结果连接在一起是通过网络传递信息的一种有趣方式。Densenet 是同年晚些时候发表的一篇论文，该论文采用了 ResNet 网络方法，并使用 concat 运算符代替 add 运算来产生一个新的最先进的网络(尽管计算成本极高)。我们稍后将再次讨论这个想法。

由于我们已经减少了通过网络的数据量，SqueezeNet 做的另一件事是无用的 maxpool 操作，所以我们减少了这种破坏性的操作。

## 深度压缩

接下来，SqueezeNet 的作者应用了另一篇论文中的技术，使模型尽可能小:

>深度压缩:通过剪枝、训练量化和霍夫曼编码压缩深度神经网络

```py
> https://arxiv.org/abs/1510.00149

```

理解剪枝和量化作为模型压缩技术的一般概念是至关重要的。作者在顶层所做的具体优化对理解也是有价值的，但不是必需的。

### 模型修剪

我们可以做的另一件事是让模型运行得更快，这叫做网络修剪。从概念上讲，神经网络遵循 Zipf 定律的一种变体，而我们 20%的网络激活产生了 80%的结果。因此，如果我们愿意牺牲准确性，我们可以通过丢弃除了最受欢迎的节点之外的所有节点来轻松地构建一个明显更小的网络，这被称为稀疏化或修剪。

“深度压缩”论文采用了这一思想，但是在执行稀疏步骤之后重新训练网络。有趣的是，通过执行这个再训练步骤，我们可以得到一个和输入网络一样精确的最终网络。然后，通过应用 CRC 压缩方案(本文的特定方法)，我们可以得到一个参数数量级更少的网络。

### 模型量化

接下来，我们可以将 32 位浮点数转换成 8 位整数权重，以便将它们的大小再减小 4 倍。这是一个非常常见的步骤，当生产更小的模型以在支持量化数学的设备上运行时，以及生产显著更小的模型以通过互联网发送到移动和嵌入式设备时。在最简单的模型量化形式中，浮点数表示为+–~10^38 的范围，而整数 8 数学的范围为–128 到 127，我们只需将较大的浮点数映射到它们最接近的归一化整数。然而，这种方法的问题是，减少网络可用空间的过程通常是破坏性的，因此最终的网络在之后不能很好地工作(例如，事情工作得更快，但准确性显著降低)。

然而，如果我们有先见之明，将我们的网络最终将被量化的知识纳入其中，那么我们就可以修改我们的训练过程(技术术语是量化感知训练)来利用这一事实。与之前的模型修剪步骤类似,“深度压缩”论文对网络进行了量化，并再次对其进行了训练，以使量化过程的结果最小化。通过这样做，他们能够消除任何精度下降，但最终仍然得到一个明显更小的模型。

SqueezeNet 论文的最后一步是利用霍夫曼编码，这是一种无损压缩方案。结果，他们能够进一步压缩量子化网络。

### 尺寸度量

因此，在高水平上，这个网络产生的网络在 ImageNet 上的准确性与 AlexNet 相同，Alex net 是 2012 年最先进的计算机视觉网络。通过应用他们的模型压缩技术，他们能够将 AlexNet 的大小从 240MB 减少到 6.9MB，而没有损失准确性。通过使用 fire 模块来生产 SqueezeNet，他们能够在 ImageNet 数据集上实现与 AlexNet 相同的准确性，模型为 4.8MB，提高了 50 倍。然后，他们能够将他们的模型压缩技术应用于该模型，以产生. 47MB(不到半兆字节)的量化版本，但仍具有与原始模型和 AlexNet 相当的准确性。从概念上讲，SqueezeNet 能够实现与 AlexNet 相同质量的结果，而使用的参数减少了 510 倍，这是一个令人印象深刻的成就。

### SqueezeNet 1.0 和 1.1 的区别

文献中有两个版本的 SqueezeNet，即 1.0 版和 1.1 版。两者的主要区别在于第一层，1.0 版使用 7x7 步距和 96 个滤镜，而 1.1 版使用 3x3 步距和 64 个滤镜。

## 密码

以下是 1.1 的演示。其中，1.1 版模型将其最大池层移至堆栈的更高层(例如，在第 1、3、5 层，而不是第 1、4、8 层)。这就产生了一个具有相同精度的网络，而运算量却减少了约 2.4 倍(例如，1.0 的运算量为 1.72 Gflops/image，而 1.1 的运算量为 0.72 Gflops/image)。

```py
```
import TensorFlow

public struct Fire: Layer {
  public var squeeze: Conv2D<Float>
  public var expand1: Conv2D<Float>
  public var expand3: Conv2D<Float>

  public init(
    inputFilterCount: Int,
    squeezeFilterCount: Int,
    expand1FilterCount: Int,
    expand3FilterCount: Int
  ) {
    squeeze = Conv2D(
      filterShape: (1, 1, inputFilterCount, squeezeFilterCount),
      activation: relu)
    expand1 = Conv2D(
      filterShape: (1, 1, squeezeFilterCount, expand1FilterCount),
      activation: relu)
    expand3 = Conv2D(
      filterShape: (3, 3, squeezeFilterCount, expand3FilterCount),
      padding: .same,
      activation: relu)
  }

  @differentiable
  public func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    let squeezed = squeeze(input)
    let expanded1 = expand1(squeezed)
    let expanded3 = expand3(squeezed)
    return expanded1.concatenated(with: expanded3, alongAxis: -1)
  }
}

public struct SqueezeNet: Layer {
  public var inputConv = Conv2D<Float>(
    filterShape: (3, 3, 3, 64),
    strides: (2, 2),
    padding: .same,
    activation: relu)
  public var maxPool1 = MaxPool2D<Float>(poolSize: (3, 3), strides: (2, 2))
  public var fire2 = Fire(
    inputFilterCount: 64,
    squeezeFilterCount: 16,
    expand1FilterCount: 64,
    expand3FilterCount: 64)
  public var fire3 = Fire(
    inputFilterCount: 128,
    squeezeFilterCount: 16,
    expand1FilterCount: 64,
    expand3FilterCount: 64)
  public var maxPool3 = MaxPool2D<Float>(poolSize: (3, 3), strides: (2, 2))
  public var fire4 = Fire(
    inputFilterCount: 128,
    squeezeFilterCount: 32,
    expand1FilterCount: 128,
    expand3FilterCount: 128)
  public var fire5 = Fire(
    inputFilterCount: 256,
    squeezeFilterCount: 32,
    expand1FilterCount: 128,
    expand3FilterCount: 128)
  public var maxPool5 = MaxPool2D<Float>(poolSize: (3, 3), strides: (2, 2))
  public var fire6 = Fire(
    inputFilterCount: 256,
    squeezeFilterCount: 48,
    expand1FilterCount: 192,
    expand3FilterCount: 192)
  public var fire7 = Fire(
    inputFilterCount: 384,
    squeezeFilterCount: 48,
    expand1FilterCount: 192,
    expand3FilterCount: 192)
  public var fire8 = Fire(
    inputFilterCount: 384,
    squeezeFilterCount: 64,
    expand1FilterCount: 256,
    expand3FilterCount: 256)
  public var fire9 = Fire(
    inputFilterCount: 512,
    squeezeFilterCount: 64,
    expand1FilterCount: 256,
    expand3FilterCount: 256)
  public var outputConv: Conv2D<Float>
  public var avgPool = AvgPool2D<Float>(poolSize: (13, 13), strides: (1, 1))

  public init(classCount: Int = 10) {
    outputConv = Conv2D(filterShape: (1, 1, 512, classCount), strides: (1, 1), activation: relu)
  }

  @differentiable
  public func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    let convolved1 = input.sequenced(through: inputConv, maxPool1)
    let fired1 = convolved1.sequenced(through: fire2, fire3, maxPool3, fire4, fire5)
    let fired2 = fired1.sequenced(through: maxPool5, fire6, fire7, fire8, fire9)
    let output = fired2.sequenced(through: outputConv, avgPool)
    return output.reshaped(to: [input.shape[0], outputConv.filter.shape[3]])
  }
}
```py

```

### 训练循环

将前面的代码放入名为 SqueezeNet.swift 的文件中，然后添加一个名为 main.swift 的训练循环:

```py
```
import Datasets
import TensorFlow

let batchSize = 128
let epochCount = 100

let dataset = Imagenette(batchSize: batchSize, inputSize: .resized320, outputSize: 224)
var model = SqueezeNet()

let optimizer = SGD(for: model, learningRate: 0.0001, momentum: 0.9); print("sgd")
//let optimizer = RMSProp(for: model, learningRate: 0.0001); print ("rmsprop")
//let optimizer = Adam(for: model, learningRate: 0.0001); print ("adam")

print("Starting training...")

for (epoch, epochBatches) in dataset.training.prefix(epochCount).enumerated() {
  Context.local.learningPhase = .training
  for batch in epochBatches {
    let (images, labels) = (batch.data, batch.label)
    let (_, gradients) = valueWithGradient(at: model) { model -> Tensor<Float> in
      let logits = model(images)
      return softmaxCrossEntropy(logits: logits, labels: labels)
    }
    optimizer.update(&model, along: gradients)
  }

  Context.local.learningPhase = .inference
  var testLossSum: Float = 0
  var testBatchCount = 0
  var correctGuessCount = 0
  var totalGuessCount = 0
  for batch in dataset.validation {
    let (images, labels) = (batch.data, batch.label)
    let logits = model(images)
    testLossSum += softmaxCrossEntropy(logits: logits, labels: labels).scalarized()
    testBatchCount += 1

    let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels
    correctGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())
    totalGuessCount = totalGuessCount + batch.label.shape[0]
  }

  let accuracy = Float(correctGuessCount) / Float(totalGuessCount)
  print(
    """
    [Epoch \(epoch+1)] \
    Accuracy: \(correctGuessCount)/\(totalGuessCount) (\(accuracy)) \
    Loss: \(testLossSum / Float(testBatchCount))
    """
  )
}
```py

```

展望未来，我们将只是更换型号，并以这种方式运行。如果你需要自定义训练参数，我会在这里注明。

### 结果

运行您的模型，您应该会得到如下结果:

```py
```
...
[Epoch 95 ] Accuracy: 79/500 (0.158) Loss: 2.3003228
[Epoch 96 ] Accuracy: 78/500 (0.156) Loss: 2.3002906
[Epoch 97 ] Accuracy: 78/500 (0.156) Loss: 2.300246
[Epoch 98 ] Accuracy: 79/500 (0.158) Loss: 2.3002024
[Epoch 99 ] Accuracy: 78/500 (0.156) Loss: 2.3001637
[Epoch 100] Accuracy: 80/500 (0.16)  Loss: 2.3001184
```py

```

为什么我们的网络性能很差？我们之所以只有 16%的准确率，是因为 SqueezeNet 是一个极难训练的网络。基本的 SGD 通常可以用于构建模型，但是要精确地训练这个模型，需要在优化器方面采用稍微复杂一点的方法。

```py
> SGD + momentum + (optional) Nesterov smoothing

```

到目前为止，我们实际上还没有使用普通的 SGD 我们一直用 SGD +动量，也就是所谓的二阶方法。通过跟踪网络当前移动的路径，然后根据矢量的惯性(物理学)进行更新，我们有更高的概率不会被随机更新分散注意力。内斯特罗夫动量(可以用标志“nesterov: true”启用)通过数学平滑结合这两者的函数来改进这一过程。

> RMSProp

```py
> www.cs.toronto.edu/~tijmen/csc321/slides/ lecture_slides_lec6.pdf

```

这是从杰佛瑞·辛顿之前的课堂笔记中出现的，后来被亚历克斯·格雷夫斯写在了一篇论文中(见 [`https://arxiv.org/abs/1308.0850`](https://arxiv.org/abs/1308.0850) )。在概念上，我们通过存储搜索空间的每个向量的梯度来代替 SGD +动量过程，然后更新过程是这些平方梯度的指数递减和。由于我们跟踪多个向量，这在处理稀疏网络时做得很好。

>亚当

```py
> https://arxiv.org/abs/1412.6980

```

亚当和它的变体可以被粗略地描述为将动量的概念与梯度空间的跟踪相结合，试图获得两个世界的最佳结果。不严格地说，在某些情况下，任何一种形式都难以融合。对于基于动量的方法，这发生在梯度搜索子空间非常颠簸的时候。同样，跟踪梯度可能会遇到所谓的消失梯度效应，搜索过程开始变得越来越慢，最终完全停止。

无论如何，选择一个非 SGD 方法来启用、运行网络，您的准确性应该会显著提高:

```py
```
[Epoch 96 ] Accuracy: 378/500 (0.756) Loss: 0.7979737
[Epoch 97 ] Accuracy: 369/500 (0.738) Loss: 0.8244314
[Epoch 98 ] Accuracy: 387/500 (0.774) Loss: 0.74936193
[Epoch 99 ] Accuracy: 377/500 (0.754) Loss: 0.7717642
[Epoch 100] Accuracy: 379/500 (0.758) Loss: 0.7441697
```py

```

在本书的其余部分，我们将继续使用 SGD 和一个小的(例如，0.002)学习率，但你应该知道前面的优化器，在基本随机方法失败的情况下尝试。

### 支线任务

如果你对优化感兴趣，Sebastian Ruder 有一篇不错的博文，你应该看看:

```py
https://ruder.io/optimizing-gradient-descent/

```

## 概述

我们已经研究了 SqueezeNet，这是一个来自 2016 年的计算机视觉网络，与我们迄今为止研究的网络相比，它提供了很好的结果，周期和参数数量明显减少。然后，我们看了一些优化器调整，有时需要训练这些较小的网络。接下来，让我们看看一些围绕手机可用硬件设计的架构。