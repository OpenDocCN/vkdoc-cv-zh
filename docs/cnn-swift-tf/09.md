# 9\. 移动网络 v2

在这一章中，我们将看看如何修改我们的 MobileNet v1 方法来产生 MobileNet v2，它稍微更精确并且计算成本更低。该网络于 2018 年问世，并交付了 v1 架构的改进版本。

> MobileNetV2:反向残差和线性瓶颈

```
> https://arxiv.org/abs/1801.04381

```

Google 团队在本文中介绍的关键概念是反向剩余块和线性瓶颈层，所以让我们看看它们是如何工作的。

## 反向残差块

在我们之前的 ResNet 50 瓶颈块中，我们在每个组的初始层中通过 1x1 卷积来传递输入层，这减少了此时的数据。在将数据通过昂贵的 3×3 卷积后，我们使用 1×1 卷积来扩展滤波器的数量。

在反向残差块中，这是 MobileNet v2 所使用的，我们改为使用初始的 1x1 卷积来增加我们的网络深度，然后应用 MobileNet v1 的深度方向卷积，然后使用 1x1 卷积来压缩我们的网络。

## 反向跳跃连接

在我们的 ResNet 网络中，我们应用了跳过连接(例如，add 操作)将数据从输入层传递到输出层。MobileNet v2 以一种稍微不同的方式来实现这一点，只在输入和输出数量相同的块上执行这一操作(例如，不是每个堆栈的第一个块，而是其余块之间的块)。这意味着这个网络不像原来的 ResNet 那样连接紧密，通过的数据也更少，但从另一方面来说，评估它要便宜得多。

## 线性瓶颈层

下一个微妙的调整与我们的反向跳跃连接有关。在原始的 ResNet 网络中，我们将 ReLU 激活函数应用于瓶颈层的组合输出和输入。有趣的是，MobileNet v2 的作者发现我们可以消除这种激活功能，提高网络的性能。这种激活就变成了一个线性函数，所以他们称这个结果为线性瓶颈函数。

## 密码

对于这个网络，我们将使用我们的块操作符来生成子图层(例如，InvertedBottleneckBlockStack)。从概念上来说，与我们的 MobileNet v1 架构的主要区别在于，我们在残差块中添加了深度方向的 conv，以及我们计算每一遍梯度的反向方法。

```
```
import TensorFlow

public struct InitialInvertedBottleneckBlock: Layer {
  public var dConv: DepthwiseConv2D<Float>
  public var batchNormDConv: BatchNorm<Float>
  public var conv2: Conv2D<Float>
  public var batchNormConv: BatchNorm<Float>

  public init(filters: (Int, Int)) {
    dConv = DepthwiseConv2D<Float>(
      filterShape: (3, 3, filters.0, 1),
      strides: (1, 1),
      padding: .same)
    conv2 = Conv2D<Float>(
      filterShape: (1, 1, filters.0, filters.1),
      strides: (1, 1),
      padding: .same)
    batchNormDConv = BatchNorm(featureCount: filters.0)
    batchNormConv = BatchNorm(featureCount: filters.1)
  }

  @differentiable
  public func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    let depthwise = relu6(batchNormDConv(dConv(input)))
    return batchNormConv(conv2(depthwise))
  }
}

public struct InvertedBottleneckBlock: Layer {
  @noDerivative public var addResLayer: Bool
  @noDerivative public var strides: (Int, Int)
  @noDerivative public let zeroPad = ZeroPadding2D<Float>(padding: ((0, 1), (0, 1)))

  public var conv1: Conv2D<Float>
  public var batchNormConv1: BatchNorm<Float>
  public var dConv: DepthwiseConv2D<Float>
  public var batchNormDConv: BatchNorm<Float>
  public var conv2: Conv2D<Float>
  public var batchNormConv2: BatchNorm<Float>

  public init(
    filters: (Int, Int),
    depthMultiplier: Int = 6,
    strides: (Int, Int) = (1, 1)
  ) {
    self.strides = strides
    self.addResLayer = filters.0 == filters.1 && strides == (1, 1)

    let hiddenDimension = filters.0 * depthMultiplier
    conv1 = Conv2D<Float>(
      filterShape: (1, 1, filters.0, hiddenDimension),
      strides: (1, 1),
      padding: .same)
    dConv = DepthwiseConv2D<Float>(
      filterShape: (3, 3, hiddenDimension, 1),
      strides: strides,
      padding: strides == (1, 1) ? .same : .valid)
    conv2 = Conv2D<Float>(
      filterShape: (1, 1, hiddenDimension, filters.1),
      strides: (1, 1),
      padding: .same)
    batchNormConv1 = BatchNorm(featureCount: hiddenDimension)
    batchNormDConv = BatchNorm(featureCount: hiddenDimension)
    batchNormConv2 = BatchNorm(featureCount: filters.1)
  }

  @differentiable
  public func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    let pointwise = relu6(batchNormConv1(conv1(input)))
    var depthwise: Tensor<Float>
    if self.strides == (1, 1) {
      depthwise = relu6(batchNormDConv(dConv(pointwise)))
    } else {
      depthwise = relu6(batchNormDConv(dConv(zeroPad(pointwise))))
    }
    let pointwiseLinear = batchNormConv2(conv2(depthwise))

    if self.addResLayer {
      return input + pointwiseLinear
    } else {
      return pointwiseLinear
    }
  }
}

public struct InvertedBottleneckBlockStack: Layer {
  var blocks: [InvertedBottleneckBlock] = []

  public init(
    filters: (Int, Int),
    blockCount: Int,
    initialStrides: (Int, Int) = (2, 2)
  ) {
    self.blocks = [
      InvertedBottleneckBlock(
        filters: (filters.0, filters.1),
        strides: initialStrides)
    ]
    for _ in 1..<blockCount {
      self.blocks.append(
        InvertedBottleneckBlock(
          filters: (filters.1, filters.1))
      )
    }
  }

  @differentiable
  public func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    return blocks.differentiableReduce(input) { $1($0) }
  }
}

public struct MobileNetV2: Layer {
  @noDerivative public let zeroPad = ZeroPadding2D<Float>(padding: ((0, 1), (0, 1)))
  public var inputConv: Conv2D<Float>
  public var inputConvBatchNorm: BatchNorm<Float>
  public var initialInvertedBottleneck: InitialInvertedBottleneckBlock

  public var residualBlockStack1: InvertedBottleneckBlockStack
  public var residualBlockStack2: InvertedBottleneckBlockStack
  public var residualBlockStack3: InvertedBottleneckBlockStack
  public var residualBlockStack4: InvertedBottleneckBlockStack
  public var residualBlockStack5: InvertedBottleneckBlockStack

  public var invertedBottleneckBlock16: InvertedBottleneckBlock

  public var outputConv: Conv2D<Float>
  public var outputConvBatchNorm: BatchNorm<Float>
  public var avgPool = GlobalAvgPool2D<Float>()
  public var outputClassifier: Dense<Float>

  public init(classCount: Int = 10) {
    inputConv = Conv2D<Float>(
      filterShape: (3, 3, 3, 32),
      strides: (2, 2),
      padding: .valid)
    inputConvBatchNorm = BatchNorm(
      featureCount: 32)

    initialInvertedBottleneck = InitialInvertedBottleneckBlock(
      filters: (32, 16))

    residualBlockStack1 = InvertedBottleneckBlockStack(filters: (16, 24), blockCount: 2)
    residualBlockStack2 = InvertedBottleneckBlockStack(filters: (24, 32), blockCount: 3)
    residualBlockStack3 = InvertedBottleneckBlockStack(filters: (32, 64), blockCount: 4)
    residualBlockStack4 = InvertedBottleneckBlockStack(
      filters: (64, 96), blockCount: 3,
      initialStrides: (1, 1))
    residualBlockStack5 = InvertedBottleneckBlockStack(filters: (96, 160), blockCount: 3)

    invertedBottleneckBlock16 = InvertedBottleneckBlock(filters: (160, 320))

    outputConv = Conv2D<Float>(
      filterShape: (1, 1, 320, 1280),
      strides: (1, 1),
      padding: .same)
    outputConvBatchNorm = BatchNorm(featureCount: 1280)

    outputClassifier = Dense(inputSize: 1280, outputSize: classCount)
  }

  @differentiable
  public func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    let convolved = relu6(input.sequenced(through: zeroPad, inputConv, inputConvBatchNorm))
    let initialConv = initialInvertedBottleneck(convolved)
    let backbone = initialConv.sequenced(
      through: residualBlockStack1, residualBlockStack2, residualBlockStack3,
      residualBlockStack4, residualBlockStack5)
    let output = relu6(outputConvBatchNorm(outputConv(invertedBottleneckBlock16(backbone))))
    return output.sequenced(through: avgPool, outputClassifier)
  }
}

```

### 结果

使用相同的训练循环和基本设置，该网络的性能优于我们的 MobileNet v1 架构。

```
Starting training...
[Epoch 1 ] Accuracy: 50/500  (0.1)   Loss: 3.0107288
[Epoch 2 ] Accuracy: 276/500 (0.552) Loss: 1.4318728
[Epoch 3 ] Accuracy: 324/500 (0.648) Loss: 1.2038971
[Epoch 4 ] Accuracy: 337/500 (0.674) Loss: 1.1165649
[Epoch 5 ] Accuracy: 347/500 (0.694) Loss: 0.9973701
[Epoch 6 ] Accuracy: 363/500 (0.726) Loss: 0.9118728
[Epoch 7 ] Accuracy: 310/500 (0.62)  Loss: 1.2533528
[Epoch 8 ] Accuracy: 372/500 (0.744) Loss: 0.797099
[Epoch 9 ] Accuracy: 368/500 (0.736) Loss: 0.8001915
[Epoch 10] Accuracy: 350/500 (0.7)   Loss: 1.1580966
[Epoch 11] Accuracy: 372/500 (0.744) Loss: 0.84680176
[Epoch 12] Accuracy: 358/500 (0.716) Loss: 1.1446275
[Epoch 13] Accuracy: 388/500 (0.776) Loss: 0.90346915
[Epoch 14] Accuracy: 394/500 (0.788) Loss: 0.82173353
[Epoch 15] Accuracy: 365/500 (0.73)  Loss: 0.9974839
[Epoch 16] Accuracy: 359/500 (0.718) Loss: 1.2463648
[Epoch 17] Accuracy: 333/500 (0.666) Loss: 1.5243211
[Epoch 18] Accuracy: 390/500 (0.78)  Loss: 0.8723967
[Epoch 19] Accuracy: 383/500 (0.766) Loss: 1.0088551
[Epoch 20] Accuracy: 372/500 (0.744) Loss: 1.1002765
[Epoch 21] Accuracy: 392/500 (0.784) Loss: 0.9233314
[Epoch 22] Accuracy: 395/500 (0.79)  Loss: 0.9421617
[Epoch 23] Accuracy: 367/500 (0.734) Loss: 1.1607682
[Epoch 24] Accuracy: 372/500 (0.744) Loss: 1.1685853
[Epoch 25] Accuracy: 375/500 (0.75)  Loss: 1.1443601
[Epoch 26] Accuracy: 389/500 (0.778) Loss: 1.0197723
[Epoch 27] Accuracy: 392/500 (0.784) Loss: 1.0215062
[Epoch 28] Accuracy: 387/500 (0.774) Loss: 1.1886547
[Epoch 29] Accuracy: 400/500 (0.8)   Loss: 0.9691738
[Epoch 30] Accuracy: 383/500 (0.766) Loss: 1.1193326

```

## 概述

我们已经研究了 MobileNet v2，这是一个从 2018 年开始的最先进的网络，用于在计算能力有限的设备(如电话)上执行图像识别。接下来，让我们看看如何通过强化学习获得更好的结果！