# 五、ResNet 34

在本章中，我们将探讨如何改造 VGG 网络主干网，以生产 ResNet 34，即 2015 年的网络。回顾我们过去的几章，我们的 2D MNIST、CIFAR 和 VGG 网络之间的区别只是 3×3 卷积的块数。但是，为什么要在这一点上停下来呢？让我们建立更大的网络！接下来，我们将看看 ResNet 系列网络，从 ResNet 34 开始。

从概念上讲，我们将从一个与我们刚才看到的 VGG 网络相似的基础开始。如果我们的 VGG 网络的主干可以被认为是 VGG16 的[2，2，3，3，3]，那么 ResNet 34 的主干是[6，8，12，6]，每个块由成对的 3x3 卷积组成，与我们之前看到的网络完全相同。然而，我们将增加一个更重要的概念，叫做跳过连接。

## 跳过连接

可以说，残留网络的魔力在于添加了所谓的残留层或跳过连接。

>用于图像识别的深度残差学习

```py
> https://arxiv.org/abs/1512.03385

```

基本思想是，我们添加一组额外的路径，从每组层跳到输出节点。这可以在网络级很简单地实现，只需将每组输入层添加到输出步骤的模块中。

这通常表示为网络一侧的一组层。

### 噪音

从概念上讲，VGG 模式的问题不在于我们不能建立越来越大的网络。如果我们有足够的 GPU 内存，我们当然可以在一段时间内复制/粘贴我们的块！VGG 式网络的主要局限是噪音。每个卷积都是破坏性的操作。如果每个卷积只丢失了很小一部分信息，比如 0.1%，那么 16 或 19 层上的效果就会开始复合，因为该效果会在每层中重新应用。

因此，ResNet 的第一个真正的技巧只是这些跳过连接将每组层的输入添加到最终层的输出。这为网络提供了更多的数据，以便为最终的预测步骤找到正确的卷积层组合。ResNet 的第二大绝招在最后。由于我们通过网络发送更多的数据，我们可以停止使用完全连接的层，而是使用平均池步骤来产生最终输出。

与我们之前一起启动的节点相比，这里的神经网络正在以与我们其他卷积相同的方式有效地学习这个输出层，这比完全连接的节点的计算成本低得多。这意味着评估我们的网络突然变得非常，非常便宜。因此，尽管我们在网络中增加了更多层，跳过连接意味着我们通过网络发送更多数据，但整个网络的评估速度实际上比我们的 VGG 网络快得多。

首先，我们的参数总数显著下降(大约是参数总数的四分之一)。此外，与我们完全连接的层相比，这种添加操作实际上非常便宜。这意味着网络更小更快。

ResNet 的第一层是 7x7 卷积，但这只是为了将我们的输入分解成更小的网络。最近的研究表明，有更好的方法来实现输入/头层(我们将在第十二章中讨论)，所以请注意这可能不是最好的方法。话虽如此，由于当时的硬件限制，这是一种降低输入大小的廉价好方法，以便卷积神经网络能够完成其工作。

### 批量标准化

>批量标准化:通过减少内部协变量变化来加速深度网络训练

```py
> https://arxiv.org/abs/1502.03167

```

批量标准化是一项重要的培训技术，您应该知道。从概念上讲，它的工作原理是根据最近看到的数据的标准偏差对图层的输出进行归一化。当使用随机小批(我们的训练循环正在做的)时，这具有平滑梯度空间的有用属性，以便使我们的反向传播运行得更有效。因此，网络收敛更加顺畅，更新过程也快了一个数量级。从技术上讲，这个过程还会在训练过程中引入一些噪声，因此它有时也被认为是一种正则化技术。

## 密码

这将是我们第一个使用多个代码块的大型网络。第一个(head)块略有不同，因此我们有特定的逻辑来处理输入，然后所有其他内容都经过中间层，中间层是以编程方式生成的。这是一种模式，我们将从这里一次又一次地看到。

```py
```
import Datasets
import TensorFlow

struct ConvBN: Layer {
  var conv: Conv2D<Float>
  var norm: BatchNorm<Float>

  init(
    filterShape: (Int, Int, Int, Int),
    strides: (Int, Int) = (1, 1),
    padding: Padding = .valid
  ) {
    self.conv = Conv2D(filterShape: filterShape, strides: strides, padding: padding)
    self.norm = BatchNorm(featureCount: filterShape.3)
  }

  @differentiable
  public func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    return input.sequenced(through: conv, norm)
  }
}

struct ResidualBasicBlock: Layer {
  var layer1: ConvBN
  var layer2: ConvBN

  init(
    featureCounts: (Int, Int, Int, Int),
    kernelSize: Int = 3,
    strides: (Int, Int) = (1, 1)
  ) {
    self.layer1 = ConvBN(
      filterShape: (kernelSize, kernelSize, featureCounts.0, featureCounts.1),
      strides: strides,
      padding: .same)
    self.layer2 = ConvBN(
      filterShape: (kernelSize, kernelSize, featureCounts.1, featureCounts.3),
      strides: strides,
      padding: .same)
  }

  @differentiable
  public func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    return layer2(relu(layer1(input)))
  }
}

struct ResidualBasicBlockShortcut: Layer {
  var layer1: ConvBN
  var layer2: ConvBN
  var shortcut: ConvBN

  init(featureCounts: (Int, Int, Int, Int), kernelSize: Int = 3) {
    self.layer1 = ConvBN(
      filterShape: (kernelSize, kernelSize, featureCounts.0, featureCounts.1),
      strides: (2, 2),
      padding: .same)
    self.layer2 = ConvBN(
      filterShape: (kernelSize, kernelSize, featureCounts.1, featureCounts.2),
      strides: (1, 1),
      padding: .same)
    self.shortcut = ConvBN(
      filterShape: (1, 1, featureCounts.0, featureCounts.3),
      strides: (2, 2),
      padding: .same)
  }

  @differentiable
  public func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    return layer2(relu(layer1(input))) + shortcut(input)
  }
}

struct ResNet34: Layer {
  var l1: ConvBN
  var maxPool: MaxPool2D<Float>

  var l2a = ResidualBasicBlock(featureCounts: (64, 64, 64, 64))
  var l2b = ResidualBasicBlock(featureCounts: (64, 64, 64, 64))
  var l2c = ResidualBasicBlock(featureCounts: (64, 64, 64, 64))

  var l3a = ResidualBasicBlockShortcut(featureCounts: (64, 128, 128, 128))
  var l3b = ResidualBasicBlock(featureCounts: (128, 128, 128, 128))
  var l3c = ResidualBasicBlock(featureCounts: (128, 128, 128, 128))
  var l3d = ResidualBasicBlock(featureCounts: (128, 128, 128, 128))

  var l4a = ResidualBasicBlockShortcut(featureCounts: (128, 256, 256, 256))
  var l4b = ResidualBasicBlock(featureCounts: (256, 256, 256, 256))
  var l4c = ResidualBasicBlock(featureCounts: (256, 256, 256, 256))
  var l4d = ResidualBasicBlock(featureCounts: (256, 256, 256, 256))
  var l4e = ResidualBasicBlock(featureCounts: (256, 256, 256, 256))
  var l4f = ResidualBasicBlock(featureCounts: (256, 256, 256, 256))

  var l5a = ResidualBasicBlockShortcut(featureCounts: (256, 512, 512, 512))
  var l5b = ResidualBasicBlock(featureCounts: (512, 512, 512, 512))
  var l5c = ResidualBasicBlock(featureCounts: (512, 512, 512, 512))

  var avgPool: AvgPool2D<Float>
  var flatten = Flatten<Float>()
  var classifier: Dense<Float>

  init() {
    l1 = ConvBN(filterShape: (7, 7, 3, 64), strides: (2, 2), padding: .same)
    maxPool = MaxPool2D(poolSize: (3, 3), strides: (2, 2))
    avgPool = AvgPool2D(poolSize: (7, 7), strides: (7, 7))
    classifier = Dense(inputSize: 512, outputSize: 10)
  }

  @differentiable
  public func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    let inputLayer = maxPool(relu(l1(input)))
    let level2 = inputLayer.sequenced(through: l2a, l2b, l2c)
    let level3 = level2.sequenced(through: l3a, l3b, l3c, l3d)
    let level4 = level3.sequenced(through: l4a, l4b, l4c, l4d, l4e, l4f)
    let level5 = level4.sequenced(through: l5a, l5b, l5c)
    return level5.sequenced(through: avgPool, flatten, classifier)
  }
}

let batchSize = 32
let epochCount = 30

let dataset = Imagenette(batchSize: batchSize, inputSize: .resized320, outputSize: 224)
var model = ResNet34()
let optimizer = SGD(for: model, learningRate: 0.002, momentum: 0.9)

print("Starting training...")

for (epoch, epochBatches) in dataset.training.prefix(epochCount).enumerated() {
  Context.local.learningPhase = .training
  for batch in epochBatches {
    let (images, labels) = (batch.data, batch.label)
    let (_, gradients) = valueWithGradient(at: model) { model -> Tensor<Float> in
      let logits = model(images)
      return softmaxCrossEntropy(logits: logits, labels: labels)
    }
    optimizer.update(&model, along: gradients)
  }

  Context.local.learningPhase = .inference
  var testLossSum: Float = 0
  var testBatchCount = 0
  var correctGuessCount = 0
  var totalGuessCount = 0
  for batch in dataset.validation {
    let (images, labels) = (batch.data, batch.label)
    let logits = model(images)
    testLossSum += softmaxCrossEntropy(logits: logits, labels: labels).scalarized()
    testBatchCount += 1

    let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels
    correctGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())
    totalGuessCount = totalGuessCount + batch.label.shape[0]
  }

  let accuracy = Float(correctGuessCount) / Float(totalGuessCount)
  print(
    """
    [Epoch \(epoch+1)] \
    Accuracy: \(correctGuessCount)/\(totalGuessCount) (\(accuracy)) \
    Loss: \(testLossSum / Float(testBatchCount))
    """
  )
}

```py

### 结果

由于使用了更简单的卷积输出和残差块，该网络收敛得非常好，并且比以前的 VGG 网络训练/评估快得多。

```
Starting training...
[Epoch  1] Accuracy: 217/500 (0.434) Loss: 2.118794
[Epoch  2] Accuracy: 194/500 (0.388) Loss: 2.0524213
[Epoch  3] Accuracy: 295/500 (0.59)  Loss: 1.4818325
[Epoch  4] Accuracy: 177/500 (0.354) Loss: 2.1035159
[Epoch  5] Accuracy: 327/500 (0.654) Loss: 1.0758021
[Epoch  6] Accuracy: 278/500 (0.556) Loss: 1.680953
[Epoch  7] Accuracy: 327/500 (0.654) Loss: 1.3363588
[Epoch  8] Accuracy: 348/500 (0.696) Loss: 1.107703
[Epoch  9] Accuracy: 284/500 (0.568) Loss: 1.9379689
[Epoch 10] Accuracy: 350/500 (0.7)   Loss: 1.2561296
[Epoch 11] Accuracy: 288/500 (0.576) Loss: 1.995267
[Epoch 12] Accuracy: 353/500 (0.706) Loss: 1.2237265
[Epoch 13] Accuracy: 342/500 (0.684) Loss: 1.4842949
[Epoch 14] Accuracy: 374/500 (0.748) Loss: 1.385373
[Epoch 15] Accuracy: 313/500 (0.626) Loss: 2.0999825
[Epoch 16] Accuracy: 368/500 (0.736) Loss: 1.1946388
[Epoch 17] Accuracy: 370/500 (0.74)  Loss: 1.2470249
[Epoch 18] Accuracy: 382/500 (0.764) Loss: 1.1730658
[Epoch 19] Accuracy: 390/500 (0.78)  Loss: 1.1377627
[Epoch 20] Accuracy: 392/500 (0.784) Loss: 1.0375359
[Epoch 21] Accuracy: 371/500 (0.742) Loss: 1.3912839
[Epoch 22] Accuracy: 379/500 (0.758) Loss: 1.2445369
[Epoch 23] Accuracy: 384/500 (0.768) Loss: 1.1650964
[Epoch 24] Accuracy: 365/500 (0.73)  Loss: 1.4282515
[Epoch 25] Accuracy: 361/500 (0.722) Loss: 1.4129665
[Epoch 26] Accuracy: 376/500 (0.752) Loss: 1.3693335
[Epoch 27] Accuracy: 364/500 (0.728) Loss: 1.4527073
[Epoch 28] Accuracy: 376/500 (0.752) Loss: 1.3168014
[Epoch 29] Accuracy: 363/500 (0.726) Loss: 1.6024143
[Epoch 30] Accuracy: 383/500 (0.766) Loss: 1.1949569

```py

### 支线任务

这超出了本书的范围，但是这种方法已经被证明可以扩展到非常大的网络。千层 ResNet 网络已经建立并在 CIFAR 数据集上成功训练。这种方法的一个稍微不同的变体叫做高速公路网络，也值得一看。这种跳跃连接方法自然地有助于将不同的块组合在一起，并且是许多现代神经网络方法的基础，这些方法使用残差网络将定制的块类型组合在一起，以解决越来越大的问题。

>高速公路网络

```
> https://arxiv.org/abs/1505.00387

```

## 概述

我们已经了解了如何堆叠类似于 VGG 网络的卷积组，以构建更大的卷积网络。然后，通过在我们的层组之间添加剩余跳跃连接，我们可以使这种方法抵抗噪声，并且结果可以达到比以前更高的精确度。接下来，我们将看看如何稍微修改这种方法，以产生更好的结果！