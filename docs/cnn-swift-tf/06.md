# 六、ResNet 50

ResNet 50 对你来说是一个至关重要的网络。这是该领域许多学术研究的基础。许多不同的论文将他们的结果与 ResNet 50 基线进行比较，这是一个有价值的参考点。此外，我们可以轻松下载已经在 ImageNet 数据集上训练过的 ResNet 50 网络的权重，并修改最后几层(称为**再训练**或* *迁移学习* *)以快速生成模型来解决新问题。对于大多数问题，这是最好的着手方式，而不是试图发明新的网络或技术。构建一个定制的数据集，并使用数据扩充技术对其进行扩展，将比构建一个新的架构更有意义。

继续我们上一章末尾的思路，剩余网络的真正力量在于它允许我们以低廉的成本建立、评估和训练更大的网络。因此，我们不再需要坚持使用 3×3 卷积，而是可以开始引入不同的细胞类型。所以，让我们建造更强大的东西。我们将看看如何修改 ResNet 34 以产生 ResNet 50，这是一个在这个领域中你会反复遇到的坚固的现代架构。

## 瓶颈区块

我们将要介绍的是所谓的瓶颈块。从概念上讲，我们将从两个 3x3 卷积到一个堆栈，看起来像这样:1x1，3x3，1x1。从数学的角度来看，这实际上不如我们迄今为止使用的 3x3 方法强大。瓶颈模块允许我们做的第二件事是运行更多的瓶颈模块，因为实施 1x1 层更便宜。因此，使用这些瓶颈层，我们可以运行四倍多的过滤器，这就是为什么我认为它们最终会更强大。或者，换句话说，它们在技术上不那么强大，但在计算上也更便宜。这意味着我们可以在不显著增加计算预算的情况下使用更多的块，例如，完整的瓶颈块比两个块的 ResNet 34 3x3 堆栈大约贵 5%。因此，通过简单地替换这些单元，该网络能够产生比我们的 ResNet 34 网络更精确的结果。这是一个我们将在接下来的章节中深入探讨的概念。

## 密码

这个网络和 Resnet 34 之间唯一真正的区别是将事物转换成使用瓶颈层，然后将较大的参数输入到中间阶段。

```py
```
import Datasets
import TensorFlow

struct ConvBN: Layer {
  var conv: Conv2D<Float>
  var norm: BatchNorm<Float>

  init(
    filterShape: (Int, Int, Int, Int),
    strides: (Int, Int) = (1, 1),
    padding: Padding = .valid
  ) {
    self.conv = Conv2D(filterShape: filterShape, strides: strides, padding: padding)
    self.norm = BatchNorm(featureCount: filterShape.3)
  }

  @differentiable
  public func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    return input.sequenced(through: conv, norm)
  }
}

struct ResidualConvBlock: Layer {
  var layer1: ConvBN
  var layer2: ConvBN
  var layer3: ConvBN
  var shortcut: ConvBN

  init(
    featureCounts: (Int, Int, Int, Int),
    kernelSize: Int = 3,
    strides: (Int, Int) = (2, 2)
  ) {
    self.layer1 = ConvBN(
      filterShape: (1, 1, featureCounts.0, featureCounts.1),
      strides: strides)
    self.layer2 = ConvBN(
      filterShape: (kernelSize, kernelSize, featureCounts.1, featureCounts.2),
      padding: .same)
    self.layer3 = ConvBN(filterShape: (1, 1, featureCounts.2, featureCounts.3))
    self.shortcut = ConvBN(
      filterShape: (1, 1, featureCounts.0, featureCounts.3),
      strides: strides,
      padding: .same)
  }

  @differentiable
  public func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    let tmp = relu(layer2(relu(layer1(input))))
    return relu(layer3(tmp) + shortcut(input))
  }
}

struct ResidualIdentityBlock: Layer {
  var layer1: ConvBN
  var layer2: ConvBN
  var layer3: ConvBN

  init(featureCounts: (Int, Int, Int, Int), kernelSize: Int = 3) {
    self.layer1 = ConvBN(filterShape: (1, 1, featureCounts.0, featureCounts.1))
    self.layer2 = ConvBN(
      filterShape: (kernelSize, kernelSize, featureCounts.1, featureCounts.2),
      padding: .same)
    self.layer3 = ConvBN(filterShape: (1, 1, featureCounts.2, featureCounts.3))
  }

  @differentiable
  public func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    let tmp = relu(layer2(relu(layer1(input))))
    return relu(layer3(tmp) + input)
  }
}

struct ResNet50: Layer {
  var l1: ConvBN
  var maxPool: MaxPool2D<Float>

  var l2a = ResidualConvBlock(featureCounts: (64, 64, 64, 256), strides: (1, 1))
  var l2b = ResidualIdentityBlock(featureCounts: (256, 64, 64, 256))
  var l2c = ResidualIdentityBlock(featureCounts: (256, 64, 64, 256))

  var l3a = ResidualConvBlock(featureCounts: (256, 128, 128, 512))
  var l3b = ResidualIdentityBlock(featureCounts: (512, 128, 128, 512))
  var l3c = ResidualIdentityBlock(featureCounts: (512, 128, 128, 512))
  var l3d = ResidualIdentityBlock(featureCounts: (512, 128, 128, 512))

  var l4a = ResidualConvBlock(featureCounts: (512, 256, 256, 1024))
  var l4b = ResidualIdentityBlock(featureCounts: (1024, 256, 256, 1024))
  var l4c = ResidualIdentityBlock(featureCounts: (1024, 256, 256, 1024))
  var l4d = ResidualIdentityBlock(featureCounts: (1024, 256, 256, 1024))
  var l4e = ResidualIdentityBlock(featureCounts: (1024, 256, 256, 1024))
  var l4f = ResidualIdentityBlock(featureCounts: (1024, 256, 256, 1024))

  var l5a = ResidualConvBlock(featureCounts: (1024, 512, 512, 2048))
  var l5b = ResidualIdentityBlock(featureCounts: (2048, 512, 512, 2048))
  var l5c = ResidualIdentityBlock(featureCounts: (2048, 512, 512, 2048))

  var avgPool: AvgPool2D<Float>
  var flatten = Flatten<Float>()
  var classifier: Dense<Float>

  init() {
    l1 = ConvBN(filterShape: (7, 7, 3, 64), strides: (2, 2), padding: .same)
    maxPool = MaxPool2D(poolSize: (3, 3), strides: (2, 2))
    avgPool = AvgPool2D(poolSize: (7, 7), strides: (7, 7))
    classifier = Dense(inputSize: 2048, outputSize: 10)
  }

  @differentiable
  public func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    let inputLayer = maxPool(relu(l1(input)))
    let level2 = inputLayer.sequenced(through: l2a, l2b, l2c)
    let level3 = level2.sequenced(through: l3a, l3b, l3c, l3d)
    let level4 = level3.sequenced(through: l4a, l4b, l4c, l4d, l4e, l4f)
    let level5 = level4.sequenced(through: l5a, l5b, l5c)
    return level5.sequenced(through: avgPool, flatten, classifier)
  }
}

let batchSize = 32
let epochCount = 30

let dataset = Imagenette(batchSize: batchSize, inputSize: .resized320, outputSize: 224)
var model = ResNet50()
let optimizer = SGD(for: model, learningRate: 0.002, momentum: 0.9)

print("Starting training...")

for (epoch, epochBatches) in dataset.training.prefix(epochCount).enumerated() {
  Context.local.learningPhase = .training
  for batch in epochBatches {
    let (images, labels) = (batch.data, batch.label)
    let (_, gradients) = valueWithGradient(at: model) { model -> Tensor<Float> in
      let logits = model(images)
      return softmaxCrossEntropy(logits: logits, labels: labels)
    }
    optimizer.update(&model, along: gradients)
  }

  Context.local.learningPhase = .inference
  var testLossSum: Float = 0
  var testBatchCount = 0
  var correctGuessCount = 0
  var totalGuessCount = 0
  for batch in dataset.validation {
    let (images, labels) = (batch.data, batch.label)
    let logits = model(images)
    testLossSum += softmaxCrossEntropy(logits: logits, labels: labels).scalarized()
    testBatchCount += 1

    let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels
    correctGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())
    totalGuessCount = totalGuessCount + batch.label.shape[0]
  }

  let accuracy = Float(correctGuessCount) / Float(totalGuessCount)
  print(
    """
    [Epoch \(epoch+1)] \
    Accuracy: \(correctGuessCount)/\(totalGuessCount) (\(accuracy)) \
    Loss: \(testLossSum / Float(testBatchCount))
    """
  )
}
```py

```

## 结果

通过以上设置，您应该能够在 Imagenette 上获得 75%以上的准确率，而无需任何数据扩充:

```py
[Epoch 20] Accuracy: 362/500 (0.724) Loss: 1.4309547
[Epoch 21] Accuracy: 315/500 (0.63)  Loss: 2.2550986
[Epoch 22] Accuracy: 372/500 (0.744) Loss: 1.4735502
[Epoch 23] Accuracy: 345/500 (0.69)  Loss: 1.9369599
[Epoch 24] Accuracy: 359/500 (0.718) Loss: 2.0183568
[Epoch 25] Accuracy: 337/500 (0.674) Loss: 2.2227683
[Epoch 26] Accuracy: 369/500 (0.738) Loss: 1.4570786
[Epoch 27] Accuracy: 380/500 (0.76)  Loss: 1.3399329
[Epoch 28] Accuracy: 377/500 (0.754) Loss: 1.4157851
[Epoch 29] Accuracy: 357/500 (0.714) Loss: 1.8361444
[Epoch 30] Accuracy: 377/500 (0.754) Loss: 1.3033926

```

## Side Quest: ImageNet

下面是我们如何在 ImageNet 数据集上使用 Swift for TensorFlow、随机梯度下降和 TrainingLoop API 训练 ResNet50 网络:

```py
```
import Datasets
import ImageClassificationModels
import TensorFlow
import TrainingLoop

// XLA mode can't load ImageNet, need to use eager mode to limit memory use
let device = Device.defaultTFEager
let dataset = ImageNet(batchSize: 32, outputSize: 224, on: device)
var model = ResNet(classCount: 1000, depth: .resNet50)

// 0.1 for 30, .01 for 30, .001 for 30
let optimizer = SGD(for: model, learningRate: 0.1, momentum: 0.9)
public func scheduleLearningRate<L: TrainingLoopProtocol>(
  _ loop: inout L, event: TrainingLoopEvent
) throws where L.Opt.Scalar == Float {
  if event == .epochStart {
    guard let epoch = loop.epochIndex else  { return }
    if epoch > 30 { loop.optimizer.learningRate = 0.01 }
    if epoch > 60 { loop.optimizer.learningRate = 0.001 }
    if epoch > 80 { loop.optimizer.learningRate = 0.0001 }
  }
}

var trainingLoop = TrainingLoop(
  training: dataset.training,
  validation: dataset.validation,
  optimizer: optimizer,
  lossFunction: softmaxCrossEntropy,
  metrics: [.accuracy],
  callbacks: [scheduleLearningRate])

try! trainingLoop.fit(&model, epochs: 90, on: device)
```py

```

值得注意的是，swift-models 导入引入了 ResNet v1.5，这是实践中更常见的 ResNet 变体。关键区别在于 2x2 步幅从每组的第一个 ConvBN 移动到第二个 con vbn。来自 He 等人的另一篇论文是“深度剩余网络中的身份映射”( [`https://arxiv.org/abs/1603.05027`](https://arxiv.org/abs/1603.05027) )，其有时被称为 ResNet v2 或预激活 ResNet，关键区别在于，在卷积运算之前完成批量归一化/激活步骤，并且去除了每个组中的最终激活。

## 概述

我们采用了上一章的 ResNet 34 模型，并通过添加瓶颈块对其进行了轻微修改。我们的 3x3 + 3x3 卷积已经被 1x1、3x3、1x1 风格的方法所取代，其中最后的 1x1 卷积具有四倍的层数。这使得我们的网络更大，从而提高了结果。不过，重要的是，这种方法的评估成本也很低，因此我们在计算方面以大致相同的成本获得了改进的结果。

这种剩余法可以与这一领域的许多其他方法相结合。不同组的卷积方法(称为**单元* *)可以使用残差堆栈结合在一起，以解决不同的问题。许多大规模强化学习技术(AlphaZero 是一个显著的例子)使用大量卷积层和残差网络。

如果你只从这本书里学一个网络，我觉得这是最适合你了解的一个。我们实际上已经花了六章来构建这种方法。接下来，我们将考察一些特定于移动设备的网络，尝试提供与我们的 ResNet 50 网络大致相似的结果，但在规模和复杂性方面成本显著降低。接下来，我们将尝试大幅缩减网络规模，以便构建能够在资源受限环境中运行的网络。