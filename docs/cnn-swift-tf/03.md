# 3.CIFAR:分块 2D 神经网络

在这一章中，我们将看看如何堆叠多层卷积来扩大我们的网络，以解决一个更加现实的问题，即区分动物和车辆的彩色图片，称为 CIFAR。

## CIFAR 数据集

我们将何去何从？让我们来处理一个稍微大一点、复杂一点的问题。这是一个名为 CIFAR 的数据集。这是一套彩色图片集。所以我们有猫、狗、动物以及人类交通工具——汽车和卡车的图片。我们有十个类别。现在，我们将处理颜色数据，因此我们有一个 RGB 组件。

## 颜色

从神经网络的角度来看，颜色并没有你想象的那么复杂。从概念上讲，我们只需从 MNIST 网络中提取第一个 3×3 卷积，如下所示:

```
var conv1a = Conv2D<Float>(filterShape: (3, 3, 1, 32), padding: .same, activation: relu)

```

我们只需将输入层数增加到 3 层，如下所示:

```
var conv1a = Conv2D<Float>(filterShape: (3, 3, 3, 32), padding: .same, activation: relu)

```

这是怎么回事？实际上，在我们的 MNIST 示例中，我们是将颜色作为灰度值(例如，Int/255.0)来处理的，所以现在我们将为每个颜色分量(例如，红、绿、蓝)设置三个灰度通道。对于我们的卷积运算，这只是添加了更多的数据供我们处理，但我们只是使用了与之前相同的过程。

## 故障

对于 CIFAR，我们可以采用之前使用的相同的基本方法，并将其扩展以解决这个问题。因此，我们将简单地采用我们的颜色输入数据——三个通道，32x32 像素。我们将通过两组卷积、一个最大池、另外两组卷积、一个最大池和同样的两个紧密连接的层来运行它，然后我们将有十个输出类别。

## 密码

这是这个模型的样子。除了添加另一叠卷积，我们什么也没做，但现在我们正在处理彩色和真实世界的照片。

```
```
import Datasets
import TensorFlow

struct CIFARModel: Layer {
  var conv1a = Conv2D<Float>(filterShape: (3, 3, 3, 32), padding: .same, activation: relu)
  var conv1b = Conv2D<Float>(filterShape: (3, 3, 32, 32), padding: .same, activation: relu)
  var pool1 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))

  var conv2a = Conv2D<Float>(filterShape: (3, 3, 32, 64), padding: .same, activation: relu)
  var conv2b = Conv2D<Float>(filterShape: (3, 3, 64, 64), padding: .same, activation: relu)
  var pool2 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))

  var flatten = Flatten<Float>()
  var inputLayer = Dense<Float>(inputSize: 8 * 8 * 64, outputSize: 512, activation: relu)
  var hiddenLayer = Dense<Float>(inputSize: 512, outputSize: 512, activation: relu)
  var outputLayer = Dense<Float>(inputSize: 512, outputSize: 10)

  @differentiable
  func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    let conv1 = input.sequenced(through: conv1a, conv1b, pool1)
    let conv2 = conv1.sequenced(through: conv2a, conv2b, pool2)
    return conv2.sequenced(through: flatten, inputLayer, hiddenLayer, outputLayer)
  }
}

let batchSize = 128
let epochCount = 12
var model = CIFARModel()
let optimizer = SGD(for: model, learningRate: 0.1)
let dataset = CIFAR10(batchSize: batchSize)

print("Starting training...")

for (epoch, epochBatches) in dataset.training.prefix(epochCount).enumerated() {
  Context.local.learningPhase = .training
  for batch in epochBatches {
    let (images, labels) = (batch.data, batch.label)
    let (_, gradients) = valueWithGradient(at: model) { model -> Tensor<Float> in
      let logits = model(images)
      return softmaxCrossEntropy(logits: logits, labels: labels)
    }
    optimizer.update(&model, along: gradients)
  }

  Context.local.learningPhase = .inference
  var testLossSum: Float = 0
  var testBatchCount = 0
  var correctGuessCount = 0
  var totalGuessCount = 0
  for batch in dataset.validation {
    let (images, labels) = (batch.data, batch.label)
    let logits = model(images)
    testLossSum += softmaxCrossEntropy(logits: logits, labels: labels).scalarized()
    testBatchCount += 1

    let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels
    correctGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())
    totalGuessCount = totalGuessCount + batch.data.shape[0]
  }

  let accuracy = Float(correctGuessCount) / Float(totalGuessCount)
  print(
    """
    [Epoch \(epoch + 1)] \
    Accuracy: \(correctGuessCount)/\(totalGuessCount) (\(accuracy)) \
    Loss: \(testLossSum / Float(testBatchCount))
    """
  )
}
```

```

## 结果

使用这个简单的卷积堆栈，我们的简单模型可以达到 70%以上的精度。这不会很快赢得奖项，但这种基本方法是可行的。您应该会看到类似这样的结果:

```
```
...
[Epoch 1] Accuracy: 4938/10000 (0.4938) Loss: 1.403413
[Epoch 2] Accuracy: 5828/10000 (0.5828) Loss: 1.1972797
[Epoch 3] Accuracy: 6394/10000 (0.6394) Loss: 1.0232711
[Epoch 4] Accuracy: 6857/10000 (0.6857) Loss: 0.92201495
[Epoch 5] Accuracy: 6951/10000 (0.6951) Loss: 0.9035831
[Epoch 6] Accuracy: 6778/10000 (0.6778) Loss: 1.0228367
[Epoch 7] Accuracy: 7082/10000 (0.7082) Loss: 0.95399994
[Epoch 8] Accuracy: 7088/10000 (0.7088) Loss: 1.0445035
[Epoch 9] Accuracy: 7117/10000 (0.7117) Loss: 1.1742744
[Epoch 10] Accuracy: 7183/10000 (0.7183) Loss: 1.347533
[Epoch 11] Accuracy: 7045/10000 (0.7045) Loss: 1.4588598
[Epoch 12] Accuracy: 7132/10000 (0.7132) Loss: 1.5338957
```

```

## 支线任务

研究颜色在现实世界中如何工作以及我们如何感知光是一个有趣的领域。你应该看看 CYMK(例如，打印色彩理论)，然后如何压缩视频(例如，YUV)色彩空间。光源，无论是人造的(如灯泡，发光二极管)，监视器(电视/电脑)，还是天然的(如火，星星)，都会导致各种有趣的差异(氢光谱，哈勃常数)。

## 概述

我们已经从灰度跳到了彩色，并切换到了一个稍大、更复杂的数据集，称为**CIFAR**，但除此之外，我们与上一章相同的方法大致相同。为了更好地对我们的图像进行分类，我们添加了另一个**块* *的卷积。然后，我们使用上一章中的这些多重卷积块和第一章中的相同全连接网络来对现实世界物体的彩色图像进行分类(尽管由于它们很小，看起来有点困难)。接下来，我们将构建同一网络的更大版本，以处理更大的图像和更多的数据。