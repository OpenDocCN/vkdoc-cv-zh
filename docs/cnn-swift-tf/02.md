# 二、MNIST：2D 神经网络

在本章中，我们将通过添加卷积来修改我们的一维神经网络，以产生我们的第一个实际卷积(2D)神经网络，并使用它来再次分类黑白(例如，MNIST)图像。

## 回旋

卷积是计算机视觉理论的一个深入领域。在高层次上，我们可能会想到获取一个输入图像并产生另一个输出图像:

```py
[cat] --> [magic black box] --> [dog]

```

概括地说，对于任何输入图像，都有一种方法可以将其转换为目标图像。在最简单的层面上，我们可以破坏源图像(例如，乘以零)，然后插入目标图像(例如，添加其像素):

```py
[cat] --> 0 * [cat] + [dog] --> [dog]

```

然后，我们可以使用简单的数学方法对中间步骤进行建模:

```py
```a[X] + b```py

```

这块数学叫做内核。这是一个卷积，尽管不是非常有用。

广义地说，对于宇宙中的每一幅图像，我们都可以想出一个内核来将其转换成我们想要的任何其他图像。推而广之，你能想到的任何东西都有一个内核。

一般来说，这是计算机视觉中非常非常深入的研究领域，这里可以做许多不同的事情。

### 3x3 附加模糊示例

接下来，我们来看一个稍微复杂一点的例子，一个 3x3 的加法模糊。实际的内核如下所示:

```py
[ 1, 1, 1 ]
[ 1, 1, 1 ]
[ 1, 1, 1 ]

```

这个卷积将会对输入图像产生一个简单的模糊。这是通过为输入图像中的每个 3x3 像素块创建一个输出像素来实现的，它是我们所看到的 9 个像素的总和。然后，通过使用 1 步的步幅跨过输入图像的行，我们最终得到模糊的最终图像，因为每个输出像素不仅具有来自原始对应像素的信息，还具有来自其邻居的信息。我们所有的产出都比我们开始时的数字要大。我们应用最后一个简单的步骤，通过将所有值除以 9 来产生与原始图像相似的值，从而对结果进行**归一化* *处理。

### 3x3 高斯模糊示例

下一点你不需要 100%理解，我们只是试图建立在概念上。

我们可以改变 3x3 的数据，并保持相同的操作，以产生更复杂的东西。这里有一个我们可以使用的略有不同的乘法内核:

```py
[1/16, 1/8, 1/16]
[1/8, 1/4, 1/8]
[1/16, 1/8, 1/16]

```

然后我们可以用和之前一样的基本方法得到不同的结果。这里，我们利用矩阵乘法来保留更多的中心像素和更远的像素。在 3x3 大小的情况下，很难看出这个例子和我们的第一个例子之间的差异，但如果你可以想象构建上述矩阵的更大版本，这就是在 Photoshop 等图像编辑程序中产生更大高斯模糊的数学。

### 组合 3x3 卷积–Sobel 滤波器示例

对于卷积可以做什么的更高级的例子，让我们看一下将这些内核操作中的两个结合在一起以产生所谓的 Sobel 滤波器。还是那句话，你不需要 100%理解这个。

我们的第一个内核看起来像这样:

```py
[1, 0, -1]
[2, 0, -2]
[1, 0, -1]

```

我们的第二个内核是这样的:

```py
[1, 2, 1]
[0, 0, 0]
[-1, -2, -1]

```

然后我们把它们和我们的输入图像组合在一起，就像这样，一个接一个:

```py
[A] x [B] = [C]

```

结果很有趣；所发生的是相似的像素被乘以零(例如黑色)，但是具有显著差异的像素集合被乘以无穷大(例如白色)。因此，用几个基本的卷积核，我们制作了一个边缘检测器！现在让我们避免陷入更深的回旋兔子洞。只要知道这是一个很深很深的领域，很多事情都有可能。

### 3x3 大步走

非常宽泛地说，我们实际上不会构建我们自己的卷积。相反，我们要让神经网络来学习它们！为此，我们只需要关注一个关键概念，即在这些 3x3 块中检查我们的图像的过程。这叫做大步走，这是一个需要理解的非常重要的概念。基本上，神经网络将学习在飞行中进行自己的卷积，然后使用它们来更好地理解我们的输入数据，然后每一步都将稍微更新它们以改善其结果。别担心，刚开始会有点头脑不稳定。让网络学习一些，然后我们可以看看他们如何在现实世界的例子中工作。

### 填料

“相同”填充和“有效”填充是卷积中会遇到的两种填充形式。在我们的前几章中，我们将使用“相同”的填充，但“有效”是 swift for tensorflow 中 2D 卷积运算符的默认设置，因此您需要理解这两者。

Valid 也许更容易理解。每一步都向前推进，直到卷积的远边缘碰到输入图像的边缘，然后停止。这意味着根据定义，这种卷积类型将产生比输入图像更小的输出(1x1 滤波器的特殊情况除外)。“相同”填充扩展输入数据的边缘以继续在输入图像上工作，直到步幅的前沿达到输入图像的界限。

这意味着“相同”填充(当使用步长为 1 时)将产生与输入图像大小相同的输出图像。在接下来的几章中，我们将使用相同的填充跳转到一些更复杂的模型，所以现在专注于理解它。

### Maxpool(最大池)

您需要理解的另一个关键概念是最大池。我们要做的就是取每组 4 个输入像素，以两个为一组的步幅跨过我们的图像，并通过选择最大值将其转换为单个输出。对于区域，我们只需找到最大的像素，并将其作为我们的输出。

## 2D·MNIST 模型

如果我们把这两个概念放在一起，重新审视 MNIST 问题，我们实际上可以通过改变我们对数据建模的方式来显著提高我们的质量。我们将采用相同的 784，但我们将把它视为实际图像，因此它现在将是 28x28 像素。我们将通过两层 3x3 卷积，一个最大池操作来运行它，然后我们将保持我们相同的密集连接层和十个类别的输出。

### 密码

这是实际的 swift 代码。我已经从前面的例子，并添加了一个顶部的卷积堆栈。然后，我们将输入通过卷积层，然后发送到与之前相同的输出和密集连接层。这将运行一段时间，最终我们将在 MNIST 数据集上达到大约 98%的准确率。因此，通过简单地改变我们对输入数据建模的方式，改用卷积，我们就能够在这个玩具问题上将错误率降低一半。此外，卷积比我们的密集层更容易评估，所以随着我们的数据集开始变大，我们仍然可以继续使用这种方法。

```py
```
import Datasets
import TensorFlow

struct CNN: Layer {
  var conv1a = Conv2D<Float>(filterShape: (3, 3, 1, 32), padding: .same, activation: relu)
  var conv1b = Conv2D<Float>(filterShape: (3, 3, 32, 32), padding: .same, activation: relu)
  var pool1 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))

  var flatten = Flatten<Float>()
  var inputLayer = Dense<Float>(inputSize: 14 * 14 * 32, outputSize: 512, activation: relu)
  var hiddenLayer = Dense<Float>(inputSize: 512, outputSize: 512, activation: relu)
  var outputLayer = Dense<Float>(inputSize: 512, outputSize: 10)

  @differentiable
  public func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    let convolutionLayer = input.sequenced(through: conv1a, conv1b, pool1)
    return convolutionLayer.sequenced(through: flatten, inputLayer, hiddenLayer, outputLayer)
  }
}

let batchSize = 128
let epochCount = 12
var model = CNN()
let optimizer = SGD(for: model, learningRate: 0.1)
let dataset = MNIST(batchSize: batchSize)

print("Starting training...")

for (epoch, epochBatches) in dataset.training.prefix(epochCount).enumerated() {
  Context.local.learningPhase = .training
  for batch in epochBatches {
    let (images, labels) = (batch.data, batch.label)
    let (_, gradients) = valueWithGradient(at: model) { model -> Tensor<Float> in
      let logits = model(images)
      return softmaxCrossEntropy(logits: logits, labels: labels)
    }
    optimizer.update(&model, along: gradients)
  }

  Context.local.learningPhase = .inference
  var testLossSum: Float = 0
  var testBatchCount = 0
  var correctGuessCount = 0
  var totalGuessCount = 0
  for batch in dataset.validation {
    let (images, labels) = (batch.data, batch.label)
    let logits = model(images)
    testLossSum += softmaxCrossEntropy(logits: logits, labels: labels).scalarized()
    testBatchCount += 1

    let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels
    correctGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())
    totalGuessCount = totalGuessCount + batch.data.shape[0]
  }

  let accuracy = Float(correctGuessCount) / Float(totalGuessCount)
  print(
    """
    [Epoch \(epoch + 1)] \
    Accuracy: \(correctGuessCount)/\(totalGuessCount) (\(accuracy)) \
    Loss: \(testLossSum / Float(testBatchCount))
    """
  )
}

```py

您应该会得到如下所示的输出:

```
```py
Loading resource: train-images-idx3-ubyte Loading resource: train-labels-idx1-ubyte Loading resource: t10k-images-idx3-ubyte Loading resource: t10k-labels-idx1-ubyte Starting training...
[Epoch 1] Accuracy: 9657/10000 (0.9657) Loss: 0.11145979
[Epoch 2] Accuracy: 9787/10000 (0.9787) Loss: 0.06319246
[Epoch 3] Accuracy: 9834/10000 (0.9834) Loss: 0.05008082
[Epoch 4] Accuracy: 9860/10000 (0.986) Loss: 0.041191828
[Epoch 5] Accuracy: 9847/10000 (0.9847) Loss: 0.04551203
[Epoch 6] Accuracy: 9856/10000 (0.9856) Loss: 0.04516899
[Epoch 7] Accuracy: 9890/10000 (0.989) Loss: 0.036287367
[Epoch 8] Accuracy: 9860/10000 (0.986) Loss: 0.043286547
[Epoch 9] Accuracy: 9878/10000 (0.9878) Loss: 0.037299085
[Epoch 10] Accuracy: 9877/10000 (0.9877) Loss: 0.042443674
[Epoch 11] Accuracy: 9884/10000 (0.9884) Loss: 0.043763407

[Epoch 12] Accuracy: 9890/10000 (0.989) Loss: 0.038426008
```

```py

### 支线任务

LeNet 是解决 MNIST 问题的经典方法，始于 1998 年。我们使用稍微不同的架构来简化以后向更高级模型的过渡，但是您应该看看这篇文章。

>基于梯度的学习应用于文档识别

```
>  http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf

```

## 概述

我们已经通过一些不同的例子研究了卷积是如何工作的。我们已经了解了**跨步**和*填充* *如何跨越输入图像。然后，我们看了**maxpool**，这是一个减少数据量的简单操作。然后，我们使用两对 3×3 卷积和一个最大池运算，在上一章的多层感知器的基础上，构建了第一个用于图像识别的卷积神经网络。运行与之前相同的训练循环，我们能够减少简单网络中的误差量，通过改变我们对输入数据的建模方式来提高我们的准确性。接下来，让我们看看如何扩展我们相同的基本方法来处理彩色图像和真实世界的数据。