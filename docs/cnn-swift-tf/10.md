# 10.效率网

EfficientNet 是图像识别的最新技术。我怀疑这种情况会永远保持下去，但我不相信它会被轻易取代。它是该领域多年研究的成果，结合了多种不同的技术。我对这个网络特别感兴趣的是，我们看到为移动设备开发的技术在更大的计算机视觉社区中有应用。或者说，为资源受限的设备构建模型的研究正在推动云计算的发展，而历史上的情况恰恰相反。

在高层次上，EfficientNet 是使用 MobileNetV2 的反向剩余块作为架构类型并结合 MnasNet 搜索策略创建的。这些较小的块在 MnasNet 创建时并不存在，通过使用它们，研究人员能够找到一组显著改进的网络。此外，在给定初始起点的情况下，他们能够找到一组可靠的可扩展试探法来构建更大的网络，这是我们在本章前面看到的进化策略的关键限制。

此外，研究人员还添加了其他论文中的两个重要概念:swish 激活功能和 SE(挤压和激发)块。

## 嗖嗖

ReLU 函数，我们在第 [1](01.html) 章介绍过，并不是唯一尝试过的激活函数。无论是在数学层面还是硬件层面，它们的实现都非常简单，性能也非常好，可以说经受住了时间的考验。

>搜索激活功能

```py
> https://arxiv.org/abs/1710.05941

```

本文探讨了各种可选的激活函数，并发现 swish 函数(本文中发现的)在网络中使用时会产生更好的结果。

Swish 在数学上被定义为

```py
```f(x)=x·sigmoid(βx)```py
```sigmoid(y)=1/(1+e^(-y))```py

```

将这两者结合在一起有一个有趣的特性，即在零附近略微变负，而大多数传统的激活函数总是> =零。从概念上讲，这产生了更平滑的梯度空间，并且通过扩展使得网络更容易学习底层数据分布，这转化为提高的准确性。在其他强化学习问题场景中，Swish 已经被证明可以提高性能，所以它是一个重要的激活功能，你应该知道。

从实现的角度来看，swish 有一些限制，即它比简单的 ReLU 使用更多的内存。我们将在下一章回到这一点。

## SE(挤压+激励)块

这是一篇来自 2017 年牛津视觉几何小组(例如，制作 VGG 的人)的有趣论文，该论文赢得了当年的 ImageNet 竞赛。

>挤压和激励网络

```py
> https://arxiv.org/abs/1709.01507

```

从概念上讲，我们可能会认为我们的神经网络实际上正在学习的是一组特征。然后，当网络看到符合特定特征集合的图片时，我们训练它激发特定的神经元。为了让事情更上一层楼，避免随机激活，理想情况下，对于每个特征图，我们可以定义一种主神经元，决定该特征是否应该作为一个整体激活。

这大致就是挤压和激励块的概念。通过获取特征输入并将其显著减少(在某些情况下减少到单个像素)，我们允许网络对每个块进行某种训练，以教会自己在给定特定输入的情况下是否应该触发。这产生了最先进的结果，但也是计算昂贵的。

EfficientNet 使用了一个更简单的变体，它基于两个卷积的组合，以更低的计算成本产生类似的结果。

## 密码

请注意 squeeze 和 excite 模块，以及它们如何用于提高卷积模块的结果。通过这一添加，该主干的其余部分与 MobileNet v2 非常相似。还要看看 MBConvBlockStack 生成器参数的细微差别，我们将在下一章中看到更多。

```py
```
import TensorFlow

struct InitialMBConvBlock: Layer {
  @noDerivative var hiddenDimension: Int
  var dConv: DepthwiseConv2D<Float>
  var batchNormDConv: BatchNorm<Float>
  var seAveragePool = GlobalAvgPool2D<Float>()
  var seReduceConv: Conv2D<Float>
  var seExpandConv: Conv2D<Float>
  var conv2: Conv2D<Float>
  var batchNormConv2: BatchNorm<Float>

  init(filters: (Int, Int), width: Float) {
    let filterMult = filters
    self.hiddenDimension = filterMult.0
    dConv = DepthwiseConv2D<Float>(
      filterShape: (3, 3, filterMult.0, 1),
      strides: (1, 1),
      padding: .same)
    seReduceConv = Conv2D<Float>(
      filterShape: (1, 1, filterMult.0, 8),
      strides: (1, 1),
      padding: .same)
    seExpandConv = Conv2D<Float>(
      filterShape: (1, 1, 8, filterMult.0),
      strides: (1, 1),
      padding: .same)
    conv2 = Conv2D<Float>(
      filterShape: (1, 1, filterMult.0, filterMult.1),
      strides: (1, 1),
      padding: .same)
    batchNormDConv = BatchNorm(featureCount: filterMult.0)
    batchNormConv2 = BatchNorm(featureCount: filterMult.1)
  }

  @differentiable
  func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    let depthwise = swish(batchNormDConv(dConv(input)))
    let seAvgPoolReshaped = seAveragePool(depthwise).reshaped(to: [
      input.shape[0], 1, 1, self.hiddenDimension,
    ])
    let squeezeExcite =
      depthwise
      * sigmoid(seExpandConv(swish(seReduceConv(seAvgPoolReshaped))))
    return batchNormConv2(conv2(squeezeExcite))
  }
}

struct MBConvBlock: Layer {
  @noDerivative var addResLayer: Bool
  @noDerivative var strides: (Int, Int)
  @noDerivative let zeroPad = ZeroPadding2D<Float>(padding: ((0, 1), (0, 1)))
  @noDerivative var hiddenDimension: Int

  var conv1: Conv2D<Float>
  var batchNormConv1: BatchNorm<Float>
  var dConv: DepthwiseConv2D<Float>
  var batchNormDConv: BatchNorm<Float>
  var seAveragePool = GlobalAvgPool2D<Float>()
  var seReduceConv: Conv2D<Float>
  var seExpandConv: Conv2D<Float>
  var conv2: Conv2D<Float>
  var batchNormConv2: BatchNorm<Float>

  init(
    filters: (Int, Int),
    width: Float,
    depthMultiplier: Int = 6,
    strides: (Int, Int) = (1, 1),
    kernel: (Int, Int) = (3, 3)
  ) {
    self.strides = strides
    self.addResLayer = filters.0 == filters.1 && strides == (1, 1)

    let filterMult = filters
    self.hiddenDimension = filterMult.0 * depthMultiplier
    let reducedDimension = max(1, Int(filterMult.0 / 4))
    conv1 = Conv2D<Float>(
      filterShape: (1, 1, filterMult.0, hiddenDimension),
      strides: (1, 1),
      padding: .same)
    dConv = DepthwiseConv2D<Float>(
      filterShape: (kernel.0, kernel.1, hiddenDimension, 1),
      strides: strides,
      padding: strides == (1, 1) ? .same : .valid)
    seReduceConv = Conv2D<Float>(
      filterShape: (1, 1, hiddenDimension, reducedDimension),
      strides: (1, 1),
      padding: .same)
    seExpandConv = Conv2D<Float>(
      filterShape: (1, 1, reducedDimension, hiddenDimension),
      strides: (1, 1),
      padding: .same)
    conv2 = Conv2D<Float>(
      filterShape: (1, 1, hiddenDimension, filterMult.1),
      strides: (1, 1),
      padding: .same)
    batchNormConv1 = BatchNorm(featureCount: hiddenDimension)
    batchNormDConv = BatchNorm(featureCount: hiddenDimension)
    batchNormConv2 = BatchNorm(featureCount: filterMult.1)
  }

  @differentiable
  func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    let piecewise = swish(batchNormConv1(conv1(input)))
    var depthwise: Tensor<Float>
    if self.strides == (1, 1) {
      depthwise = swish(batchNormDConv(dConv(piecewise)))
    } else {
      depthwise = swish(batchNormDConv(dConv(zeroPad(piecewise))))
    }
    let seAvgPoolReshaped = seAveragePool(depthwise).reshaped(to: [
      input.shape[0], 1, 1, self.hiddenDimension,
    ])
    let squeezeExcite =
      depthwise
      * sigmoid(seExpandConv(swish(seReduceConv(seAvgPoolReshaped))))
    let piecewiseLinear = batchNormConv2(conv2(squeezeExcite))

    if self.addResLayer {
      return input + piecewiseLinear
    } else {
      return piecewiseLinear
    }
  }
}

struct MBConvBlockStack: Layer {
  var blocks: [MBConvBlock] = []

  init(
    filters: (Int, Int),
    width: Float,
    initialStrides: (Int, Int) = (2, 2),
    kernel: (Int, Int) = (3, 3),
    blockCount: Int,
    depth: Float
  ) {
    let blockMult = blockCount
    self.blocks = [
      MBConvBlock(
        filters: (filters.0, filters.1), width: width,
        strides: initialStrides, kernel: kernel)
    ]
    for _ in 1..<blockMult {
      self.blocks.append(
        MBConvBlock(
          filters: (filters.1, filters.1),
          width: width, kernel: kernel))
    }
  }

  @differentiable
  func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    return blocks.differentiableReduce(input) { $1($0) }
  }
}

public struct EfficientNet: Layer {
  @noDerivative let zeroPad = ZeroPadding2D<Float>(padding: ((0, 1), (0, 1)))
  var inputConv: Conv2D<Float>
  var inputConvBatchNorm: BatchNorm<Float>
  var initialMBConv: InitialMBConvBlock

  var residualBlockStack1: MBConvBlockStack
  var residualBlockStack2: MBConvBlockStack
  var residualBlockStack3: MBConvBlockStack
  var residualBlockStack4: MBConvBlockStack
  var residualBlockStack5: MBConvBlockStack
  var residualBlockStack6: MBConvBlockStack

  var outputConv: Conv2D<Float>
  var outputConvBatchNorm: BatchNorm<Float>
  var avgPool = GlobalAvgPool2D<Float>()
  var dropoutProb: Dropout<Float>
  var outputClassifier: Dense<Float>

  public init(
    classCount: Int = 1000,
    width: Float = 1.0,
    depth: Float = 1.0,
    resolution: Int = 224,
    dropout: Double = 0.2
  ) {
    inputConv = Conv2D<Float>(
      filterShape: (3, 3, 3, 32),
      strides: (2, 2),
      padding: .valid)
    inputConvBatchNorm = BatchNorm(featureCount: 32)

    initialMBConv = InitialMBConvBlock(filters: (32, 16), width: width)

    residualBlockStack1 = MBConvBlockStack(
      filters: (16, 24), width: width,
      blockCount: 2, depth: depth)
    residualBlockStack2 = MBConvBlockStack(
      filters: (24, 40), width: width,
      kernel: (5, 5), blockCount: 2, depth: depth)
    residualBlockStack3 = MBConvBlockStack(
      filters: (40, 80), width: width,
      blockCount: 3, depth: depth)
    residualBlockStack4 = MBConvBlockStack(
      filters: (80, 112), width: width,
      initialStrides: (1, 1), kernel: (5, 5), blockCount: 3, depth: depth)
    residualBlockStack5 = MBConvBlockStack(
      filters: (112, 192), width: width,
      kernel: (5, 5), blockCount: 4, depth: depth)
    residualBlockStack6 = MBConvBlockStack(
      filters: (192, 320), width: width,
      initialStrides: (1, 1), blockCount: 1, depth: depth)

    outputConv = Conv2D<Float>(
      filterShape: (
        1, 1,
        320, 1280
      ),
      strides: (1, 1),
      padding: .same)
    outputConvBatchNorm = BatchNorm(featureCount: 1280)

    dropoutProb = Dropout<Float>(probability: dropout)
    outputClassifier = Dense(inputSize: 1280, outputSize: classCount)
  }

  @differentiable
  public func forward(_ input: Tensor<Float>) -> Tensor<Float> {
    let convolved = swish(input.sequenced(through: zeroPad, inputConv, inputConvBatchNorm))
    let initialBlock = initialMBConv(convolved)
    let backbone = initialBlock.sequenced(
      through: residualBlockStack1, residualBlockStack2,
      residualBlockStack3, residualBlockStack4, residualBlockStack5, residualBlockStack6)
    let output = swish(backbone.sequenced(through: outputConv, outputConvBatchNorm))
    return output.sequenced(through: avgPool, dropoutProb, outputClassifier)
  }
}
```py

```

## 结果

这个网络训练得非常好，在没有添加任何数据增强技术的情况下，比我们迄今为止看到的任何网络都具有更高的准确性。

```py
Starting training...
[Epoch 1 ] Accuracy: 50/500  (0.1)   Loss: 3.919964
[Epoch 2 ] Accuracy: 315/500 (0.63)  Loss: 1.1730766
[Epoch 3 ] Accuracy: 340/500 (0.68)  Loss: 1.042603
[Epoch 4 ] Accuracy: 382/500 (0.764) Loss: 0.7738381
[Epoch 5 ] Accuracy: 358/500 (0.716) Loss: 0.8867168
[Epoch 6 ] Accuracy: 397/500 (0.794) Loss: 0.7941174
[Epoch 7 ] Accuracy: 384/500 (0.768) Loss: 0.7910826
[Epoch 8 ] Accuracy: 375/500 (0.75)  Loss: 0.9265955
[Epoch 9 ] Accuracy: 395/500 (0.79)  Loss: 0.7806258
[Epoch 10] Accuracy: 389/500 (0.778) Loss: 0.8921993
[Epoch 11] Accuracy: 393/500 (0.786) Loss: 0.913636
[Epoch 12] Accuracy: 395/500 (0.79)  Loss: 0.8772738
[Epoch 13] Accuracy: 396/500 (0.792) Loss: 0.819137
[Epoch 14] Accuracy: 393/500 (0.786) Loss: 0.7435807
[Epoch 15] Accuracy: 418/500 (0.836) Loss: 0.6915679
[Epoch 16] Accuracy: 404/500 (0.808) Loss: 0.79288286
[Epoch 17] Accuracy: 405/500 (0.81)  Loss: 0.8690043
[Epoch 18] Accuracy: 404/500 (0.808) Loss: 0.89440507
[Epoch 19] Accuracy: 409/500 (0.818) Loss: 0.85941887

[Epoch 20] Accuracy: 408/500 (0.816) Loss: 0.8633226
[Epoch 21] Accuracy: 404/500 (0.808) Loss: 0.7646436
[Epoch 22] Accuracy: 411/500 (0.822) Loss: 0.8865621
[Epoch 23] Accuracy: 424/500 (0.848) Loss: 0.6812671
[Epoch 24] Accuracy: 402/500 (0.804) Loss: 0.8662841
[Epoch 25] Accuracy: 425/500 (0.85)  Loss: 0.7081538
[Epoch 26] Accuracy: 423/500 (0.846) Loss: 0.7106852
[Epoch 27] Accuracy: 411/500 (0.822) Loss: 0.88567644
[Epoch 28] Accuracy: 410/500 (0.82)  Loss: 0.8509838
[Epoch 29] Accuracy: 409/500 (0.818) Loss: 0.85791296
[Epoch 30] Accuracy: 416/500 (0.832) Loss: 0.76689

```

### 高效网络变体

一旦我们有了这个基础，我们就可以使用我们改进的图像识别网络来解决不同领域的其他相关问题。

### 效率网[B1-8]

回顾我们在上一章对网络架构搜索功能的探索，这类方法的问题在于，试图扩大搜索功能很困难，因为没有一个清晰的系统来扩大搜索功能。

作者在本文中介绍的是他们的基本(B0)网络的一组缩放试探法，使平滑缩放能够产生越来越大的网络。不严格地说，我们可以说大型网络的每一步都需要大量的计算。然后，只要有大量的计算时间运行，我们就可以持续地构建大型网络。因此，这是高效网络的变体，可以通过简单地将我们之前的网络与我们在本书中迄今为止看到的各种网络进行比较来产生。

### 随机扩增

> RandAugment:实用的自动数据扩充，减少了搜索空间

```py
> https://arxiv.org/abs/1909.13719

```

我们在前一章中简要讨论了数据扩充，我提到这是一个活跃的研究领域。本文结合了各种增强技术(例如，翻转、旋转、缩放等。)与强化学习算法一起使用，以便在应用于数据集时找到数据扩充过滤器的最佳(用最小的集合对准确度的最大影响)组合。然后，他们对 ImageNet 数据集运行这种学习到的算法，然后在其上训练 EfficientNet 变体，以产生显著的(~ 4–5%！)仅使用计算时间的改进的网络集。

### 吵闹的学生

>嘈杂学生的自我培训提高了 ImageNet 分类

```py
> https://arxiv.org/abs/1911.04252

```

接下来，**网络提炼* *是构建小型网络的一个有趣的研究领域。大致来说，我们将一个大型网络作为教师，然后训练一个较小的学生网络，在给定相同输入和来自教师的每个答案的反馈的情况下，对较大的网络给出类似的响应。例如，一旦一种更大的方法在 GPU 集群上证明了自己，这在为资源有限的设备构建网络方面具有有趣的应用。这是自然语言处理中感兴趣的大领域，其中大型网络(例如 BERT)已经实现了最先进的性能，但是太大而不能用于日常问题解决。

网络蒸馏已经被用来使网络变小，但是它能被用来使网络变大吗？粗略地说，这篇论文采用了数据增强技术，并使用它们来使学生的输入更加嘈杂，但仍然要求学生网络给出与老师的答案相匹配的答案。通过在老师身上迭代训练一个更大的学生，然后用训练过的学生代替老师，他们能够建立一个更大的网络，能够产生甚至比脸书 2019 年 10 亿张图片的 Instagram 语料库更准确的 ImageNet 结果(见 [`https://arxiv.org/abs/1905.00546`](https://arxiv.org/abs/1905.00546) )。

### 效率检测

> EfficientDet:可扩展且高效的对象检测

```py
> https://arxiv.org/abs/1911.09070

```

我们在本书中没有谈到物体检测网络，但许多方法的基本思想是使用已知良好的现有图像识别网络(称为**主干**)，然后我们可以在最后添加物体检测输出层(称为* *头部* *)。这种方法实现了一种很好的混合和匹配风格的技术，在这种技术中，我们可以使用具有多个不同主干或数据增强策略的同一个头来找到特定问题的最佳解决方案。

因此，我们采用 EfficientNet，添加一个定制的对象检测头，应用我们的缩放技术，瞧，我们有一个对象检测(以及一些其他调整，语义分段)网络，具有最先进的性能。

## 概述

我们看了 EfficientNet，这是图像识别的最新技术。我们已经了解了如何使用 EfficientNet 基础在相关领域构建最先进的方法。接下来，让我们看看如何将这些想法带回移动设备领域。