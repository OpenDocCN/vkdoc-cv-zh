# 1.计算机视觉中的识别

大多数计算机科学研究试图建造一个像人类一样的机器人，能够完全像人类一样工作。甚至情感属性对于这样的机器人来说也不是不可能的。使用传感器，机器人可以感觉到周围环境的温度。利用面部表情，有可能知道一个人是悲伤还是快乐。即使是看似不可能的事情，最终也只会变得具有挑战性。

目前，一个非常具有挑战性的应用是对象识别。识别可以基于不同类型的数据，例如音频、图像和文本。但是图像识别是一种非常有效的方法，因为它有丰富的信息可以帮助我们完成任务。因此，它被认为是计算机视觉中最受欢迎的应用。

世界上存在大量的物体，区分它们是一项复杂的任务。除了细微的细节之外，不同的物体可能具有相似的视觉外观。此外，同一物体基于其周围环境而呈现出不同的外观。例如，根据光线、视角、扭曲和遮挡，同一对象在图像中会以不同的方式出现。根据原始图像，像素可能不是图像识别的好选择。这是因为每个像素的微小变化都会导致图像的重大变化，因此系统无法正确识别对象。目标是找到一组独特的属性或特征，只要对象的结构出现在图像中的某个地方，这些属性或特征即使随着像素位置或值的改变也不会改变。从图像中手动提取特征是图像识别中的一大挑战。这就是为什么自动特征提取方法正在成为一种选择。

因为在当前任何环境中识别任何对象都是复杂的，所以另一种方法是限制环境或目标对象。例如，我们可以不识别所有类型的动物，而只锁定其中的一组。与其在室内和室外工作，我们可以将环境限制在室内图像。我们可能只处理一些视图，而不是识别不同视图中的对象。一般来说，创建一个狭义的人工智能应用程序，虽然具有挑战性，但比一般的人工智能应用程序更容易，困难也更少。

本章讨论如何构建一个识别应用程序来对水果图像进行分类。它首先介绍一些对不同类型的应用程序普遍有用的特性，然后找出这些特性中最好的一个用于我们的目标应用程序。到本章结束时，我们将发现为什么手动提取特征是具有挑战性的，以及为什么使用卷积神经网络(CNN)的自动特征挖掘是首选的。

## 图像识别管道

与大多数传统的识别应用程序类似，图像识别可能会遵循一些预定义的步骤，从接受输入到返回所需的结果。这些步骤的总结如图 [1-1](#Fig1) 所示。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig1_HTML.jpg](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig1_HTML.jpg)

图 1-1

通用识别管道

有时输入图像的当前形式不适合处理。例如，如果我们要构建一个面部识别应用程序，该应用程序在复杂的环境中捕获图像以识别其中的人，那么在开始识别目标对象之前，最好先去除背景。在这种情况下，背景去除是一种预处理。通常，实际工作之前的任何步骤都称为预处理。预处理是使成功识别的概率最大化的步骤。

准备好输入后，我们开始实际工作，从特征提取或挖掘开始。这是大多数识别应用中的关键步骤。目标是找到一组能够准确描述每个输入的代表性特征。这样的一组特征应该最大化将每个输入映射到其正确输出的概率，并且最小化将每个输入分配给错误标签的概率。因此，应该对要使用的功能类型进行分析。

应用程序和所使用的功能集是相关的。基于应用选择特征。通过了解应用程序的性质，所需的功能类型将很容易被发现。对于人脸检测这样的应用，需要提取哪些特征？人脸具有各种颜色的皮肤，因此我们可以确定皮肤颜色是要使用的特征。知道该应用是在灰度户外图像、低照明和移动环境中检测人脸有助于选择适当的特征。如果要求您构建一个识别橙子和香蕉的应用程序，您可以从橙子和香蕉具有不同颜色的事实中受益，从而决定仅使用颜色特征就足够了。例如，它们不足以识别不同类型的皮肤癌。必须做更多的工作来找到最合适的特性集。下一节标题为**特征提取**讨论了一些在图像识别应用中有帮助的特征。

在创建了包含可能在识别应用中有用的特征的特征向量之后，我们进入添加进一步增强的其他步骤，即特征选择和减少。特征选择和减少的主要目标可以被定义为从一组特征中获得最佳特征子集，其通过减少不相关、相关和噪声特征的数量来增强学习算法的性能或准确性。标题为**特征选择&减少**的章节讨论了通过去除这些特征来减少特征向量长度的方法。

## 特征抽出

将图像以其原始形式作为输入应用于训练模型是不常见的。为什么提取特征是一种更好的方法，有不同的原因。一个原因是图像，即使是小图像，也有大量的像素，每个像素都作为模型的输入。对于大小为 100×100 像素的灰度图像，有 100×100 = 10，000 个输入变量要应用于模型。对于包含 100 个样本的小型数据集，整个数据集总共有 100×10，000 = 1，000，000 个输入。如果图像是红绿蓝(RGB)，总数乘以 3。这除了计算量大之外，还需要大的存储器。

在训练之前优选特征提取的另一个原因是，输入图像具有不同类型的具有不同属性的对象，并且我们只想针对单个对象。例如，图 [1-2(a)](#Fig2) 显示了“狗与猫 Kaggle”比赛中一只狗的图像。我们的目标是发现狗，我们不关心树林或草地。如果将完整的图像用作模型的输入，木材和草地将会影响结果。最好只使用专属于狗的功能。从图 [1-2(b)](#Fig2) 可以明显看出，狗的颜色不同于图像中的其他颜色。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig2_HTML.jpg](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig2_HTML.jpg)

图 1-2

使用特征时，锁定图像中的特定对象更容易

通常，问题的成功建模依赖于最佳特征的选择。数据科学家应该为正在解决的问题选择最具代表性的功能集。有不同类型的特征用于描述图像。这些特征可以以不同的方式分类。一种方法是检查它们是从图像中的特定区域全局还是局部提取的。局部特征是诸如边缘和关键点的那些特征。全局特征是诸如颜色直方图和像素计数之类的特征。全局意味着该特征描述了整个图像。说颜色直方图在左侧区域居中意味着整个图像是暗的。该描述不仅仅针对图像的特定区域。局部特征集中在图像中的特定部分，例如边缘。

后续小节将讨论以下特性:

*   颜色直方图

*   边缘
    *   猪

*   纹理
    *   [军]GroundLaunchedCruiseMissile

    *   梯度共生矩阵

    *   垂直线间的距离

### 颜色直方图

颜色直方图表示颜色在图像中的分布。它通常用于灰色图像，但也有修改用于彩色图像。为简单起见，让我们计算图 [1-3](#Fig3) 中 5×5 2 位图像的颜色直方图。该图像只有 4 个灰度级。图像是使用 NumPy 随机生成的。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig3_HTML.png](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig3_HTML.png)

图 1-3

尺寸为 5×5 的两位灰度图像

通过计算每个灰度级的频率，直方图如图 [1-4](#Fig4) 所示。基于直方图，很明显高频箱位于右侧，因此图像是明亮的，因为其大多数像素是高的。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig4_HTML.jpg](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig4_HTML.jpg)

图 1-4

2 位 5×5 灰度图像的直方图

清单 [1-1](#PC1) 给出了 Python 代码，除了计算和显示直方图之外，还用来随机生成前面的小图像。

```py
import matplotlib.pyplot
import numpy

rand_img = numpy.random.uniform(low=0, high=3, size=(5,5))
rand_img = numpy.uint8(rand_img)
hist = numpy.histogram(rand_img, bins=4)
matplotlib.pyplot.bar(left=[0,1,2,3], height=hist[0], align="center", width=0.3)
matplotlib.pyplot.xticks([0,1,2,3], fontsize=20)
matplotlib.pyplot.yticks(numpy.arange(0, 15, 2), fontsize=20)

Listing 1-1Histogram for a Tiny Randomly Generated Image

```

`numpy.random.uniform()`除了接受图像像素赋值范围的上限和下限之外，还接受要返回的数组大小。下限为 0，上限为 3，因为我们希望创建一个 2 位映像。`numpy.uint8()`用于将浮点值转换为整数。然后，使用`numpy.histogram()`计算直方图，它接受图像和箱数，并返回每个级别的频率。最后，`matplotlib.pyplot.bar()`用于返回一个条形图，在 x 轴上显示每个级别，在 y 轴上显示其频率。`matplotlib.pyplot.xticks()`和`matplotlib.pyplot.yticks()`用于改变 x 轴和 y 轴的范围以及显示字体大小。

#### 真实世界图像的直方图

让我们在将现实世界的图像转换成黑白图像后，计算如图 [1-2(a)](#Fig2) 所示的直方图。灰度图像和直方图如图 [1-5](#Fig5) 所示。似乎直方图大多集中在左侧部分，这意味着图像普遍较暗。因为狗的身体是白色的，所以部分直方图位于直方图分布的最右边。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig5_HTML.jpg](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig5_HTML.jpg)

图 1-5

灰度图像直方图

清单 [1-2](#PC2) 给出了读取彩色图像、将其转换为灰度、计算其直方图并最终将直方图绘制成条形图的 Python 代码。

```py
import matplotlib.pyplot
import numpy
import skimage.io

im = skimage.io.imread("69.jpg", as_grey=True)
im = numpy.uint8(im*255)

hist = numpy.histogram(im, bins=256)
matplotlib.pyplot.bar(left=numpy.arange(256), height= hist[0], align="center", width=0.1)

Listing 1-2Histogram for a Real-World Image

```

使用`skimage.io.imread()`功能，使用`as_grey`属性读取图像并将其转换为灰度。当设置为`True`时，图像以灰度返回。返回的图像数据类型为`float64`。为了将它转换成范围从 0 到 255 的无符号整数，使用了`numpy.uint8()`。图像在转换前首先乘以 255，因为`numpy.uint8()`不会改变输入的比例。它只是确保数字是由 8 位表示的整数。例如，将等于 0.7 的数字应用于该函数，结果为 0。我们希望将 0.4 从 0–1 范围重新调整到 0–255 范围，然后将其转换为 uint8。如果不将输入乘以 255，所有的值将只是 0 或 1。注意，直方图仓的数量被设置为 256，而不是上例中的 4，因为图像被表示为 8 位。

#### HSV 颜色空间

颜色直方图是指将图像像素表示在其中一个颜色空间中，然后统计这些颜色空间中存在的级别的频率。以前，图像是在 RGB 颜色空间中表示的，每个通道的颜色范围从 0 到 255。但是这不是唯一存在的颜色空间。

我们将涉及的另一个颜色空间是 HSV(色调-饱和度-值)。这个颜色空间的优点是颜色和照明信息的分离。色调通道保存颜色信息，其他通道(饱和度和值)指定颜色的亮度。以颜色而不是照明为目标并创建照明不变的特征是有用的。我们不会在本书中涉及 HSV 色彩空间，但是阅读更多关于如何使用 HSV 生成颜色的内容是很好的。值得一提的是，色调通道表示一个圆，其值在 0 到 360 之间，其中 0 度表示红色，120 度表示绿色，240 度表示蓝色，360 度返回红色。所以，它以红色开始和结束。

对于图 [1-2(a)](#Fig2) 中的图像，色调通道及其直方图如图 [1-6](#Fig6) 所示。当色调通道被表示为如图 [1-6(a)](#Fig6) 所示的灰度图像时，红色将被赋予高值(白色)，如狗项圈所示。因为蓝色被赋予 240 的高色调值，所以它在灰度图像中更亮。色调值为 140 的绿色比 360 更接近 0；因此，它的颜色很深。请注意，狗的身体在 RGB 颜色空间中是白色的，在 HSV 中看起来是黑色的。原因是 HSV 不负责强度，而只负责颜色。在价值通道中会是白色的。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig6_HTML.jpg](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig6_HTML.jpg)

图 1-6

用 HSV 表示的彩色图像的色调通道及其直方图

根据清单 [1-3](#PC3) ，RGB 图像被转换到 HSV 颜色空间并显示其色调通道直方图。

```py
import matplotlib.pyplot
import numpy
import skimage.io
import skimage.color

im = skimage.io.imread("69.jpg", as_grey=False)

im_HSV = skimage.color.rgb2hsv(im)
Hue = im_HSV[:, :, 0]

hist = numpy.histogram(Hue, bins=360)
matplotlib.pyplot.bar(left=numpy.arange(360), height=hist[0], align="center", width=0.1)

Listing 1-3Displaying the Image Histogram Using Matplotlib

```

因为色调通道是 HSV 颜色空间中的第一个通道，所以它被赋予索引 0 以获得返回。

对于不同的图像，特征应该是唯一的。如果不同的图像具有相同的特征，结果将是不准确的。颜色直方图有这样的缺点，因为它对于不同的图像可能是相同的。原因是颜色直方图只计算颜色的频率，不管它们在图像中的排列如何。图 [1-7(a)](#Fig7) 调换了图 [1-3](#Fig3) 中的图像。从图 [1-7(b)](#Fig7) 可以看出，尽管像素位置不同，但是图像在转置前后的直方图是相同的。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig7_HTML.jpg](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig7_HTML.jpg)

图 1-7

改变像素位置不会改变颜色直方图

人们可能认为这不是问题，因为一个好的特征描述符应该保持持久，即使图像发生了变化，如旋转和缩放。颜色直方图不能满足这个属性，因为即使图像完全不同，它也返回相同的直方图。为了解决这个问题，应该考虑像素强度和位置，以返回更有代表性的特征。这种特征的例子是纹理特征，例如 GLCM。

### [军]GroundLaunchedCruiseMissile

一种流行的统计纹理分析方法依赖于从像素对之间的空间关系中提取的二阶统计量。这些特征中最流行的是从共现矩阵(CM)中提取的特征。其中一个 CMs 是灰度共生矩阵(GLCM)。根据其名称，它接受灰度图像作为输入，并返回 GLCM 矩阵作为输出。

GLCM 可以描述为二维直方图，它根据每对灰度级之间的距离来计算它们之间的共现次数。GLCM 与一阶直方图的不同之处在于，GLCM 不仅取决于强度，还取决于像素的空间关系。对于每两个像素，一个称为参考，另一个称为邻居。当两个强度级别之间的距离为 D 且角度为θ时，GLCM 会找出两个强度级别同时出现的次数。 *GLCM* <sub>(1，3)，D = 1，θ = 0</sub> 是指强度值为 1 的参考像素与其强度为 3 的邻居相隔距离 D = 1，角度θ= 0<sup>T5 时共现的次数。当θ = 0 时，这意味着它们在同一水平线上。θ指定方向，D 指定该方向的距离。请注意，引用位于邻居的左侧。</sup>

计算 GLCM 的步骤如下:

1.  如果输入图像是灰度或二进制的，直接使用它。如果是彩色图像，将其转换为灰度图像，或者在适当的情况下只使用其中一个通道。

2.  找出图像中强度等级的总数。如果数字为 L，则从 0 到 L-1 对这些级别进行编号。

3.  创建一个 LxL 矩阵，其中行和列的编号都是从 0 到 L 1。

4.  选择合适的 GLCM 参数(D，θ)。

5.  找出每两对强度等级之间的同现。

#### d 值

研究表明 D 的最佳值在 1 到 10 之间。较大的值将产生无法捕捉详细纹理信息的灰度共生矩阵。因此，对于 D=1，2，4，8，结果是准确的，D=1，2 是最好的。通常，一个像素可能与其附近的像素更相关。减小距离比增大距离会产生更好的结果。

#### θ值

对于 3×3 矩阵，中心像素有 8 个相邻像素。在这样的中心像素和所有其他 8 个像素之间，θ有 8 个可能的值，如图 [1-8](#Fig8) 所示。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig8_HTML.png](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig8_HTML.png)

图 1-8

中心像素与其八个相邻像素之间的θ值

因为选择θ设置为 0°和 180°得到的共现对是相等的(即 *GLCM* <sub>(1，3)，θ = 0</sub> = *GLCM* <sub>(3，1)，θ= 180°</sub>，只需要一个角度就足够了。通常，相隔 180°的角度会返回相同的结果。这适用于角度(45，225)，(135，315)和(90，270)。

当 D=1 且θ=0 时，让我们开始计算图 [1-3](#Fig3) 中的前一矩阵的 GLCM，在下面的矩阵中再次重复。因为该图像具有四个强度级别，所以当参考强度为 0 时，可用的对是(0，0)、(0，1)、(0，2)和(0，3)。当参考强度为 1 时，则配对为(1，0)、(1，1)、(1，2)和(1，3)。这种情况持续到 2 和 3。

<colgroup><col class="tcol1 align-center"> <col class="tcol2 align-center"> <col class="tcol3 align-center"> <col class="tcol4 align-center"> <col class="tcol5 align-center"></colgroup> 
| three | Two | Two | Zero | three |
| one | three | Zero | Two | Two |
| Two | Two | Two | Two | three |
| three | three | three | Two | three |
| Zero | Two | three | Two | Two |

计算 *GLCM* <sub>(0，0)，D = 1，θ = 0</sub> ，数值将为 0。这是因为没有强度为 0 的像素与另一个强度为 0 的像素水平相距 1 个像素。对于对(0，1)、(1，0)、(1，1)、(1，2)、(2，1)和(3，1)，结果也是 0。

对于 *GLCM* <sub>(0，2)，D = 1，θ = 0</sub> ，结果是 2，因为有三次强度 3 位于水平方向上距离强度 0 1 个像素的位置(即θ = 0 )。对于 *GLCM* <sub>(3，3)，D = 1，θ = 0</sub> ，结果也是 2。对于 *GLCM* <sub>(0，3)，D = 1，θ = 0</sub> ，结果为 1，因为强度 3 只出现一次，距离强度 0 为 1，角度为 0。这位于原始矩阵的右上方。

完整的 GLCM 如图 [1-9](#Fig9) 所示。该矩阵的大小为 4×4，因为它具有从 0 到 3 编号的 4 个强度等级。添加行和列标签是为了更容易知道哪个强度级别与另一个强度级别同时出现。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig9_HTML.png](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig9_HTML.png)

图 1-9

图 [1-3](#Fig3) 中距离为 1，角度为 0 的矩阵的 GLCM

清单 [1-4](#PC4) 中给出了用于返回前面的 GLCM 的 Python 代码。

```py
import numpy
import skimage.feature

arr = numpy.array([[3, 2, 2, 0, 3],
                   [1, 3, 0, 2, 2],
                   [2, 2, 2, 2, 3],
                   [3, 3, 3, 2, 3],
                   [0, 2, 3, 2, 2]])

co_mat = skimage.feature.greycomatrix(image=arr, distances=[1], angles=[0], levels=4)

Listing 1-4GLCM Matrix Calculation

```

`skimage.feature.greycomatrix()`用于计算 GLCM。它接受输入图像、距离、计算矩阵的角度，最后是使用的级数。级别的数量很重要，因为默认值是 256。

请注意，每对唯一的角度和距离都有一个矩阵。只使用了一个角度和距离，因此返回了一个 GLCM 矩阵。返回输出的形状有四个数字，如下所示:

```py
co_mat.shape = (4, 4, 1, 1)

```

前两个数字分别代表行数和列数。第三个数字代表使用的距离数。最后一个是角度数。如果要计算更多距离和角度的矩阵，则在`skimage.feature.greycomatrix()`中指定。下一行使用两个距离和三个角度计算 GLCM。

```py
co_mat = skimage.feature.greycomatrix(image=arr, distances=[1, 4], angles=[0, 45, 90], levels=4)

```

返回的矩阵的形状是

```py
co_mat.shape = (4, 4, 2, 3)

```

因为有两个距离和三个角度，所以返回的 GLCMs 总数为 2×3 = 6。要在距离 1 和角度 0 处返回 GLCM，步进如下:

```py
co_mat[:, :, 0, 0]

```

这将返回完整的 4×4 GLCM，但仅针对第一个距离(1)和第一个角度(0)，根据它们在`skimage.feature.greycomatrix()`函数中的顺序。为了返回对应于距离 4 和角度 90<sup>T2 的 GLCM，索引将如下:</sup>

```py
co_mat[:, :, 1, 2]

```

#### GLCM 归一化

先前计算的 GLCMs 对于了解每个强度等级彼此共出现多少次是有用的。我们可以从这些信息中受益，以预测每两个强度级别之间的同现概率。GLCM 可以被转换成概率矩阵，因此我们可以知道当被距离 D 和角度θ分开时，两个强度等级 *l* <sub>1</sub> 和*l*T6】2 中的每一个之间的同现概率。这是通过将矩阵中的每个元素除以矩阵元素的总和来实现的。由此产生的矩阵被称为规范化或概率矩阵。根据图 [1-9](#Fig9) ，所有元素的总和为 20。将每个元素除以后，归一化矩阵如图 [1-10](#Fig10) 所示。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig10_HTML.png](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig10_HTML.png)

图 1-10

距离为 1、角度为 0 的归一化 GLCM 矩阵

归一化 GLCM 的一个好处是输出矩阵中的所有元素都在从 0.0 到 1.0 的相同范围内。此外，结果与图像大小无关。例如，根据尺寸为 5×5 的图 [1-9](#Fig9) ，对(2，2)的最高频率为 6。如果新图像更大(例如 100×100)，则最高频率将不是 6，而是更大的值，例如 2000。我们不能比较 6 乘 2，000，因为这样的数字与图像大小有关。通过归一化矩阵，GLCM 的元素与图像大小无关，因此我们可以正确地比较它们。在图 [1-10](#Fig10) 中，对(2，2)给出的概率为 0.3，这与来自任何大小的任何图像的同现概率相当。

用 Python 规范化 GLCM 非常简单。基于名为`normed`的布尔参数，如果设置为`True`，结果将被归一化。默认设置为`False`。归一化矩阵是根据下面这条线计算的:

```py
co_mat_normed = skimage.feature.greycomatrix(image=arr, distances=[1], angles=[0], levels=4, normed=True)

```

GLCM 的大小为 4×4，因为我们使用的是只有 4 个级别的 2 位图像。对于图 [1-2(a)](#Fig2) 中的 8 位灰度图像，有 256 级，因此矩阵大小为 256×256。归一化的灰度共生矩阵如图 [1-11](#Fig11) 所示。两个地区的概率很大。第一个在左上角(低强度)，因为背景是深色的。另一个区域在狗身体的右下方(高强度)，因为它的颜色是白色的。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig11_HTML.jpg](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig11_HTML.jpg)

图 1-11

灰度图像的 GLCM 矩阵，256 级，距离为 6，角度为 0

随着级别数量的增加，矩阵的大小也会增加。图 [1-11](#Fig11) 中的 GLCM 有 256×256 = 65536 个元素。在特征向量中使用矩阵中的所有元素将大大增加其长度。我们可以通过从矩阵中提取一些特征来减少这个数字，包括相异度、相关性、同质性、能量、对比度和 ASM(角二阶矩)。清单 [1-5](#PC11) 给出了提取这些特征所需的 Python 代码。

```py
import skimage.io, skimage.feature
import numpy

img = skimage.io.imread('im.jpg', as_grey=True);

img = numpy.uint8(img*255)

glcm = skimage.feature.greycomatrix(img, distances=[6], angles=[0], levels=256, normed=True)

dissimilarity = skimage.feature.greycoprops(P=glcm, prop="dissimilarity")
correlation = skimage.feature.greycoprops(P=glcm, prop="correlation")
homogeneity = skimage.feature.greycoprops(P=glcm, prop="homogeneity")
energy = skimage.feature.greycoprops(P=glcm, prop="energy")
contrast = skimage.feature.greycoprops(P=glcm, prop="contrast")
ASM = skimage.feature.greycoprops(P=glcm, prop="ASM")

glcm_props = [dissimilarity, correlation, homogeneity, energy, contrast, ASM]

print('Dissimilarity',dissimilarity,'\nCorrelation',correlation,'\nHomogeneity',homogeneity,'\nEnergy',energy,'\nContrast',contrast,'\nASM',ASM)

Listing 1-5Extracting GLCM Features

```

GLCM 的一个缺点是依赖于灰度值。光照的微小变化都会影响最终的灰度共生矩阵。一种解决方案是使用梯度而不是强度来构建 CM。这种矩阵被称为基于灰度梯度的共生矩阵(GLGCM)。通过使用梯度，GLGCM 对于光照变化是不变的。

GLCM 和 GLGCM 都是图像变换的变体。也就是说，如果相同的灰度图像受到诸如旋转的变换的影响，描述符将产生不同的特征。一个好的特征描述符应该不受这些影响。

### 猪

灰度共生矩阵用于描述图像纹理，但不能描述图像强度的突变(即边缘)。有时纹理并不适合在问题中使用，我们必须寻找另一个特征。一类特征描述符用于描述图像边缘。这些特征描述了边缘的不同方面，例如边缘方向或方位、边缘位置以及边缘强度或大小。

本小节讨论一个称为梯度方向直方图(HOG)的描述符，它描述边缘方向。有时，目标对象具有唯一的移动方向，因此 HOG 是一个合适的特征。HOG 创建了一个表示边缘方向频率的直方图。让我们看看 HOG 是如何工作的。

#### 图像渐变

图像中每对相邻像素之间的强度都有变化。为了测量这种变化，计算每个像素的梯度向量，以测量从该像素到其相邻像素的强度如何变化。该向量的大小是两个像素之间的亮度差。向量也反映了 X 方向和 Y 方向的变化方向。对于图 [1-12](#Fig12) 中的灰度图像，让我们计算第三行第四列的像素 21 在 X 和 Y 方向上的强度变化。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig12_HTML.png](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig12_HTML.png)

图 1-12

灰度图像计算其梯度

图 [1-13](#Fig13) 中显示了用于查找 X 和 Y 方向上的梯度幅度的掩模。让我们开始计算梯度。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig13_HTML.jpg](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig13_HTML.jpg)

图 1-13

用于计算水平和垂直梯度的遮罩

通过将水平蒙版在目标像素上居中，我们可以计算 X 方向的梯度。在这种情况下，相邻像素是 83 和 98。通过减去这些值，或者从右边的像素中减去左边的像素，或者从左边的像素中减去右边的像素，但在整个图像中保持一致:该像素的变化量为 9883 = 15。这种情况下使用的角度为 0°。

为了获得 Y 方向上该像素的变化量，垂直遮罩以目标像素为中心。然后，减去该像素的顶部和左侧像素，得出 6353 = 10。这种情况下使用的角度是 90 度。

在计算 X 和 Y 方向上的变化之后，接下来是根据等式 1-1 计算最终梯度幅度，以及根据等式 1-2 计算梯度方向。

![$$ Z=\sqrt{X^2+{Y}^2} $$](../images/473634_1_En_1_Chapter/473634_1_En_1_Chapter_TeX_IEq1.png)(方程式 1-1)

![$$ Angle= ta{n}^{-1}\frac{Y}{X} $$](../images/473634_1_En_1_Chapter/473634_1_En_1_Chapter_TeX_IEq2.png)(方程式 1-2)

梯度幅度等于![$$ \sqrt{15^2+{10}^2}=18.03\. $$](../images/473634_1_En_1_Chapter/473634_1_En_1_Chapter_TeX_IEq3.png)

#### 梯度方向

关于梯度方向，可以说该像素的变化方向在 0°处，因为 0°处的幅度高于 90°处的矢量。然而，其他人可能会说，像素不会在 0°或 90°处变化，而是在两个角度之间变化。这种角度是通过考虑 X 和 Y 方向来计算的。向量的方向是![$$ {\tan}^{-1}\frac{15}{10}={56.31}^{{}^{\circ}} $$](../images/473634_1_En_1_Chapter/473634_1_En_1_Chapter_TeX_IEq4.png)。结果，像素变化方向为 56.31。

计算完所有图像的角度后，下一步是为这些角度创建一个直方图。为了使直方图更小，并不使用所有的角度，而只是一组预定义的角度。最常用的角度是水平(0°)、垂直(90°)和对角(45°和 135°)。每个角度的贡献值等于根据等式 1-3 计算的梯度幅度。例如，如果当前像素对 Z 轴有贡献，它会将值 18.03 添加到其中。

#### 有助于直方图仓

我们之前计算的角度是 56.31。这不是以前选择的角度之一。解决方案是将该角度分配给最近的直方图仓。56.31 位于仓 45 和 90 之间。因为 56.31 比 90 更接近 45，所以它将被分配到 bin 45。更好的方法是将该像素对这两个角度(45°和 90°)的贡献分开。

45 度角和 90 度角之间的距离是 45 度。56.31°角和 45°角之间的距离正好是∣56.31 45°∣= 11.31°。这意味着 56.31 度角与 45 度角相差一个等于![$$ \frac{11.32}{45^{{}^{\circ}}}\%=25\% $$](../images/473634_1_En_1_Chapter/473634_1_En_1_Chapter_TeX_IEq5.png)的百分比。换句话说，56.31 是接近 45 的 75%。同样，56.31°角和 95°角之间的距离正好是∣56.31 90°∣= 33.69°。这意味着 56.31°的角度与 90°相差一个等于![$$ \frac{33.69}{45^{{}^{\circ}}}\%=75\% $$](../images/473634_1_En_1_Chapter/473634_1_En_1_Chapter_TeX_IEq6.png)的百分比。根据等式 1-3 计算角度添加到仓中的值。

![$$ contributio{n}_{value}=\frac{abs\left( pixe{l}_{angle}- bi{n}_{angle}\right)}{bi{n}_{spacing}}\left( pixe{l}_{gradientMagnitude}\right) $$](../images/473634_1_En_1_Chapter/473634_1_En_1_Chapter_TeX_IEq7.png)(方程式 1-3)

其中*像素* <sub>*角度*</sub> 为当前像素的方向，*像素*<sub>*gradient magnitude*</sub>为当前像素的渐变幅度， *bin* <sub>*角度*</sub> 为直方图 bin 值， *bin* <sub>*间距*</sub> 为每两个 bin 之间的间距量。

因此，56.31°的角度增加了 45°的 75%的梯度幅度，等于![$$ \frac{75}{100}\mathrm{x}18.03=13.5 $$](../images/473634_1_En_1_Chapter/473634_1_En_1_Chapter_TeX_IEq8.png)。它只将 25%的渐变幅度增加到 45 到 90，等于![$$ \frac{25}{100}\mathrm{x}18.03=4.5 $$](../images/473634_1_En_1_Chapter/473634_1_En_1_Chapter_TeX_IEq9.png)。

更实际的直方图包含从 0°开始到 180°结束的九个角度。每对角度之间的差将是 180/9=20。因此，所用的角度为 0、20、40、60、80、100、120、140、160 和 180。箱不是这些角度，而是每个范围的中心。对于 0–20 范围，使用的 bin 是 10。对于 20–40，仓位为 30，依此类推。最终的直方图柱为 10、30、50、70、90、110、130、150 和 170。如果角度为 25 °,它会添加到其所在的面元中。也就是说，它添加到库 10(增加 0.25)和库 30(增加 0.75)。

通过对位于第二行第二列的像素 68 重复上述步骤，应用水平掩码的结果是 9750 = 47，这是 X 方向的梯度变化。应用垂直遮罩后，结果为 4323 = 20。根据等式 1-2，变化方向计算如下:

![$$ \mathrm{Angle}={\tan}^{-1}\frac{Y}{X}={\tan}^{-1}\frac{20}{47}={23}^{{}^{\circ}} $$](../images/473634_1_En_1_Chapter/473634_1_En_1_Chapter_TeX_Equa.png)

同样，合成角度不等于任何直方图区间。因此，该角度的贡献在它所落入的 15°和 45°的区间上被分开。它把 0.27 加到 45，又把 0.73 加到 45。

对于位于强度值为 88 的第四行第二列的像素，X 方向上的变化为 0。应用等式 1-2，结果将除以 0。为了避免被零除，在分母上加一个很小的值，如 0.0000001。

#### 拱形台阶

至此，我们已经学会了如何计算任何像素的梯度大小和方向。但是在计算这些值之前和之后还有一些工作要做。HOG 步骤总结如下:

1.  将输入图像分割成纵横比为 1:2 的面片。例如，补丁大小可能是 64×128、100×200 等等。

2.  将补丁分成块(例如，四个块)。

3.  将每个区块划分成单元格。块内的单元大小是不固定的。
    *   例如，如果块大小为 16×16，我们决定将其分成四个单元，则每个单元的大小为 8×8。还要注意，块可能彼此重叠，并且一个单元可能在多个块中可用。

4.  对于每个块中的每个单元，计算所有像素的梯度大小和方向。
    *   基于图 [1-13](#Fig13) 中的掩模计算梯度。

    *   梯度大小和方向分别根据等式 1-1 和 1-2 计算。

5.  根据梯度的大小和方向，为每个像元构建直方图。如果用于构成直方图的角度数是 9，则每个单元返回一个 9×1 的特征向量。直方图是根据我们之前的讨论计算出来的。

6.  连接同一块中所有单元的所有直方图，并只返回整个块的单个直方图。如果每个单元直方图由九个二进制表示，并且每个块具有四个单元，则级联直方图长度为 4×9=36。这个 36×1 的矢量是每个块的结果。

7.  该矢量被归一化以使其对光照变化具有鲁棒性。

8.  连接图像补片中所有块的归一化向量，以返回最终的特征向量。

图 [1-14](#Fig14) 显示了图 [1-5(a)](#Fig5) 中图像的一个补丁，尺寸为 64×128。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig14_HTML.jpg](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig14_HTML.jpg)

图 1-14

计算其 HOG 的图像补丁

在创建直方图之前，根据垂直和水平遮罩计算垂直和水平梯度。梯度如图 [1-15](#Fig15) 所示。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig15_HTML.jpg](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig15_HTML.jpg)

图 1-15

64×128 图像面片的垂直和水平渐变

清单 [1-6](#PC12) 中给出了用于计算这种梯度的 Python 代码。

```py
import skimage.io, skimage.color
import numpy
import matplotlib

def calculate_gradient(img, template):
    ts = template.size #Number of elements in the template (3).
    #New padded array to hold the resultant gradient image.
    new_img = numpy.zeros((img.shape[0]+ts-1,
                           img.shape[1]+ts-1))
    new_img[numpy.uint16((ts-1)/2.0):img.shape[0]+numpy.uint16((ts-1)/2.0),
            numpy.uint16((ts-1)/2.0):img.shape[1]+numpy.uint16((ts-1)/2.0)] = img
    result = numpy.zeros((new_img.shape))

    for r in numpy.uint16(numpy.arange((ts-1)/2.0, img.shape[0]+(ts-1)/2.0)):
        for c in numpy.uint16(numpy.arange((ts-1)/2.0,
                              img.shape[1]+(ts-1)/2.0)):
            curr_region = new_img[r-numpy.uint16((ts-1)/2.0):r+numpy.uint16((ts-1)/2.0)+1,
                                  c-numpy.uint16((ts-1)/2.0):c+numpy.uint16((ts-1)/2.0)+1]
            curr_result = curr_region * template
            score = numpy.sum(curr_result)
            result[r, c] = score
    #Result of the same size as the original image after removing the padding.
    result_img = result[numpy.uint16((ts-1)/2):result.shape[0]-numpy.uint16((ts-1)/2),numpy.uint16((ts-1)/2):result.shape[1]-numpy.uint16((ts-1)/2)]
    return result_img

Listing 1-7
Gradient Magnitude

Listing 1-6Calculating Gradients

```

基于接受灰度图像和遮罩的`calculate_gradient(img, template)`函数，基于遮罩对图像进行过滤，然后将其返回。通过用不同的掩码(垂直和水平)调用它两次，返回垂直和水平渐变。

然后，根据清单 [1-7](#PC13) 中的`gradient_magnitude()`函数，使用垂直和水平梯度计算梯度幅度。

```py
def gradient_magnitude(horizontal_gradient, vertical_gradient):
    horizontal_gradient_square = numpy.power(horizontal_gradient, 2)
    vertical_gradient_square = numpy.power(vertical_gradient, 2)
    sum_squares = horizontal_gradient_square + vertical_gradient_square
    grad_magnitude = numpy.sqrt(sum_squares)
    return grad_magnitude

Listing 1-8
Gradient Direction

```

该函数只是将等式 1-1 应用于先前计算的垂直和水平梯度。补片图像的梯度大小如图 [1-16](#Fig16) 所示。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig16_HTML.jpg](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig16_HTML.jpg)

图 1-16

基于先前为 64×128 图像补片计算的垂直和水平渐变的渐变幅度

使用清单 [1-8](#PC14) 中的函数`gradient_direction()`，计算梯度方向。

```py
def gradient_direction(horizontal_gradient, vertical_gradient):
    grad_direction = numpy.arctan(vertical_gradient/(horizontal_gradient+0.00000001))
    grad_direction = numpy.rad2deg(grad_direction)
    # Some angles are outside the 0-180 range. Next line makes all results fall within the 0-180 range.
    grad_direction = grad_direction % 180
    return grad_direction

Listing 1-9Cell Histogram

```

注意添加到分母上的小值(`0.00000001`)。这避免了被零除。忽略这一点，一些输出值将是 NaN(不是数字)。

图 [1-17](#Fig17) 显示了分割成 16×8 个单元后的图像块。每个单元具有 8×8 个像素，每个块具有 4 个单元(即，每个块具有 16×16 个像素)。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig17_HTML.jpg](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig17_HTML.jpg)

图 1-17

图像分为 16×8 个单元格

基于之前计算的梯度大小和方向，我们可以返回图像块中第一个 8×8 单元(左上角单元)的结果，如图 [1-18](#Fig18) 所示。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig18_HTML.png](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig18_HTML.png)

图 1-18

左上角 8×8 单元格的渐变幅度和方向

直方图将基于我们之前讨论的简单示例来创建。有 9 个直方图仓，覆盖从 0°到 180°的角度范围。仅使用有限数量的箱来表示这样的范围使得每个箱覆盖不止一个角度。仅使用 9 个箱，那么每个箱将覆盖 20 个角度。第一个箱覆盖从 0(包括 0)到 20(不包括 0)的角度。第二个从 20(含)到 40(不含)，直到覆盖 160(含)到 180(含)角度的最后一个面元。每个范围的仓将被赋予一个等于每个范围中心的数字。也就是说，第一个箱被赋予 10，第二个箱被赋予 20，依此类推，直到最后一个箱被赋予 170。我们可以说，从第 20 步开始，仓从 10 到 170。对于图 [1-18(a)](#Fig18) 中的每个角度，找到其所在的两个直方图仓。从左上角的值为 44.41 的元素开始，它位于库 30 和 50 之间。根据等式 1-3，该值对这两个仓都有贡献。箱 30 的贡献值计算如下:

![$$ contributio{n}_{value}=\frac{abs\left(44.41-30\right)}{20}(207.19)=0.72\times 207.19=149.28 $$](../images/473634_1_En_1_Chapter/473634_1_En_1_Chapter_TeX_Equb.png)

关于箱 50，贡献值计算如下:

![$$ contributio{n}_{value}=\frac{abs\left(44.41-50\right)}{20}(207.19)=0.28\times 207.19=57.91 $$](../images/473634_1_En_1_Chapter/473634_1_En_1_Chapter_TeX_Equc.png)

对当前单元中的所有 8×8 像素继续该过程。左上角单元格的直方图如图 [1-19(a)](#Fig19) 所示。假设每个块包含 2×2 个单元，图 [1-17](#Fig17) 中用亮色标记的左上块中剩余三个单元的 9-bin 直方图也显示在图 [1-19](#Fig19) 中。通过计算给定块的所有直方图，其特征向量是这四个 9-bin 直方图的串联。特征向量的长度为 9×4 = 36。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig19_HTML.jpg](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig19_HTML.jpg)

图 1-19

当前图像块左上块内四个单元的九格直方图

计算完第一个块的特征向量后，选择下一个有四个单元格的块，在图 [1-20](#Fig20) 中用亮色标记。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig20_HTML.jpg](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig20_HTML.jpg)

图 1-20

图像补片中的第二个块以亮色突出显示

同样，如图 [1-21](#Fig21) 所示，计算该块内四个单元中每一个单元的九格直方图，并将它们的结果连接起来，返回 36×1 特征向量。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig21_HTML.jpg](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig21_HTML.jpg)

图 1-21

在当前图像块的图 [1-20](#Fig20) 中用亮色标记的第二个块内的四个单元的九格直方图

使用清单 [1-9](#PC15) 中的`HOG_cell_histogram()`函数计算每个单元格的直方图。该函数接受给定单元格的方向和大小，并返回其直方图。

```py
def HOG_cell_histogram(cell_direction, cell_magnitude):
    HOG_cell_hist = numpy.zeros(shape=(hist_bins.size))
    cell_size = cell_direction.shape[0]

    for row_idx in range(cell_size):
        for col_idx in range(cell_size):
            curr_direction = cell_direction[row_idx, col_idx]
            curr_magnitude = cell_magnitude[row_idx, col_idx]

            diff = numpy.abs(curr_direction - hist_bins)

            if curr_direction < hist_bins[0]:
                first_bin_idx = 0
                second_bin_idx = hist_bins.size-1
            elif curr_direction > hist_bins[-1]:
                first_bin_idx = hist_bins.size-1
                second_bin_idx = 0
            else:
                first_bin_idx = numpy.where(diff == numpy.min(diff))[0][0]
                temp = hist_bins[[(first_bin_idx-1)%hist_bins.size, (first_bin_idx+1)%hist_bins.size]]
                temp2 = numpy.abs(curr_direction - temp)
                res = numpy.where(temp2 == numpy.min(temp2))[0][0]
                if res == 0 and first_bin_idx != 0:
                    second_bin_idx = first_bin_idx-1
                else:
                    second_bin_idx = first_bin_idx+1

            first_bin_value = hist_bins[first_bin_idx]
            second_bin_value = hist_bins[second_bin_idx]
            HOG_cell_hist[first_bin_idx] = HOG_cell_hist[first_bin_idx] + (numpy.abs(curr_direction - first_bin_value)/(180.0/hist_bins.size)) * curr_magnitude
            HOG_cell_hist[second_bin_idx] = HOG_cell_hist[second_bin_idx] + (numpy.abs(curr_direction - second_bin_value)/(180.0/hist_bins.size)) * curr_magnitude
    return HOG_cell_hist

Listing 1-10Complete Implementation for Calculating Histogram for the Top-Left Cell

```

清单 [1-10](#PC16) 给出了用于读取图像补丁的完整代码，并返回第一个块中左上角单元格的直方图。请注意，该代码适用于灰度图像。如果输入图像是灰度图像，它将只有两个维度。如果输入图像是彩色的，那么它将具有表示通道的第三维。在这种情况下，只使用一个灰度通道。使用 ndim 属性返回 NumPy 数组的维数。

```py
import skimage.io, skimage.color
import numpy
import matplotlib.pyplot

def calculate_gradient(img, template):
    ts = template.size #Number of elements in the template (3).
    #New padded array to hold the resultant gradient image.
    new_img = numpy.zeros((img.shape[0]+ts-1,
                           img.shape[1]+ts-1))
    new_img[numpy.uint16((ts-1)/2.0):img.shape[0]+numpy.uint16((ts-1)/2.0),
            numpy.uint16((ts-1)/2.0):img.shape[1]+numpy.uint16((ts-1)/2.0)] = img
    result = numpy.zeros((new_img.shape))

    for r in numpy.uint16(numpy.arange((ts-1)/2.0, img.shape[0]+(ts-1)/2.0)):
        for c in numpy.uint16(numpy.arange((ts-1)/2.0,
                              img.shape[1]+(ts-1)/2.0)):
            curr_region = new_img[r-numpy.uint16((ts-1)/2.0):r+numpy.uint16((ts-1)/2.0)+1,
                                  c-numpy.uint16((ts-1)/2.0):c+numpy.uint16((ts-1)/2.0)+1]
            curr_result = curr_region * template
            score = numpy.sum(curr_result)
            result[r, c] = score
    #Result of the same size as the original image after removing the padding.
    result_img = result[numpy.uint16((ts-1)/2.0):result.shape[0]-numpy.uint16((ts-1)/2.0), numpy.uint16((ts-1)/2.0):result.shape[1]-numpy.uint16((ts-1)/2.0)]
    return result_img

def gradient_magnitude(horizontal_gradient, vertical_gradient):
    horizontal_gradient_square = numpy.power(horizontal_gradient, 2)
    vertical_gradient_square = numpy.power(vertical_gradient, 2)
    sum_squares = horizontal_gradient_square + vertical_gradient_square
    grad_magnitude = numpy.sqrt(sum_squares)
    return grad_magnitude

def gradient_direction(horizontal_gradient, vertical_gradient):
    grad_direction = numpy.arctan(vertical_gradient/(horizontal_gradient+0.00000001))  

    grad_direction = numpy.rad2deg(grad_direction)
    grad_direction = grad_direction%180
    return grad_direction

def HOG_cell_histogram(cell_direction, cell_magnitude):
    HOG_cell_hist = numpy.zeros(shape=(hist_bins.size))
    cell_size = cell_direction.shape[0]

    for row_idx in range(cell_size):
        for col_idx in range(cell_size):
            curr_direction = cell_direction[row_idx, col_idx]
            curr_magnitude = cell_magnitude[row_idx, col_idx]

            diff = numpy.abs(curr_direction - hist_bins)

            if curr_direction < hist_bins[0]:
                first_bin_idx = 0
                second_bin_idx = hist_bins.size-1
            elif curr_direction > hist_bins[-1]:
                first_bin_idx = hist_bins.size-1
                second_bin_idx = 0
            else:
                first_bin_idx = numpy.where(diff == numpy.min(diff))[0][0]
                temp = hist_bins[[(first_bin_idx-1)%hist_bins.size, (first_bin_idx+1)%hist_bins.size]]
                temp2 = numpy.abs(curr_direction - temp)
                res = numpy.where(temp2 == numpy.min(temp2))[0][0]
                if res == 0 and first_bin_idx != 0:
                    second_bin_idx = first_bin_idx-1
                else:
                    second_bin_idx = first_bin_idx+1

            first_bin_value = hist_bins[first_bin_idx]
            second_bin_value = hist_bins[second_bin_idx]
            HOG_cell_hist[first_bin_idx] = HOG_cell_hist[first_bin_idx] + (numpy.abs(curr_direction - first_bin_value)/(180.0/hist_bins.size)) * curr_magnitude
            HOG_cell_hist[second_bin_idx] = HOG_cell_hist[second_bin_idx] + (numpy.abs(curr_direction - second_bin_value)/(180.0/hist_bins.size)) * curr_magnitude
    return HOG_cell_hist

img = skimage.io.imread("im_patch.jpg")
if img.ndim >2:
    img = img[:, :, 0]

horizontal_mask = numpy.array([-1, 0, 1])
vertical_mask = numpy.array([[-1],
                             [0],
                             [1]])

horizontal_gradient = calculate_gradient(img, horizontal_mask)
vertical_gradient = calculate_gradient(img, vertical_mask)

grad_magnitude = gradient_magnitude(horizontal_gradient, vertical_gradient)
grad_direction = gradient_direction(horizontal_gradient, vertical_gradient)

grad_direction = grad_direction % 180
hist_bins = numpy.array([10,30,50,70,90,110,130,150,170])

cell_direction = grad_direction[:8, :8]
cell_magnitude = grad_magnitude[:8, :8]
HOG_cell_hist = HOG_cell_histogram(cell_direction, cell_magnitude)

matplotlib.pyplot.bar(left=numpy.arange(9), height=HOG_cell_hist, align="center", width=0.8)
matplotlib.pyplot.show()

```

在计算了块的特征向量之后，下一步是归一化该向量。特征归一化的动机是特征向量依赖于图像强度水平，并且最好使其对光照变化具有鲁棒性。归一化通过将向量中的每个元素除以根据等式 1-4 计算的向量长度来进行。

![$$ vecto{r}_{length}=\sqrt{X_1+{X}_2+\dots +{X}_n} $$](../images/473634_1_En_1_Chapter/473634_1_En_1_Chapter_TeX_IEq10.png)(方程式 1-4)

其中*X*<sub>T3】IT5】代表矢量元素编号 *i* 。归一化向量是第一块的结果。该过程继续，直到返回所有块的所有 36×1 特征向量。然后，将这些向量连接起来，用于正在处理的整个图像补片。</sub>

根据前面的讨论，HOG 在计算之前需要指定以下参数:

1.  方向的数量。

2.  每个单元格的像素数。

3.  每个块的单元数。

HOG 已经在 Python 的`skimage.feature`模块中实现，可以根据`skimage.feature.hog()`函数轻松使用。前面三个参数有默认值，可以根据您的目标进行更改。如果`normalized`参数设置为`True`，则返回标准化的 HOG。

```py
skimage.feature.hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(3, 3), visualise=False, transform_sqrt=False, feature_vector=True, normalise=None)

```

### 垂直线间的距离

LBP 代表局部二元模式，这是另一种二阶纹理描述符。提取 LBP 特征的步骤如下:

1.  将图像分成块(例如，16×16 块)。

2.  对于每个块，一个 3×3 的窗口位于每个像素的中心。

根据等式 1-5，将所选中心像素 *P* <sub>*中心*</sub> 与其周围 8 个邻居 *P* <sub>*邻居*</sub> 中的每一个进行比较。从八次比较中，将有八个二进制数字。

![$$ {P}_{neighbor}=\Big\{{\displaystyle \begin{array}{l}1,\kern5.5em {P}_{neighbor}&gt;{P}_{central}\\ {}0,\kern5.5em otherwise\end{array}} $$](../images/473634_1_En_1_Chapter/473634_1_En_1_Chapter_TeX_IEq11.png)(方程式 1-5)

1.  8 位二进制代码被转换成整数。整数范围从 0 到 2 <sup>8</sup> = 255。

2.  用计算出的整数替换 *P* <sub>*中央*</sub> 的值。

3.  在计算同一块内所有像素的新值后，计算直方图。

4.  在计算了所有块的直方图后，它们被连接起来。

假设我们当前正在处理的块在图 [1-12](#Fig12) 中，我们可以基于它开始计算基本的 LBP。

通过处理第三行和第四列的像素，将中心像素与八个相邻像素中的每一个进行比较。图 [1-22](#Fig22) 显示了比较的结果。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig22_HTML.png](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig22_HTML.png)

图 1-22

将中心像素与其八个相邻像素进行比较的结果

接下来是返回二进制代码。您可以从 3×3 矩阵中的任何位置开始，但必须在整个图像中保持一致。例如，从左上位置开始顺时针移动，代码为 11011101。你可以顺时针或逆时针移动，但要保持一致。

此后，通过将每个二进制数乘以对应于其在二进制码中的位置的权重相加，将二进制码转换成十进制码。结果是 128 + 64 + 16 + 8 + 4 + 1 = 221。

在计算块中每个像素的二进制代码并返回其十进制代码后，就创建了直方图。对所有图像块重复该过程，并且像在 HOG 的情况下一样，连接来自所有块的直方图。

这是 LBP 的基本实现，但是这种特征描述符具有多种变化，使得它对光照变化、缩放和旋转具有鲁棒性。

使用接受三个参数的`skimage.feature.local_binary_pattern()`函数可以很容易地在 Python 中实现它:

*   输入图像。

*   圆中相邻点的数目(P)。该参数有助于实现旋转不变性。

*   圆的半径(R)。这种参数有助于实现比例不变性。

这里是一个 LBP 应用于图 [1-2(a)](#Fig2) 中的灰度图像的例子。

```py
import skimage.feature
import skimage.io
import matplotlib.pyplot

im = skimage.io.imread("69.jpg", as_grey=True)
lbp = skimage.feature.local_binary_pattern(image=im, P=9, R=3)
matplotlib.pyplot.imshow(lbp, cmap="gray")
matplotlib.pyplot.xticks([])
matplotlib.pyplot.yticks([])

```

输出图像如图 [1-23](#Fig23) 所示。

![../images/473634_1_En_1_Chapter/473634_1_En_1_Fig23_HTML.jpg](../images/473634_1_En_1_Chapter/473634_1_En_1_Fig23_HTML.jpg)

图 1-23

在 P-9 和 R=3 的灰度图像上应用 LBP 的输出

## 特征选择和减少

假设在与某个领域的专家讨论之后，您推断出特性 X、Y 和 Z 是合适的。这些功能只是最初选择的，其中一些功能可能没有帮助。您可以根据一些实验来决定每个特性是好是坏。在基于这三个特征训练模型之后，识别率较低，并且必须在特征向量中改变某些东西。为了知道原因，您通过为每个单独的特征训练模型来进行一些实验。您发现特征 Z 和目标之间的相关性很低，因此决定不使用该特征。从特征向量中完全消除某些特征并保留其他特征称为特征选择。选择技术将特征分为好的或坏的。坏的特征被完全消除，而好的特征被专门使用。

事实上，每个特性中的一些元素可能不适合所分析的应用程序类型。假设在特征向量中使用特征 X，并且该特征具有一组 10 个元素。这些元素中的一个或多个可能对任务没有帮助。例如，有些功能是多余的。也就是说，一些特征可能彼此最佳相关，因此仅一个特征就足以描述数据，并且不需要使用工作相同的多个特征。由于相关的特征，可能不存在唯一的最优特征子集。这是因为可能有不止一个完全相关的特征，因此一个可以替换另一个并创建新的特征子集。

另一类是无关的特性。一些特征与所需的预测无关，它们被视为噪声。这样的特征不会增强而是降低结果。因此，最好检测这些特征并删除它们，这样它们就不会影响学习过程。只删除元素的一个子集而保留其他的叫做特征约简。

通过尽可能去除坏特征来减少特征向量长度的另一个动机是，特征向量长度越长，在训练和测试模型时消耗的计算时间就越多。

要将要素分类为相关或不相关，需要一些度量来显示每个要素与输出类的相关性或每个要素预测所需输出的程度。特征相关性是特征区分不同类别的能力。在选择度量之后，它们将被用于通过消除坏的特征来创建好的特征子集。特征消除方法分为监督和非监督方法。有监督的方法包括过滤器和包装器，无监督的方法包括嵌入式。

### 过滤器

过滤方法增加了额外的预处理步骤，以应用可变排序技术，基于为每个特征计算的不同标准来对特征进行排序，从而测量特征的相关性。这些标准包括标准偏差(STD)、能量、熵、相关性和互信息(MI)。基于阈值，选择排名高的特征来训练模型。与其他选择方法相比，过滤方法非常快速且不耗时。它们的计算也很简单，可扩展，能够避免过拟合，并且独立于学习模型。

对于训练不同的模型，选择只进行一次，然后训练模型可以使用所选择的特征。但是，与其他特征选择方法相比，过滤方法有许多严重影响其性能的严重缺点。过滤/分级方法没有对特征依赖性建模。它独立于同一子集中的其他特征/变量来选择每个变量/特征。当根据所选择的标准被高度排序时，特征被选择。用于排序的标准没有考虑多个特征之间的关系。忽略特征依赖性会破坏整个所选子集，因为当与其他特征组合时，不能保证那些本身对提高学习速率很重要的特征也是如此。在某些情况下，有用的变量在组合在一起时仍然有用，但情况并非总是如此。

如果两个特征 *f* <sub>1</sub> 和 *f* <sub>2</sub> 的有用性分别是 *x* <sub>1</sub> 和 *x* <sub>2</sub> ，这并不意味着它们组合在一起时有用性就会是*x*<sub>1</sub>+*x*<sub>2</sub>。此外，忽略特性依赖会导致冗余和相关的特性。这是因为可能有两个或两个以上的特征完全满足标准，但它们中的每一个都是做相同任务的所有其他特征的完美反映。所以不要求使用同一事物的倍数；一个就够了。相关性是冗余的另一种形式，在这种形式中，特征可能不相同，但是相互依赖，并且总是工作相同(可以表示为两条平行线)。完全相关的变量确实是多余的，因为它们没有增加额外的信息。冗余和相关特征的使用导致大的特征向量，因此不能实现特征选择减少特征向量长度的好处。过滤方法不与学习模型交互，因为它们不依赖于学习算法性能，这是由于将特征选择与性能解耦。相反，这些只是考虑特征和类标签之间的单个标准，而不是指示特征与学习算法工作得如何的信息。一个好的特征选择器应该考虑学习算法和训练数据集如何交互。最后，计算用于将特征分类为选中或未选中的阈值并不是一件容易的事情。所有这些原因导致了克服这些问题的其他特征选择方法的使用。

### 包装材料

包装器方法是解决过滤方法的一些问题的第二种方法。包装器方法试图通过创建使性能最大化的所选特征的子集来与学习模型交互。包装器方法创建所有可能的特征子集，以找到最佳子集。包装器方法之所以这么叫，是因为它围绕着学习算法。它使用归纳或学习算法作为黑盒，通过用所选子集训练算法来测量所选特征子集的工作情况，然后使用最大化其性能的算法。当谈到包装器方法时，应该很好地涵盖多个要点，包括选择特征子集长度、创建特征子集空间、搜索特征子集空间、评估学习算法的性能、停止搜索标准以及确定使用哪个学习算法。任何特征缩减/选择算法的目标都是从长度为 *N* 的原始完整特征向量中创建长度为 *L* 个特征的所有可能的特征组合，以最大化性能，其中< *N* 。对于长度=30 的正常特征向量，有大量的组合来创建长度为 *L* = 10 的子集。为此，应用搜索策略来搜索最佳子集，并使用评价函数惩罚不良子集。在这种情况下，目标函数是模型性能。这样，问题就从学习问题转化为搜索问题。穷举搜索不适用于这种问题，因为它访问和训练具有所有子集的学习模型，这在计算方面是密集的。因此，进化算法(EAs)被用来避免探索所有的子集，这些算法可以分为两类:顺序选择算法(确定性的)和启发式搜索算法(随机的)。

确定性搜索算法被进一步分为实际上非常相似的两类，即前向选择和后向选择。在前向选择中，该算法从表示空集特征的根开始，然后逐个特征地添加，同时为每个变化训练学习模型。在后向选择中，搜索的根是完整的特征集，然后算法逐个删除特征，同时为每个变化训练学习模型。这种算法的例子包括顺序特征选择(SFS)、顺序向后选择(SBS)、顺序向前浮动选择(SFFS)、自适应 SFFS (ASFFS)和波束搜索。为了防止搜索穷尽，添加了停止标准以防止探索所有可能的组合。该标准可以是前向选择的最大特征向量长度或后向选择的最小长度。它也可以是一个最大性能，因此在达到选定的性能后，搜索停止。

第二类搜索算法，随机算法，是使用启发式评估函数的通知搜索，生成一个启发式值，告诉每个子集有多接近最大性能。这种搜索算法的例子包括遗传算法(GA)、粒子群优化(PSO)、模拟退火(SA)和随机爬山。GA 将在第 [5](5.html) 章中详细讨论。

一个必须回答的问题是 *L* (特征数)的最优值是多少？包装器方法有不同的方法来回答这个问题。一种方法是选择固定数量的特征来创建特征向量，并且通过使用组合，有可能获得从 *N* 个特征中仅选择 *L* 个特征的所有可能性。但不幸的是，为 *L* 选择的固定值可能不是最佳值，并且不能保证 *L* 选择的特征是为学习模型提供最佳性能的特征。因此，另一种方法是使被选择的特征的数量可变并且动态地变化。这是通过尝试不同数量的特征并选择最佳数量的特征来最大化性能，如同在顺序选择算法中一样。使特征的数量动态变化的缺点是通过创建不同长度的不同特征组合并用它们训练模型来增加越来越多的计算时间。为了减少这个时间，可以添加一个标准，使得在达到目标性能之后或者在所选特征的数量达到最大长度之后，学习更早地停止。

将包装器方法与过滤器方法相比较，有许多优点。包装器方法与学习模型交互，因为它使用学习算法性能作为选择最佳特征子集的度量。它还对功能依赖关系进行建模，因为功能不是单独或相互独立选择的，并监控将功能组合在一起对性能的影响。最后，它对冗余和相关特征具有鲁棒性。但是各种包装方法都有许多缺点。它们非常耗时，因为每个模型都需要多次训练。有些模型非常耗时，一次训练可能需要几个小时。因此，包装方法不是这种模型的选项。此外，包装器方法受到过度拟合的影响，因为选择依赖于学习模型，因此不能在不同的模型上概括选择的特征。

### 植入的

过滤器和包装器这两种特性选择方法各有优缺点。嵌入式方法试图结合过滤器和包装器方法的优点。这种方法并不耗时，因为它们避免了在过滤器和包装器方法中看到的学习算法的再训练。它们通过与学习模型交互来最大化性能，就像在包装器方法中一样。仅当该特征与输出类标签 m 相关时，才选择该特征。之所以称之为嵌入式，是因为它通过在训练步骤中嵌入特征选择来工作。

嵌入式方法的类别如下:修剪、内置和正则化(惩罚)。修剪方法首先用完整的特征集训练学习模型，然后计算每个特征的相关系数。这些系数用于根据所使用的模型对特征的重要性进行排序。系数的高值反映了强相关性。嵌入式特征选择的内置方法计算每个特征的信息增益，就像决策树学习(ID3)一样。

在机器学习(ML)中，一些模型被训练得非常好，可以对训练数据中的任何样本做出正确的预测，但不幸的是，不能对训练样本之外的其他样本做出正确的预测。这个问题叫做过拟合。正则化是一种用来避免这个问题的技术。正则化是调整或选择最佳的模型复杂度以适应训练数据，同时能够预测看不见的样本。如果不进行正则化，模型可能会非常简单且拟合不足(无法对训练样本和测试样本都做出正确的预测)，或者非常复杂且过度拟合(对训练样本的预测正确，但对测试样本的预测错误)。欠拟合和过拟合都使得模型太弱，不能推广到任何样本。因此，正则化是一种概括模型以预测任何样本的方法，无论是训练还是测试。

### 正规化

为了找到最佳模型，ML 中的常用方法是定义一个描述模型与数据拟合程度的损失或成本函数。目标是找到最小化这个损失函数的模型。通常，任何学习模型中的目标函数只有一个标准，即最大化性能。正则化方法为目标函数增加了另一个标准，以控制复杂程度，如等式 1-6 所示。

*L* = min *误差* ( *Y* <sub>*预测*</sub> ， *Y* <sub>*校正*</sub> ) + *λ罚*(*W*<sub>*I*</sub>)(方程式 1-6)

其中 *Y* <sub>*预测*</sub> 为预测类标签， *Y* <sub>*正确*</sub> 为正确类标签，*错误*(。)计算预测误差， *W* <sub>*i*</sub> 是特征元素 *X* <sub>*i*</sub> 的权重， *λ* 是控制模型复杂度的正则化参数。该参数用于控制目标函数和惩罚之间的权衡。根据等式 1-7 定义罚值。

![$$ penalty(w)=\sum \limits_{i=1}\mid {W}_i\mid $$](../images/473634_1_En_1_Chapter/473634_1_En_1_Chapter_TeX_IEq12.png)(方程式 1-7)

通过改变 *λ* 值，模型复杂度发生变化。这是通过将一些特征的权重设置为接近或等于零来惩罚它们。系数的大小是决定模型复杂性的一个重要因素。通过选择具有高权重幅度的特征来间接实现特征选择。权重越高，预测正确类别的特征越相关。这就是为什么正规化的方法被称为惩罚。

正则化参数 *λ* 的目标是最小化损失 *L* 并使其保持最小。对于接近∞*λ*的非常大的值，系数必须小并且接近零，以使总值尽可能小。这使得大部分系数为零，从而消除它们。对于一个值为 0 < *ʎ* < ∞，会有一些等于零的系数被去掉，但等于零的并不多。 *λ* 的最佳值是多少？ *λ* 没有固定值，可以使用交叉验证(CV)有效地计算其值。

结合过滤器和包装器方法的优点使得嵌入式方法成为特征选择的最新研究趋势。它与学习模型交互，因为它像包装方法一样使用训练模型性能作为度量，不像过滤方法那样耗时，因为它不需要重新训练模型，并且还对特征依赖性进行建模以避免冗余和相关的特征。在训练时选择特征在数据使用方面是有效的，因为不需要将数据分成训练集和验证集。然而，尽管通过嵌入式方法选择的特征对于用于选择特征的学习模型来说表现良好，但是所选择的特征可能依赖于这样的模型，并且不会像使用过滤器方法产生的那样在不同的模型之间工作良好。