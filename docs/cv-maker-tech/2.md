# 二、神经网络

现在，我们已经知道如何使用回归来训练模型，是时候探索下一步了，即将多个回归单元拟合到神经网络中。

神经网络是解决输入特征之间具有非线性相关性的复杂回归或分类问题的更好方法。我们已经看到，如果基础数据的特征由线性关系绑定，那么线性回归和具有线性函数的逻辑回归可以表现得很好。在这种情况下，通过数据拟合一条线(或线性超曲面)是训练模型的好策略。我们还看到，更复杂的非线性关系可以通过向假设函数添加更多的多项式项来表达，例如，二次或三次关系或具有某些特征乘积的项。

然而，作为额外的多项式项添加更多的合成要素是有限制的。考虑图 2-1 所示的例子。线性分割边界在描述输入要素之间的关系时可能不太准确。我们可以添加更多的多项式项(例如，*x*<sub>1</sub>*x*<sub>2</sub>![$$ {x}_1² $$](img/497180_1_En_2_Chapter_TeX_IEq1.png)或![$$ {x}_1{x}_2² $$](img/497180_1_En_2_Chapter_TeX_IEq2.png))，这确实可以很好地拟合我们的数据，但我们有过度拟合数据集的风险(即，生成一个对特定训练输入表现良好但对其他情况不够通用的模型)。此外，如果我们只有两个输入特征，该方法可能仍然是可持续的。但是，请尝试想象一个真实的场景，例如房屋的价格，它可能依赖于大量不一定线性相关的要素，您会注意到模型所需的额外多项式要素的数量很容易激增。使用多个输入要素和多个非线性项来训练回归模型有两大缺点:

*   这些特征之间的关系很难想象。

*   这是一种倾向于组合爆炸的方法。您很可能会以大量的特征来表达所有的关系。这种模型训练起来非常昂贵，但仍然容易过度拟合。

当我们转向图像检测领域时，事情只会变得更加棘手。请记住，计算机只能看到图像中的原始像素值，图像中拍摄的对象通常具有非线性边界。

![img/497180_1_En_2_Fig1_HTML.jpg](img/497180_1_En_2_Fig1_HTML.jpg)

图 2-1

两个变量之间的非线性边界的例子可能很难单独用逻辑回归来表达

当您的数据由许多输入要素组成，并且数据的分布或其类之间的边界呈非线性时，将回归分类器组织成一个网络以更好地捕捉增加的复杂性通常是一个更好的主意，而不是尝试构建一个单一的回归分类器，该分类器可能带有许多多项式项来最好地描述您的训练集，但最终很容易过度拟合您的数据而实际上无法提供良好的预测。这个想法类似于大多数动物(和人类)的学习方式。我们系统中的神经元通过一种类似于图 2-2 所示的结构牢固地连接在一起，它们通过微小的电势变化不断地与身体周围(在称为*轴突*的纤维上，每个轴突都连接到一个神经元，如果你将更多的轴突捆绑在一起，你就会得到一个*神经*)以及与其他神经元(在称为*树突*的连接纤维上)相互作用。一个神经元的轴突和下一个神经元的树突之间的连接被称为*突触*。通过这些连接发送的电化学信号使动物能够看到、听到、闻到或感觉到疼痛，并使我们能够有意识地移动手臂或腿。然而，这些联系在人的一生中不断变异。神经元之间的联系是基于从周围环境中收集的感觉信号和我们收集的经验而形成的。我们天生不知道如何正确地抓住一个物体，但我们在生命的最初几个月里逐渐学会了。我们天生不知道如何说我们父母的语言，但随着我们接触越来越多的例子，我们逐渐学会了。在物理上，这是通过神经元之间连接的连续微调过程来实现的，以便优化我们执行某项任务的方式。神经元通过与它们相连的邻居同步，快速专门化地执行某项任务——位于我们脑后的神经元处理来自我们眼睛的图像，而位于前额皮质的神经元通常负责抽象思维和规划。每当净输入信号高于或低于某个阈值时，神经元很快学会激发电化学脉冲或保持沉默，并且根据一起激发的神经元更强地连接在一起的想法，连接被不断地重新建模。神经系统不仅负责创建新的连接以更好地对环境做出反应，还负责保持连接数量的优化——如果每个神经元都与所有其他神经元紧密相连，我们的身体将需要大量能量来保持所有连接的运行——因此在一定时间内不使用的神经路径最终会失去它们的力量；举例来说，这就是为什么我们倾向于忘记那些我们很久没有刷新的概念。

![img/497180_1_En_2_Fig2_HTML.png](img/497180_1_En_2_Fig2_HTML.png)

图 2-2

物理神经元的主要成分

人工神经网络的建模方式非常类似于它们的生物学对应物。不仅如此，人工智能和神经科学领域有着相互影响的悠久传统——人工神经网络是模仿生物网络建模的，而人工神经网络的发展进展往往揭示了大脑被忽视的特征。将人工神经网络中的每个神经元想象为具有一定数量输入的计算单元，这些输入近似映射物理细胞中的树突。每个输入“线”都有一个可以在学习阶段调整的*权重*，它近似地映射了物理神经元的突触。神经元本身可以被视为一个计算单元，它执行其输入的*加权和*，并应用非线性函数(如我们之前看到的逻辑曲线)来映射开/关输出状态。如果激活函数的输出高于某个阈值，那么神经元将“发射”一个信号。每个神经元的输出既可以被馈送到另一个神经元，也可以是网络的终端输出之一。网络最简单的例子是*感知机*(见图 2-3 )，类似于 Frank Rosenblatt 在 1957 年设计的试图识别图像中的人。它是一个单个神经元的网络，具有一组 *n* + 1 个输入特征![$$ \overline{x}=\left[{x}_0,{x}_1,{x}_2,\dots, {x}_n\right] $$](img/497180_1_En_2_Chapter_TeX_IEq3.png)(就像在回归的情况下，我们使用一个附件 *x* <sub> 0 </sub> = 1 个输入以更紧凑的方式表达线性模型)。每个输入都通过一个 *n* + 1 权重![$$ \overline{theta}=\left[{\theta}_0,{\theta}_1,{\theta}_2,\dots, {\theta}_n\right] $$](img/497180_1_En_2_Chapter_TeX_IEq4.png)的向量连接到一个神经元。该单元将输出一个*激活值* ![$$ a\left(\overline{x}\right) $$](img/497180_1_En_2_Chapter_TeX_IEq5.png)，定义为其输入的加权和:

![$$ a\left(\overline{x}\right)=\sum \limits_{i=0}^n{\theta}_i{x}_i $$](img/497180_1_En_2_Chapter_TeX_Equ1.png)

(2.1)

这样的激活值将通过一个*激活函数**h*<sub>θ</sub>(*x*)，通常是我们在等式 1.39 中看到的 sigmoid/logistic 函数，它将真实值映射到一个离散的开/关值:

![$$ g(z)=\frac{1}{1+{e}^{-z}} $$](img/497180_1_En_2_Chapter_TeX_Equ2.png)

(2.2)

![img/497180_1_En_2_Fig3_HTML.jpg](img/497180_1_En_2_Fig3_HTML.jpg)

图 2-3

单神经元(感知器)网络的逻辑模型

这种学习单元可以用于一些简单的情况，但在更复杂的情况下，它将面临罗森布拉特的第一个感知机遇到的相同问题。在图像中识别人或物体是一个具有大量输入的学习问题——在其最简单的实现中，图像的每个像素都将是模型的输入。一般来说，单个神经元不足以模拟如此高水平的可变性。这就是为什么现在更常见的是将多个感知器单元打包成一个*神经网络*，其中每个神经元的每个输出都连接到下一层神经元的输入，如图 2-4 所示。通过封装更多相互连接的神经元，学习单元通常能够更好地识别高维问题中的复杂模式。图中的示例显示了一个具有三层的神经网络。对于简单的情况来说，这是一个非常常见的架构，但是我们很快就会看到，具有更细微模式的问题可以通过具有更多中间层的网络来更好地解决。按照惯例，第一层被称为*输入层*，它通常具有与输入数据集的维度一样多的神经元(加一，其中*x*0= 1)。第二层和任何其他中间层通常被称为*隐藏层*，因为它们完成大部分推理工作，但是它们既不直接连接到网络的输入也不直接连接到网络的输出。网络的最后一层称为*输出层*，它包含与输出类/标签一样多的输出(在图中的例子中是一个真/假类，但是我们很快就会看到具有更多输出的网络)。

注意，![$$ {a}_i^{(j)} $$](img/497180_1_En_2_Chapter_TeX_IEq6.png)表示网络第 *j* 层中第 *i* 单元的*激活值*，而![$$ {h}_{\Theta}\left(\overline{x}\right) $$](img/497180_1_En_2_Chapter_TeX_IEq7.png)表示模型的*假设*(或预测)与配置参数θ的函数关系，计算为

![$$ {h}_{\Theta}\left(\overline{x}\right)=\frac{1}{1+{e}^{-\Theta \overline{x}}} $$](img/497180_1_En_2_Chapter_TeX_Equa.png)

而在回归情况下，模型的参数(或权重)是向量，在这种情况下，每个第 *j* 层将具有相关联的θ<sup>(*j*)</sup>矩阵，以映射第 *j* 层和第 *j* + 1 层之间的权重。记住 *j* 中的每个单元都连接到 *j* + 1 中的每个单元，所以θ<sub>*j*</sub>将是一个 *m* × *n* 矩阵，其中 *m* 是 *j* 中的单元数， *n* 是 *j* 中的单元数因此，我们可以把θ想象成一个 3D 张量。直观上，张量是矩阵的多维推广。在我们的例子中，张量θ的每个 *j* 的“切片”代表第 *j* 层的 2D 权重矩阵。

如果我们将迄今为止收集的所有信息放在一起，我们可以将图中每个神经元的激活功能形式化如下:

![img/497180_1_En_2_Fig4_HTML.png](img/497180_1_En_2_Fig4_HTML.png)

图 2-4

三层人工神经网络的逻辑模型

*   The units in the first layer are usually mapped one-to-one to the input features, unless you want to assign each feature a different weight:

    ![$$ {a}_i^{(1)}={x}_i\ \mathrm{for}\ i=0\dots n $$](img/497180_1_En_2_Chapter_TeX_Equb.png)

*   The activation values of the units in the second layer is the logistic function of the weighted sum of the inputs:

    ![$$ {a}_1^{(2)}=g\left({\Theta}_{10}^{(1)}{x}_0+{\Theta}_{11}^{(1)}{x}_1+{\Theta}_{12}^{(1)}{x}_2+\dots +{\Theta}_{1n}^{(1)}{x}_n\right) $$](img/497180_1_En_2_Chapter_TeX_Equc.png)

![$$ {a}_2^{(2)}=g\left({\Theta}_{20}^{(1)}{x}_0+{\Theta}_{21}^{(1)}{x}_1+{\Theta}_{22}^{(1)}{x}_2+\dots +{\Theta}_{2n}^{(1)}{x}_n\right) $$](img/497180_1_En_2_Chapter_TeX_Equd.png)

![$$ \dots $$](img/497180_1_En_2_Chapter_TeX_Eque.png)

![$$ {a}_n^{(2)}=g\left({\Theta}_{n0}^{(1)}{x}_0+{\Theta}_{n1}^{(1)}{x}_1+{\Theta}_{n2}^{(1)}{x}_2+\dots +{\Theta}_{nn}^{(1)}{x}_n\right) $$](img/497180_1_En_2_Chapter_TeX_Equf.png)

*   The activation value of the unit in the last layer is the logistic function of the weighted sum of the outputs of the units from the previous layer:

    ![$$ {a}_1^{(3)}={h}_{\Theta}\left(\overline{x}\right)=g\left({\Theta}_{10}^{(2)}{a}_0^{(2)}+{\Theta}_{11}^{(2)}{a}_1^{(2)}+{\Theta}_{12}^{(2)}{a}_2^{(2)}+\dots +{\Theta}_{1n}^{(2)}{a}_n^{(2)}\right) $$](img/497180_1_En_2_Chapter_TeX_Equg.png)

我们可以将第 *j* 层中第 *i* 个单元的激活函数公式概括如下:

![$$ {a}_i^{(j)}=g\left(\sum \limits_{k=0}^n{\Theta}_{ik}^{\left(j-1\right)}{a}_k^{\left(j-1\right)}\right) $$](img/497180_1_En_2_Chapter_TeX_Equ3.png)

(2.3)

或者，使用向量符号，我们可以将第 *j* 层中单元的激活值向量描述为

![$$ {\overline{a}}^{(j)}=g\left({\Theta}^{{\left(j-1\right)}^T}{\overline{a}}^{\left(j-1\right)}\right) $$](img/497180_1_En_2_Chapter_TeX_Equ4.png)

(2.4)

这种算法通常被称为**前向传播**，它是一个具有特定权重集的神经网络如何在给定一些输入数据的情况下做出预测——直觉基本上是*通过每个节点从输入层到输出层传播*输入值。前向传播可以被视为在多单元场景中逻辑回归中使用的假设函数的推广。一些观察结果:

*   请记住， *g* 是逻辑函数，我们在每一层使用它来“离散化”输入的加权和。

*   到目前为止，我们已经设置了 *x* <sub>0</sub> = 1，因此每个输入向量的大小实际上都是 *n* + 1。我们对神经网络也保持这种做法，每个 *j* 层将有其自己的*偏置单元* ![$$ {a}_0^{(j)} $$](img/497180_1_En_2_Chapter_TeX_IEq8.png)。我们可以假设这些偏置值现在总是等于 1，但是我们将在后面看到如何调整偏置向量来提高我们的模型的性能。

*   在我们到目前为止考虑的例子中，输入层和隐藏层都有 *n* + 1 个单元。虽然在大多数情况下输入层确实有 *n* + 1 个单元，其中 *n* 是输入的维数，并且输出层的单元数通常与输出类的数量一样多，但是对隐藏层中的单元数没有限制。实际上，在许多情况下，拥有比输入维度的数量更多的单元(至少在第一个隐藏层中)是一种常见的做法，但是要注意模型的性能，以确保不要一直添加超过实际上不会提高性能指标的隐藏单元。

*   正如我前面提到的，隐藏层的数量也没有限制。事实上，添加更多的隐藏层通常会在许多情况下提高模型的性能，因为您的网络将能够检测到更细微的模式。但是，就像处理单元数量的良好做法一样，您可能也不希望通过添加比您要解决的分类问题类型实际所需更多的层来过度设计您的模型，因为添加过多的中间层或单元在最好的情况下可能对网络没有可测量的影响，在最坏的情况下会因为过度拟合而降低网络的性能。同样，最佳实践是使用不同数量的单元尝试不同数量的层，并查看您何时能在良好的模型性能指标和良好的系统性能指标之间找到“最佳点”。

## 2.1 反向传播

如果前向传播是神经网络进行预测的方式，那么反向传播就是神经网络“学习”的方式——即，在给定训练集的情况下，它如何调整其权重张量θ。就像我们对回归所做的一样，对于神经网络，学习阶段可以通过定义我们想要优化的*成本函数*来推断。

在一般情况下，您将拥有一个具有 *K* 个输出的神经网络，其中这些输出是您想要检测的类。每个输出表示某个输入属于那个类的*概率*，在 0 和 1 之间。例如，如果网络的输入是衣服的图片，并且您想要检测图片中是否包含衬衫、裙子或裤子，则可能需要用三个输出单元来建模神经网络。例如，如果一幅图片包含一件衬衫，您希望该网络输出类似于[1，0，0]的内容。如果是一条裤子，你希望它输出类似于[0，0，1]的东西，以此类推。因此，与我们到目前为止看到的只有一个输出变量的假设函数不同，您将拥有一个包含 *K* 个值的向量的假设函数![$$ {h}_{\Theta}\left(\overline{x}\right)\in {\mathfrak{R}}^K $$](img/497180_1_En_2_Chapter_TeX_IEq9.png)，每个类一个。您的模型的预测类通常是具有最高值的![$$ {h}_{\Theta}\left(\overline{x}\right) $$](img/497180_1_En_2_Chapter_TeX_IEq10.png)函数的索引:

![$$ \mathrm{class}={\mathrm{argmax}}_i{h}_{\Theta}^{(i)}\left(\overline{x}\right) $$](img/497180_1_En_2_Chapter_TeX_Equh.png)

在前面的示例中，如果您为某个图片获得了一个类似[0.8，0.2，0.1]的假设向量，并且您的输出单位按照[*衬衫*、*裙子*、*裤子*]的顺序设置，那么该图片很可能包含一件衬衫。

因此，神经网络的成本函数的工作是最小化训练集中标签的第 *i* 个向量![$$ {\overline{y}}^{(i)} $$](img/497180_1_En_2_Chapter_TeX_IEq11.png)和预测输出向量![$$ {h}_{\Theta}\left(\overline{x}\right) $$](img/497180_1_En_2_Chapter_TeX_IEq12.png)之间的分类误差。当我们涵盖逻辑回归:

![$$ J\left(\overline{\theta}\right)=-\frac{1}{m}\left[\sum \limits_{i=1}^m{y}^{(i)}\log {h}_{\theta}\left({\overline{x}}^{(i)}\right)+\left(1-{y}^{(i)}\right)\log \left(1-{h}_{\theta}\left({\overline{x}}^{(i)}\right)\right)\right] $$](img/497180_1_En_2_Chapter_TeX_Equ5.png)

(2.5)时，我们已经在等式 1.46 中的真/假二元分类问题的情况下看到了这种类型的成本函数

如果对于第 *i* 个输入样本，我们有一个由 *K* 个项组成的向量，而不是一个单个标签 *y* <sup>( *i* )</sup> ，并且我们有一个由权重 *θ* 组成的 3D 张量，其中每个切片代表权重矩阵，以将一层映射到下一层，那么成本函数可以重写如下:

![$$ {\displaystyle \begin{array}{rr}J\left(\Theta \right)=-\frac{1}{m}\left[\sum \limits_{i=1}^m\sum \limits_{k=1}^K{y}_k^{(i)}\log {\left({h}_{\Theta}\left({\overline{x}}^{(i)}\right)\right)}_k+\left(1-{y}_k^{(i)}\right)\log {\left(1-{h}_{\Theta}\left({\overline{x}}^{(i)}\right)\right)}_k\right]&amp; +\\ {}&amp; \end{array}} $$](img/497180_1_En_2_Chapter_TeX_Equi.png)

总和中的第二项(乘以![$$ \frac{\lambda }{2m} $$](img/497180_1_En_2_Chapter_TeX_IEq13.png))是将每层的*偏置输入*(![$$ {x}_0^{(j)} $$](img/497180_1_En_2_Chapter_TeX_IEq14.png)元素的权重)编码为第 *l* 层和第 *l* + 1 层之间的权重的平方和的传统方式。 *λ* 是网络的*偏差率*或*正则化率*，它定义了网络对变化的*惯性*——在这种情况下，高值会导致更为*保守的*模型，也就是说，该模型对其权重应用校正的速度较慢，而低值会导致模型更快地适应变化，但存在*过拟合*数据的风险。训练阶段通常以较低的偏置率开始，以便在开始时快速调整到随时间缓慢降低的校正。

就像在回归的情况下，寻找θ的最优值是最小化前面的成本函数的问题；因此，执行某种形式的梯度下降，以找到它的最小值。在神经网络中，这个过程通常是逐层进行的，从输出层开始，逐层向后调整权重(这就是为什么称之为*反向传播*)。直觉是首先将网络的输出与预期样本进行比较，并且当我们调整输出层中单元的权重以更紧密地匹配输出时，我们计算前一层中单元的新的中间预期结果，并且我们继续调整权重，直到到达第一层。

让我们考虑一个具有 4 层和两个输出的网络，如图 2-5 所示。如果我们给它一个输入![$$ \overline{x}=\left[{x}_1,{x}_2,{x}_3\right] $$](img/497180_1_En_2_Chapter_TeX_IEq15.png)和一个期望标签的向量![$$ \overline{y}=\left[{y}_1,{y}_2\right] $$](img/497180_1_En_2_Chapter_TeX_IEq16.png)，并对其应用前向传播，我们可以计算它的假设函数![$$ {h}_{\Theta}\left({\overline{x}}^{(i)}\right)\in {\mathfrak{R}}² $$](img/497180_1_En_2_Chapter_TeX_IEq17.png) :

![$$ {\displaystyle \begin{array}{rr}&amp; {\overline{a}}^{(1)}=\overline{x}\\ {}&amp; {\overline{a}}^{(2)}=g\left({\Theta}^{(1)^T}{\overline{a}}¹\right)\\ {}&amp; {\overline{a}}^{(3)}=g\left({\Theta}^{(2)^T}{\overline{a}}²\right)\\ {}&amp; {\overline{a}}^{(4)}={h}_{\Theta}\left(\overline{x}\right)=g\left({\Theta}^{(3)^T}{\overline{a}}³\right)\end{array}} $$](img/497180_1_En_2_Chapter_TeX_Equj.png)

然后，就像回归的情况一样，我们希望找到使成本函数*J*(θ)最小化的θ(在这种情况下是 3D 张量)的值。换句话说，对于每一层 *l* ，我们要计算它的梯度向量∇*j*(θ<sup>(*l*)</sup>)。我们希望这个向量的值尽可能接近零:

![$$ \nabla J\left({\Theta}^{(l)}\right)\underset{\mathbf{set}}{=}0\kern0.5em \forall 1\le l\le L-1 $$](img/497180_1_En_2_Chapter_TeX_Equk.png)

这意味着*J*(θ<sup>(*l*)</sup>)相对于其权重![$$ {\Theta}_{ij}^{(l)} $$](img/497180_1_En_2_Chapter_TeX_IEq18.png)的偏导数应该设置为零，因此我们可以从得到的等式中导出最佳权重:

![img/497180_1_En_2_Fig5_HTML.png](img/497180_1_En_2_Fig5_HTML.png)

图 2-5

L = 4 层，n = 3 个输入，K = 2 个输出的神经网络示例

![$$ \frac{\partial }{\partial {\Theta}_{ij}^{(l)}}J\left({\Theta}^{(l)}\right)\underset{\mathbf{set}}{=}0\kern0.5em {\displaystyle \begin{array}{r}1\le i\le {s}_l,\\ {}1\le j\le {s}_{l+1}\end{array}} $$](img/497180_1_En_2_Chapter_TeX_Equl.png)

然后我们定义一个量![$$ {\delta}_j^{(l)} $$](img/497180_1_En_2_Chapter_TeX_IEq19.png)作为第 *l* 层中第 *j* 个单元的误差系数，从最后一层开始，其中系数定义为

![$$ {\delta}_j^{(4)}={a}_j^{(4)}-{y}_j\ \mathrm{for}\ j=1,2 $$](img/497180_1_En_2_Chapter_TeX_Equm.png)

或者，以矢量的形式:

![$$ {\overline{\delta}}^{(4)}={\overline{a}}^{(4)}-\overline{y} $$](img/497180_1_En_2_Chapter_TeX_Equn.png)

考虑到输出层上的误差，我们通过以下方式计算将这些单元连接到先前层中的单元的权重的校正:

![img/497180_1_En_2_Figa_HTML.png](img/497180_1_En_2_Figa_HTML.png)

这里发生了相当多的事情，所以让我们一项一项地挖掘:

*   θ<sup>(3)</sup>是包含连接网络第二层到第三层的权重的矩阵。如果如图 2-5 所示，第三层有三个单元，第二层有四个单元，那么θ<sup>(3)</sup>就是一个 3 × 4 的矩阵。

*   我们在一层中的权重的转置矩阵和在下一层计算的 *δ* 校正系数的向量之间执行矩阵-向量乘积。结果是一个矢量，它包含的元素数量与层中的单元数量一样多。

*   We then perform an element-wise product (or *Hadamard product*, denoted by ⊙) between that vector and the vector of partial derivatives of the activation function of the units in the layer (using the notation we have seen in Equation 2.4). The element-wise product is intuitively the element-by-element product between two vectors with the same size, for example:

    ![img/497180_1_En_2_Figb_HTML.png](img/497180_1_En_2_Figb_HTML.png)

*   ∇ *g* 是为每个单元计算的激活函数(通常是 sigmoid 函数)的梯度向量。

我们可以推广前面的表达式，将第 *l* 层中单元的校正系数表示为

![img/497180_1_En_2_Figc_HTML.png](img/497180_1_En_2_Figc_HTML.png)

如方程 2.4 所示，激活函数![$$ g\left({\Theta}^{{\left(l-1\right)}^T}{a}^{\left(l-1\right)}\right) $$](img/497180_1_En_2_Chapter_TeX_IEq20.png)表示第 *l* 、第*a*??(*l*)层单元的激活值。通过求解导数，我们可以推导出此公式为*δ*(*l*):2.7

![img/497180_1_En_2_Figd_HTML.png](img/497180_1_En_2_Figd_HTML.png)

2.7

有可能证明(尽管推导过程相当冗长，我们将在本章跳过)成本函数的偏导数和系数![$$ \overline{\delta} $$](img/497180_1_En_2_Chapter_TeX_IEq21.png)(暂时忽略偏差系数和归一化率 *λ* ):

![$$ \frac{\partial }{\partial {\Theta}_{ij}^{(l)}}J\left(\Theta \right)={\overline{a}}_j^{(l)}{\overline{\delta}}_i^{\left(l+1\right)} $$](img/497180_1_En_2_Chapter_TeX_Equ8.png)

(2.8)

由于成本函数的偏导数正是我们想要最小化的，我们可以使用等式 2.7 和 2.8 的结果来定义具有*1*层的网络如何通过训练集上的正向和反向传播循环进行“学习”:

*   在你的模型中初始化权重θ，随机地或者根据一些启发，并且初始化一个张量δ，该张量包含每个权重的成本函数的偏导数，对于第 *l* + 1 层中的第 *i* 单元与第 *l* 层中的第 *j* 单元的每个连接使用![$$ {\Delta}_{ij}^{(l)}=0 $$](img/497180_1_En_2_Chapter_TeX_IEq22.png)。

*   迭代规范化训练集![$$ X=\left\{\left({\overline{x}}^{(1)},{\overline{y}}^{(1)}\right),\dots, \left({\overline{x}}^{(m)},{\overline{y}}^{(m)}\right)\right\} $$](img/497180_1_En_2_Chapter_TeX_IEq23.png)中的所有项目。

*   对于每个第 *i* 个训练项目，设置![$$ {\overline{a}}^{(1)}={\overline{x}}^{(i)} $$](img/497180_1_En_2_Chapter_TeX_IEq24.png)—网络的输入单元将使用每个标准化的输入向量进行初始化。

*   Perform forward-propagation to compute the activation values of the units in the next layers, ![$$ {\overline{a}}^{(l)} $$](img/497180_1_En_2_Chapter_TeX_IEq25.png), with 1 < *l* ≤ *L*:

    ![$$ {\overline{a}}^{(l)}=g\left({\Theta}^{{\left(l-1\right)}^T}{\overline{a}}^{\left(l-1\right)}\right) $$](img/497180_1_En_2_Chapter_TeX_Equr.png)

*   set![$$ {h}_{\Theta}\left({\overline{x}}^{(i)}\right)={\overline{a}}^{(L)} $$](img/497180_1_En_2_Chapter_TeX_IEq26.png)—你的网络的预测等于最后一层单元的激活值。

*   Start applying back-propagation by computing the *δ* vector for the last layer, as the difference between the predicted and expected values:

    ![$$ {\overline{\delta}}^{(L)}={\overline{a}}^{(L)}-{\overline{y}}^{(i)} $$](img/497180_1_En_2_Chapter_TeX_Equs.png)

*   Continue back-propagation by computing the *δ* vectors for the other layers, starting from the *L* − 1-th layer and moving all the way back until the input layer:

    ![img/497180_1_En_2_Fige_HTML.png](img/497180_1_En_2_Fige_HTML.png)

*   Update the tensor of the corrections to be applied to the weights:

    ![$$ {\Delta}_{ij}^{(l)}\underset{\mathbf{set}}{=}{\Delta}_{ij}^{(l)}+{\overline{a}}_j^{(l)}{\overline{\delta}}_i^{\left(l+1\right)} $$](img/497180_1_En_2_Chapter_TeX_Equu.png)

*   After iterating on the training set, we will have our tensor Δ fully calculated. We can now take regularization into account by introducing for each layer the bias unit (*j* = 0) and dividing each of the partial derivatives by the number of samples in the training set:

    ![$$ {\Delta}_{ij}^{(l)}\underset{\mathbf{set}}{=}\left\{\begin{array}{ll}\frac{1}{m}{\Delta}_{ij}^{(l)}&amp;\ \mathrm{if}\ j=0\\ {}\frac{1}{m}{\Delta}_{ij}^{(l)}+\lambda {\Theta}_{ij}^{(l)}&amp;\ \mathrm{if}\ j\ne 0\end{array}\right. $$](img/497180_1_En_2_Chapter_TeX_Equv.png)

*   We know that

    ![$$ {\Delta}_{ij}^{(l)}=\frac{\partial }{\partial {\Theta}_{ij}^{(l)}}J\left(\Theta \right) $$](img/497180_1_En_2_Chapter_TeX_Equw.png)

*   We can therefore plug these values into a gradient descent logic and use a learning rate *α* to update each weight according to these quantities:

    ![$$ {\theta}_{ij}^{(l)}\underset{\mathbf{set}}{=}{\theta}_{ij}^{(l)}-\alpha {\Delta}_{ij}^{(l)} $$](img/497180_1_En_2_Chapter_TeX_Equx.png)

*   对训练集的给定数量的*个时期*应用这种算法，或者直到满足某些收敛标准，你就拥有了训练网络的所有要素。

## 2.2 实施指南

为了优化神经网络的性能，您可能需要遵循一些好的做法:

*   *随机初始化网络的权重*。在大多数情况下，在预设间隔内随机初始化权重[-*ϵ*， *ϵ* ]是初始化网络的最佳方式。如果您用零(或任何其他常数)初始化权重，那么在第一次迭代中您将获得可预测的输出值。随机初始化打破了这种对称性，如果您多次训练模型，它比总是以相同方式初始化权重的解决方案更有可能将您的模型指向正确的方向。

*   *在训练阶段*之前或期间，对您的模型进行坡度检查。与我们在线性和逻辑回归的情况下看到的成本函数不同，神经网络的成本函数不能保证是凸的。这意味着，如果你从任何一点沿着梯度向量的方向，并不能保证模型收敛到全局最小值，因为你不再是把球滚下碗状的山坡。这意味着您可能希望检查以下两个方面:( 1)您为梯度下降选择的初始方向实际上导致了成本函数的显著降低(即，您没有被困在局部山谷中),( 2)学习率得到了很好的校准——如果学习率太低，您可能下降得太慢，如果学习率太高，模型可能会超过最小值而根本不会收敛。

*   *试验你的网络架构*。对于解决某个问题，多少层和多少个单元是最好的，并没有确定的规则。一般经验表明，中间层越多、中间层中的单元越多，网络的性能通常越好。然而，你可能也想避免过度工程化:一个识别 8×8 像素图像中手写数字的简单网络不一定需要 10 个中间层，每个中间层有数百个单元。不仅如此，在某个点之后增加更多的单元或层会导致过度拟合。因此，尝试不同的架构，看看在相同的训练集和训练迭代次数下，增加单元或层的数量会如何影响模型的性能，并在较大网络带来的性能提升可以忽略不计之前选择一个最佳点。

*   *在向网络*输入数据之前，一定要将输入数据标准化。谈到回归时，我已经足够强调这一点了，它在神经网络中也很重要。

### 2.2.1 欠配和过配

当你在高偏差/低方差(或*欠拟合*)和高方差/低偏差(或*过拟合*)之间训练任何模型时，总是要寻求一个健康的平衡。当我们讨论回归模型时，我们已经看到了这些问题，并且我们发现了绘制归一化数据集的重要性，以便在选择具有较少多项式项(*欠拟合*，模型的线/表面过于“平滑”并且没有真正遵循数据的分布)或太多多项式项(*过拟合*)的函数之前了解数据的分布情况， 模型的线/表面精确地遵循数据的分布，但是当被提供任何看起来不像它被训练的那些数据点时，在准确性上失败)。 这些观察也适用于神经网络。针对欠适应/过适应评估网络性能的最佳方法还是将数据集分成两部分，即训练集和测试集。在训练集上训练您的网络，并评估成本函数在训练迭代中的进展情况:

*   如果成本函数没有减少(或者，更糟的是，增加，或者经历上升/下降周期)，那么模型没有向最小值收敛:确保数据是归一化的，修改你的梯度下降策略，或者降低学习速率 *α* 。

*   如果成本函数下降太慢，那么它在适应训练集中出现的变化方面不够快:您可能希望增加学习率 *α* ，降低归一化率 *λ* ，或者向您的数据添加更多的特征。

*   如果成本函数以令人满意的方式降低，并且您的模型似乎对训练集做出了准确的预测，那么在测试集上对其进行评估(这次不进行训练:只执行前向传播，不执行反向传播)。如果测试集上的成本函数或模型的准确性差得多，那么
    1.  您没有在训练数据和测试数据之间执行很好的拆分，这通常是通过在拆分之前对数据集中的项目进行洗牌来实现的，以保证数据的分布更加均匀。

    2.  网络没有提供足够的数据点来有效地检测数据集中的模式-您可以通过添加更多的数据点来修复它。

    3.  数据集包含太多要素:您可能希望应用主成分分析或任何类型的降维算法来移除冗余要素(其他要素的线性组合)或不会真正影响数据分布和模式的要素。

    4.  网络过拟合训练集中的点。在这种情况下，您可能希望使用单元/图层数量较少的网络进行试验，或者为正则化率 *λ* 选择一个较高的值，以便增加网络对数据集中“波动”的“惯性”。

正如我们已经看到的，一旦我们找到了一种给定训练集的收敛方法，我们主要有两个参数可以调整以调整模型的性能:学习率 *α* 和正则化率 *λ* 。我们已经看到, *α* 决定了网络在收到新数据时的学习速度，而 *λ* 则表达了网络对变化的“抵抗力”。有时数据集被分成三份而不是两份，以便分别调整这两个值:

*   首先，我们在*训练集*上训练模型，并确保其成本函数不断降低。这个阶段的目标是找到最小化成本函数的权重θ的值和一个 *α* (或一个在迭代 *t* 中返回 *α* 的函数 *α* ( *t* )的值，这是速度和鲁棒性之间的一个合理的折衷(表示为模型收敛的趋势，与起点无关)。

*   然后，我们使用*交叉验证集*来调整 *λ* 。这个阶段的目标是选择一个值 *λ* (或者一个函数 *λ* ( *t* )在迭代 *t* 中返回 *λ* ，这是欠拟合和过拟合之间的一个合理的折衷。

*   最后，我们在*测试集*上评估模型，以评估模型在它尚未看到的数据点上的整体性能。我们根据这些数据评估模型的成本函数和任何附件性能指标，并使用它们来确定模型是否表现足够好，或者是否需要更多的训练、不同的参数调整或不同的架构。

另一个好的实践是编写小的测试来检查模型的性能。到目前为止，我们已经介绍了帮助我们对模型的整体性能进行定量分析的数学工具，但是在现实世界的问题中，您可能更清楚您的模型在特定情况下应该预测什么。因此，从你的数据中挑选一些足够重要和足够多样的案例，并编写一些测试来衡量这些案例中有多少是正确的或错误的。这是一个有用的工具，可以有效地跟踪模型随时间的演变。使用此类测试来查看模型中的特定更改是否会导致这些“核心案例”的更好分类，并确保模型的后续更改不会降低其在这些数据点上的性能。

另一个通用的良好做法是记住，机器学习模型仍然是软件的一部分，像任何其他软件一样，它们应该经历类似的过程。使用像 Jupyter notebooks 这样的工具来交互式地可视化数据并训练您的模型，为该过程增加了许多价值和生产力，但请记住，您的工作成果不应只是由笔记本训练的模型文件，该文件将被扔掉或保存在个人笔记本电脑上。训练模型时，除了模型文件之外，您的工作输出还应包括:

*   一个干净的(最好是版本化的)代码库，可以重用它来重新训练模型，调试它，或者训练不同的模型。将代码库的公共部分(如保存和加载模型、规范化数据或初始化分类器)提取到可重用的模块中，这些模块可以轻松导入，这样您就不必重新发明轮子或走上几乎不可维护的复制/粘贴之路。在笔记本上制作脚本，这样训练、评估和预测阶段可以作为独立实体在其他系统上轻松运行，而不需要 Jupyter 环境。

*   按照前面描述的指导原则，对您的模型进行测试。

*   请记住，在真实的应用程序中，您的模型通常是更大的业务逻辑链中的一个模块。在实际应用中，您通常会从某个地方生成或接收数据，对这些数据运行一些自定义逻辑，使用您的机器学习模型对这些数据进行一些预测，并使用这些预测来运行一些额外的业务逻辑。因此，请记住，就像更复杂系统中的任何其他模块一样，在设计机器学习逻辑时，最好考虑到可扩展性和内部通信。从 CSV 文件中读取并在标准输出中打印结果是调试和测试模型的好方法，但是在实际的应用程序中，您可能希望将您的模型包装到例如 WSGI 或 Flask web 应用程序中，这样就可以很容易地在 REST API 上使用它。或者将它设计成可以使用来自消息队列或 WebSocket 的查询或训练/评估命令。如果需要将它部署在多个环境中，您甚至可以考虑将其部署为 Docker 微服务，这样您就不必直接在目标系统上安装所有依赖项，而且通常它还有助于防止“但它可以在我的笔记本电脑上工作”的问题。

*   尽可能跟踪用于训练模型的数据。在过去几年中，机器学习应用数量的增加伴随着越来越多的问题，这些问题与由不良/有偏见的数据导致的不良预测有关。在海量数据上训练模型的公司很难跟踪哪些有偏见的训练输入导致了哪些有偏见的分类，机器学习模型通常被视为黑盒神谕——我们知道它们预测什么，但我们无法说出它们做出这些预测的确切原因。这就是为什么跟踪用于训练模型的数据变得越来越重要，并且最好对其进行版本化/标记:这使得在模型性能下降的情况下更容易找到根本原因，并且还有助于增加模型的可问责性。

## 2.3 误差指标

到目前为止，我们已经分析了一些指标来评估模型的性能。其中包括以下内容:

*   *均方误差*，常用作回归问题中模型的驱动成本函数

*   *平均绝对误差*，有时用作额外的性能指标

*   *分类误差*，在逻辑回归和神经网络中用作驱动成本函数

*   *准确度*，定义为正确分类的数量除以样本总数，可能是最流行的性能指标之一

然而，准确性并不总是给出模型对于特定问题表现如何的准确描述。假设您想要训练一个模型来检测注册到您网站的用户是否是潜在的机器人/骗子/欺诈者。在正常情况下，这样的用户可能只代表网站流量的一小部分，因此，您的数据集可能会描述这样一种情况，其中 99%的用户是普通用户，1%的用户是假冒的。在这种情况下，您可以通过这个简单的函数获得 99%的准确度:

```py
def is_fake(user):
    return False

```

准确性的问题是，当分类问题涉及*偏斜*类时，它无法提供模型实际性能的良好描述，即，具有非常不同分布的类，通常与异常检测问题或一般涉及罕见事件预测的问题相关。

对于这种情况，它通常有助于一种比查看整体准确性更细粒度的方法。为了简单起见，让我们考虑一个二元分类问题: *y* = 0 表示一个负的数据点，而 *y* = 1 表示一个正的数据点。我们的模型对每个数据点进行预测——要么是![$$ {h}_{\Theta}\left(\overline{x}\right)=0 $$](img/497180_1_En_2_Chapter_TeX_IEq27.png)(负面预测)，要么是![$$ {h}_{\Theta}\left(\overline{x}\right)=1 $$](img/497180_1_En_2_Chapter_TeX_IEq28.png)(正面预测)。我们可以根据预测值定义以下指标:

1.  *真阳性* ( **TP** ):标记为阳性和预测为阳性的数据点( *y* = 1 和![$$ {h}_{\Theta}\left(\overline{x}\right)=1 $$](img/497180_1_En_2_Chapter_TeX_IEq29.png))

2.  *真阴性* ( **TN** ):标记为阴性和预测为阴性的数据点( *y* = 1 和![$$ {h}_{\Theta}\left(\overline{x}\right)=1 $$](img/497180_1_En_2_Chapter_TeX_IEq30.png))

3.  *假阳性* ( **FP** ):标记为阴性但预测为阳性的数据点( *y* = 0 和![$$ {h}_{\Theta}\left(\overline{x}\right)=1 $$](img/497180_1_En_2_Chapter_TeX_IEq31.png))

4.  *假阴性* ( **FN** ):标记为阳性但预测为阴性的数据点( *y* = 1 和![$$ {h}_{\Theta}\left(\overline{x}\right)=0 $$](img/497180_1_En_2_Chapter_TeX_IEq32.png))

![img/497180_1_En_2_Fig6_HTML.jpg](img/497180_1_En_2_Fig6_HTML.jpg)

图 2-6

混淆矩阵的结构。在运行模型验证后，每个单元格报告符合所选类别的项目数

通常这些度量在一个*混淆矩阵*中可视化，其结构如图 2-6 所示。

有了这个新的形式主义，我们可以将模型的精度定义如下:

![$$ accuracy=\frac{TP+ TN}{TP+ TN+ FP+ FN} $$](img/497180_1_En_2_Chapter_TeX_Equy.png)

准确性是回答问题“可用项目的哪个部分被正确分类了？”

我们将**精度**定义为回答问题“预测为正的项目中有多少部分实际上是正的？”![$$ precision=\frac{TP}{TP+ FP} $$](img/497180_1_En_2_Chapter_TeX_Equz.png)

而**召回**是回答问题“标记为肯定的项目中有多少部分被预测为肯定的？”![$$ recall=\frac{TP}{TP+ FN} $$](img/497180_1_En_2_Chapter_TeX_Equaa.png)

让我们将这两个新指标应用到前面显示的`is_fake(user)`函数中。假设我们在一个包含 100 个用户的测试集上运行这个总是返回*假*的天真模型，其中 1 个是假的，99 个是正常的。因此，我们有

*   TP= 0

*   *TN* = 99

*   *FP* = 0

*   *联合国* = 1

和

*   ![$$ accuracy=\frac{0+99}{0+99+0+1}=99\% $$](img/497180_1_En_2_Chapter_TeX_IEq33.png)

*   ![$$ precision=\frac{0}{0+0}=N/A $$](img/497180_1_En_2_Chapter_TeX_IEq34.png)

*   ![$$ recall=\frac{0}{0+1}=0\% $$](img/497180_1_En_2_Chapter_TeX_IEq35.png)

召回值为 0 显然表明分类器有问题，尽管总体准确率为 99%。请注意，精确度和召回率并不总是可测量的:在一些极限情况下，比如我们的朴素`is_fake(user)`函数，分母可能是零——但这两个指标中至少有一个通常是可计算的。

您可以使用这两个额外的度量来更好地评估模型的性能，并优化具有偏斜类的分类问题的性能-如果需要，甚至会以牺牲整体准确性为代价。您还可以根据您的业务逻辑找到这两个指标之间的折衷。假设您的模型根据 X 射线图像预测患者是否患有癌症:您可以根据您对问题*的回答优化其精确度或召回率，告诉健康患者他们患有癌症更糟糕，还是告诉癌症患者他们健康更糟糕？*

如果您的模型从银行的摄像头图像中检测到潜在的入侵，您可能希望优化召回-如果真实入侵的成本非常高，那么确保检测到任何潜在的入侵可能是安全的，即使以更高数量的误报为代价。相反，如果您的模型向某个部门的所有员工发送关于某个系统上潜在流量峰值的通知，您可能希望精确度高于召回率—当我们非常确信存在峰值时发送通知，以防止向员工发送误报垃圾邮件。

有时，一个结合了精确度和召回率的度量标准被用来评估模型的性能: **F1 分数**被定义为精确度和召回率的*调和平均值*，并且经常被用作一个更细粒度的精确度度量标准:

![$$ {F}_1=2\frac{PR}{P+R} $$](img/497180_1_En_2_Chapter_TeX_Equab.png)

总而言之，到目前为止，我们已经介绍了

*   神经网络背后的直觉，如何使用它们进行预测(前向传播)，以及如何训练它们(反向传播)

*   如何评估训练过程的质量——防止欠适应和过适应的措施、标准化、规范化和特征选择

*   调试、测试、设计、打包和分发我们的机器学习模型的最佳实践是什么

*   如果我们的类别有偏差，或者我们想要检测异常情况，可以使用哪些附件性能指标来评估模型

现在，我们已经具备了开始动手编写代码的所有要素。

## 2.4 实施网络识别服装项目

如今，使用 TensorFlow 和 Keras 等库实现神经网络相对容易。我不会像对回归那样从头开始介绍 Python 中正向传播和反向传播的完整实现，但是即使您不太可能发现自己处于必须自己实现完整算法的情况下，我也强烈建议您尝试从头实现它，以确保您掌握了所有的直觉。毕竟，就在不久之前，开发人员还必须自己实现这些算法——我相信，我用 C++编写的 12 年之久的神经网络库仍然丢失在旧的谷歌代码门户的某个地方。即使现在可以用三行 Python 代码来完成模型的初始化、编译和训练，该框架也不会对数据进行规范化，而且 TensorFlow 和 Keras 提供的方法仍然需要一些关于算法如何工作的调整和知识，如果您想让您的模型在现实世界的应用程序中工作的话。

在这一节中，我们将介绍一个通常被认为是神经网络的新 hello 世界的例子:最初由 Zalando 上传的`Fashion MNIST`数据集。传统的 MNIST 数据集多年来一直被用来向学生介绍机器学习，它包括一个带有手写和标签数字的大型图像列表。时尚 MNIST 数据集在原始问题的基础上增加了一点复杂性——你必须训练一个从图片中检测服装的模型。默认情况下，典型 TensorFlow+Keras 安装会提供时尚 MNIST 数据集，您可以像这样将其加载到笔记本中:

```py
import tensorflow as tf
from tensorflow import keras

fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = \
    fashion_mnist.load_data()

```

数据集中包含了十种服装，但是它们的类不是直接作为字符串提供的。您可以用关联的类名初始化数组:

```py
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag',
               'Ankle boot']

```

通过查看数据，我们注意到训练集包含 60，000 幅图像，而测试集包含 10，000 幅图像，在这两种情况下，我们处理的都是 28x28 像素的黑白图像:

```py
train_images.shape
# Output: (60000, 28, 28)
test_images.shape
# Output: (10000, 28, 28)

```

说到标签，它们的值在 0-9 的范围内，可以映射到我们的`class_names`向量:

```py
train_labels
# Output: array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)
test_labels
# Output: array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)

```

![img/497180_1_En_2_Fig7_HTML.jpg](img/497180_1_En_2_Fig7_HTML.jpg)

图 2-7

来自时尚 MNIST 数据集的图像直方图

当我们处理图像时，我们要做的第一件事是查看数据集中的一些图像，以获得关于颜色空间、范围和外观的提示:该数据集中的图像已经被修剪以仅包括服装项目，但是在现实世界的场景中，您可能会得到大型数据集，这些数据集在被馈送到神经网络之前需要某种形式的预处理(如修剪、缩小或颜色转换):

```py
import matplotlib.pyplot as plt

plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()

```

您将看到如图 2-7 所示的图片。我们正在处理黑白图像，关于每个像素的信息被编码在一个字节中，因此每个像素具有 0(黑色)和 255(白色)之间的值。对于对图像进行操作的模型，第一步是对其进行归一化，对于黑白图像，这通常通过应用将[0，255]范围转换为[0，1.0]范围的变换来完成:

```py
def normalize(images):
    return images / 255.0

train_images = normalize(train_images)
test_images = normalize(test_images)

```

关于色彩空间的快速注释。当谈到处理图像的模型时，如果您真的想提高性能，选择正确的颜色空间是非常重要的。虽然 RGB 是导出图像的最常见选项，但它不一定是训练模型的最佳格式。在为你的模型选择一个特定的颜色空间之前，问你自己这样一个问题:我想在这些图像中发现什么样的信息或模式？如果你的神经网络应该用于自动驾驶汽车，以识别交通灯的颜色，那么 RGB 是一个很好的选择。如果你想在背景下检测形状，黑白通常是更好的选择——它不仅使模型更简单、更快，而且更鲁棒，因为同一物体或形状的不同图片可能会根据照明或环境条件显示不同的颜色。其他应用程序使用更奇特的色彩空间可能会执行得更好。例如，如果你的模型应该识别房间内的照明条件，那么考虑亮度的色彩空间(如 YUV 或 YCbCr)可以比 RGB 或灰度表现得更好。在其他应用中，模式取决于图像的颜色或饱和度，考虑这些指标的色彩空间(如 HSL 和 HSV)可能是最佳选择。请记住，您选择的色彩空间会影响网络能够推断的模式。不仅如此，还要根据模型应该识别的内容为模型选择正确的数据源。如果你想对物体进行分类，来自光学相机的图像非常有用。相反，如果您想要检测人的存在，那么红外或热感相机可以提供更好的性能，因为光学相机的图像会有很大的可变性——一个人可以在房间的不同位置以不同的姿势站着、坐着或躺着，并且您也可以在同一房间中有多个人，而红外相机只会为您提供模型实际需要的信息:“图像中是否有大约 36–37°C 的人形热源？”在其他应用中，您可能希望依赖更多的输入:如果您还集成了麦克风或其他环境传感器的数据，则检测人的存在的模型会更加准确。

机器学习通常被描述为一个过程，在这个过程中，你向模型输入数据，模型会自己“学习”，但现实比这更复杂。选择正确的信息来源、收集数据、删除冗余信息、修整和转换数据、检测任何潜在的偏差来源，以及对数据进行标准化，这些实际上决定了模型 90%的性能。我们到目前为止所探索的数学，如今往往在库和框架中实现；它相对复杂，但是您不必从头开始实现它(即使这并不意味着您不需要理解这些模型是如何工作的)。如今真正重要的是你使用的数据的质量，以及你在编写第一行代码之前收集数据的能力。机器学习不像给模型输入数据，让模型自己学习。这更类似于企鹅喂养后代的方式——成年企鹅负责捕鱼、咀嚼和预消化食物，然后再喂给幼崽。

也就是说，让我们继续我们的衣服分类器。一个好主意是查看一组图像在数据集中的外观以及它们的分类:

```py
plt.figure(figsize=(10,10))

# Plot the first 25 images and their
# associated classes in a 5x5 grid
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])

plt.show()

```

![img/497180_1_En_2_Fig8_HTML.jpg](img/497180_1_En_2_Fig8_HTML.jpg)

图 2-8

对时尚 MNIST 数据集的前 25 幅图像进行采样

您应该会看到如图 2-8 所示的图形。

如果分类看起来是正确的，并且数据是标准化的，那么让我们继续构建神经网络分类器。这通常在 Keras 中使用`Sequential`模型来完成，该模型将多个定制层链接在一起。通常，处理图像分类问题的模型具有以下结构:

1.  包含与每个图像的像素数一样多的单元的输入层。然而，我们已经看到，网络的输入层是单位的一维向量，而这里我们处理的是二维图像。因此，第一层通常是`Flatten`类型，它将二维图像“展开”成一维数组，这些数组可以传播到下一层。我们已经看到，时尚 MNIST 数据集中的图像是 28x28 像素的图像:这意味着我们的第一层将有 28 × 28 = 784 个单位。

2.  输出图层的单元数量与我们想要检测的类别数量一样多。在我们的例子中，10 个类意味着输出层中的 10 个单元，具有最高激活值的单元是我们想要关联到特定数据点的单元。

3.  输入层和输出层之间的可变数量的隐藏层，具有可变数量的单元。我们之前已经看到，增加中间单元和层的数量是提高模型精度的一种好方法，但是增加太多可能会导致过度拟合，通常可以通过调整单元和层的数量来克服这一问题，直到在训练集和测试集的精度之间达到令人满意的平衡，或者通过增加正则化率来使网络更加紧密地“锚定”我们将对输出层和中间层使用`Dense` Keras 层类型，它初始化一个层，使它的每个单元都连接到上一层和下一层中的每个单元。

综上所述，让我们继续编写初始化模型的代码:

```py
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(500, activation="sigmoid"),
    keras.layers.Dense(200, activation="sigmoid"),
    keras.layers.Dense(10, activation="softmax")
    ])

```

该代码定义了一个具有一个输入层、两个隐藏层和一个输出层的网络(`keras.Sequential`)。第一层以我们归一化的 28 × 28 图像向量作为输入，将其转换为一维向量(`keras.Flatten`)。两个隐藏层分别包含 500 和 200 个单元(您可以随意试验单元和隐藏层的数量，看看它是如何影响模型的)。他们使用一种`sigmoid`激活功能——与我们目前探索的功能相同。输出图层有 10 个单元，与类的数量一样多。每个单元的值将表示给定输入图像属于该类别的概率。每当我们有多个类时，我们可能希望对输出层使用`softmax`激活函数，并且我们希望将每个单元的值表示为概率/置信水平。

接下来，就像在回归模型中一样，我们希望*编译*这个模型，这样它就可以接受训练了:

```py
model.compile(optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    # or loss="categorical_crossentropy",
    metrics=['accuracy'])

```

挖掘这里发生的事情:

*   我们使用`adam`作为网络的优化器，这是一种基于一阶梯度的优化算法，于 2014 年首次提出，在过去几年中获得了相当大的人气，用于训练深度神经网络。我们已经在回归一章中介绍了其他优化器。其中许多算法——随机梯度下降(SGD)、nadam、RMSprop 等——也常用于神经网络。同样，掌握优化器的最好方法是阅读那些最常用的优化器，并试验哪一个对您的数据执行得更好。

*   然后，我们定义一个我们希望使用优化器最小化的成本函数(就像我们已经在回归的情况下看到的那样，Keras 框架将它们命名为*损失函数*而不是成本函数，但它们基本上意味着相同的东西)。虽然均方误差(或均对数平方误差)是线性回归问题的常见选择，但交叉熵函数是分类问题的常见选择，包括逻辑回归和通过神经网络的分类。交叉熵的概念非常接近我们在分类问题中分析过的成本函数![$$ J\left(\overline{\theta}\right) $$](img/497180_1_En_2_Chapter_TeX_IEq36.png)的类型。一般来说，在信息论中，同一组事件上的两个分布 *p* 和 *q* 之间的交叉熵表示将 *p* 转换为 *q* 所需的平均比特数(或信息片段)。如果 *p* 和 *q* 分别是我们对某一组数据点的预期值和预测值，那么交叉熵就可以直观地测量我们的预测值与预期值之间的“距离”——或者说我们平均需要改变多少位才能使我们的预测值与预期值相匹配。看待交叉熵的另一种方式是从概率的角度:你可以把它看作是对你的预测正确的可能性的一种度量。如果要为真/假预测构建模型，通常会使用二元交叉熵损失函数。在我们的例子中，我们希望对多个类进行预测，因此分类或稀疏分类交叉熵函数通常是一种流行的选择。

*   与回归的情况一样，我们希望定义一个或多个额外的指标作为“健康”指标，以确保模型确实在学习，而不是根据提供的成本函数过度拟合数据点。在这种情况下，就像我们在回归的情况下所做的那样，我们使用精确度，但请记住，根据数据的分布(尤其是在倾斜数据集的情况下)以及您想要在假阳性和假阴性之间实现的权衡，您还可以使用精确度和召回率或任何其他指标。

然后，就像我们在回归案例中看到的那样，我们使用`fit`方法在训练集上训练我们编译的模型:

```py
history = model.fit(train_images, train_labels, epochs=10)

```

在这种情况下，我们指定对数据点进行 10 次迭代。同样，请记住，历元的数量可以决定您的模型是否会欠拟合、过拟合或“恰好”拟合数据，因此您可能希望查看笔记本的输出，以了解模型的性能如何随历元而变化:

```py
Epoch 1/10
1875/1875 [======] - 6s 3ms/step - loss: 0.5423 - accuracy: 0.8091
Epoch 2/10
1875/1875 [======] - 6s 3ms/step - loss: 0.3781 - accuracy: 0.8621
Epoch 3/10
1875/1875 [======] - 7s 4ms/step - loss: 0.3396 - accuracy: 0.8755
Epoch 4/10
1875/1875 [======] - 7s 4ms/step - loss: 0.3144 - accuracy: 0.8842
Epoch 5/10
1875/1875 [======] - 9s 5ms/step - loss: 0.2956 - accuracy: 0.8912
Epoch 6/10
1875/1875 [======] - 7s 4ms/step - loss: 0.2805 - accuracy: 0.8961
Epoch 7/10
1875/1875 [======] - 7s 4ms/step - loss: 0.2649 - accuracy: 0.9014
Epoch 8/10
1875/1875 [======] - 7s 4ms/step - loss: 0.2508 - accuracy: 0.9062
Epoch 9/10
1875/1875 [======] - 7s 4ms/step - loss: 0.2387 - accuracy: 0.9105
Epoch 10/10
1875/1875 [======] - 8s 4ms/step - loss: 0.2303 - accuracy: 0.9128

```

解释您的指标的一些常见经验法则:

*   很重要的一点是，你的损失/成本函数在各个时期持续下降。如果它没有明显地趋向于零，那么你可能想要正常化/改善你的训练数据。如果它上下波动，那么成本函数可能会有一些“颠簸”——要么检查您的数据，要么调整学习率、正则化率或优化器。如果您在某个点之后没有注意到很大的改进，这意味着成本函数已经提前收敛，您可以减少历元的数量，或者您可能会遇到过度拟合的问题。

*   虽然成本函数预计会持续下降，但您的次要指标(准确度、精确度或召回率)预计会持续上升。如果他们没有，那么你可能要调查可能的过度拟合问题或调整学习/调整率。

您还可以绘制模型的精度在训练时期内的变化情况:

```py
epochs = history.epoch
accuracy = history.history['accuracy']

fig = plt.figure()
plot = fig.add_subplot()
plot.set_xlabel('epoch')
plot.set_ylabel('accuracy')
plot.plot(epochs, accuracy)

```

一旦我们对训练阶段的性能指标感到满意，就该在测试集上评估新训练的模型了:

![img/497180_1_En_2_Fig9_HTML.jpg](img/497180_1_En_2_Fig9_HTML.jpg)

图 2-9

超过 10 个训练时期的模型精确度的进展

```py
test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)

```

您可能会看到如下输出:

```py
313/313 - 1s - loss: 0.3185 - accuracy: 0.8871

```

绘制各时期的精度图应该会得到如图 2-9 所示的图表。

这意味着我们的模型在 313 个项目的测试集上有 88.71%的概率猜对这个类。如果我们将其与之前的输出进行比较，这比上一次训练迭代所达到的精度低 2.5%。在真实情况下，由您(或项目负责人)决定这样的结果是否足够好。如果测试集的准确性与训练集的准确性相差太多，那么，您可能需要再次调查过度拟合。增加测试集中的样本数量也是一个很好的做法，这样可以得到更有统计学意义的观察结果。

现在，看一眼测试集中的一些图像，看看神经网络在这些图像上的表现是一个好主意。让我们首先定义几个效用函数，将测试集的一些预测显示在网格上，每个元素包含测试图像、预期标签、预测标签和模型预测该标签的置信度:

```py
import numpy as np
import matplotlib.pyplot as plt

# Plot the image, the predicted/expected label
# and the confidence level
def plot_image_and_predictions(prediction, classes, true_label, img):
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(img, cmap=plt.cm.binary)
    predicted_label = int(np.argmax(prediction))
    confidence = 100 * np.max(prediction)
    color = 'blue' if predicted_label == true_label else 'red'

plt.xlabel('{predicted} {confidence:2.0f}% ({expected})'.format(
    predicted=classes[predicted_label],
    confidence=confidence,
    expected=classes[int(true_label)]), color=color)

# Plot a bar chart with the confidence level of each label
def plot_value_array(prediction, true_label):
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    thisplot = plt.bar(range(len(prediction)), prediction, color="#777777")
    plt.ylim([0, 1])
    predicted_label = np.argmax(prediction)

    thisplot[predicted_label].set_color('red')
    thisplot[true_label].set_color('blue')

# Plot the first N test images, their predicted and expected label.
# It colors correct predictions in blue, incorrect predictions in red.
def plot_results(images, labels, predictions, classes, rows, cols):
    n_images = rows * cols
    plt.figure(figsize=(2 * 2 * cols, 2 * rows))

    for i in range(n_images):
        plt.subplot(rows, 2 * cols, 2 * i + 1)
        plot_image_and_predictions(predictions[i], classes,
                                   labels[i], images[i])
        plt.subplot(rows, 2 * cols, 2 * i + 2)
        plot_value_array(predictions[i], labels[i])

    plt.show()

# predictions will contain the predicted values for the test set
predictions = model.predict(test_images)

# Plot the predictions for the first 25 values of the test set
plot_results(images=test_images, labels=test_labels, classes=class_names,
             predictions=predictions, rows=5, cols=5)

```

您可能会看到如图 2-10 所示的图形。这种应用于测试集的可视化有助于您了解网络如何对不在训练集中的图像执行操作，并且您可以使用它来找出可以帮助您改进模型的常见模式，例如通常被错误标注或具有“接近”误差范围的项目类别。您可能希望使用这种可视化来细化您的输入数据，改进您的图像预处理管道，或者使用目前为止看到的策略(调整学习率、标准化率、神经元数量、时期数量、成本函数等)来调整模型。)来提高业绩，直到你满意为止。

![img/497180_1_En_2_Fig10_HTML.jpg](img/497180_1_En_2_Fig10_HTML.jpg)

图 2-10

绘制测试集中前 25 幅图像的预测类别，以及预期标签和分类置信度

一旦您对您的模型感到满意，不要忘记保存它。该过程与我们之前看到的保存张量流回归模型的过程相同:

```py
def model_save(model_dir, labels, overwrite=True):
    import json
    import os

    # Create the model directory if it doesn't exist
    os.makedirs(model_dir, exist_ok=True)

    # The TensorFlow model save won't keep track of the
    # labels of your model.  It's usually a good practice to
    # store them in a separate JSON file.
    labels_file = os.path.join(model_dir, 'labels.json')
    with open(labels_file, 'w') as f:
        f.write(json.dumps(list(labels)))

    # Then, save the TensorFlow model using the save primitive
    model.save(model_dir, overwrite=overwrite)

model_dir = '/home/user/models/fashion-mnist'
model_save(model_dir, labels=class_names)

```

同样，您可以从您的应用程序中加载保存的模型，而无需再次经历培训阶段:

```py
def model_load(model_dir):
    import json
    import os
    from tensorflow.keras.models import load_model

    labels = []
    labels_file = os.path.join(model_dir, 'labels.json')

    if os.path.isfile(labels_file):
        with open(labels_file) as f:
            labels = json.load(f)

    m = load_model(model_dir)
    return m, labels

model, labels = model_load(model_dir)

```

恭喜你训练并保存了你的第一个用于图像分类的神经网络！

## 2.5 卷积神经网络

时尚 MNIST 数据集非常适合引入神经网络，但它比许多真实世界的图像数据集更简单。该网络是在一组预处理的 28x28 单色图像上训练的，所有图像都包含应该被识别的物品——在许多现实世界的场景中，你通常不会处理这样整齐修剪的数据集。理想情况下，我们希望构建足够健壮的模型，以便在我们输入的一些图像的特征与模型被训练时的特征略有不同时也能对项目进行分类，特别是，我们希望我们的模型对修剪、旋转和少量模糊或颜色/亮度变化具有鲁棒性。

卷积神经网络(或 CNN)更接近人类大脑处理图像的方式。当他们对周围环境进行视觉分类或解释时，我们的大脑不会简单地将通过视神经传递的原始亮度和颜色信号均匀地传递到视觉皮层的所有区域。这样的组织需要大量的生物能量，因为大脑皮层的所有输入神经元一直都是活跃的，而且还需要大量的下游连接。相反，输入信号最初由视觉皮层的一个区域进行预处理，这个区域被称为*感受野*【16】【17】。感受野就像一个过滤器，对一些输入信号进行预处理。它丢弃不需要的信息；它根据例如环境亮度和方向来调整/标准化数据；最后，它识别一些*特征*或模式(由例如边缘、发光区域或空间特征确定)，这些特征或模式应该激发下游的一些特定神经元。大多数哺乳动物的感觉网络旨在检测模式并快速检测它们，专注于周围环境中最相关的元素，同时丢弃不需要的信息，并且它们被建模为在亮度、距离和方向变化的情况下也能足够稳健地工作。对灵长类动物的研究已经证明，某些感受野负责在不同的亮度和方向情况下过滤和规范感觉信号，当在不同的亮度条件下呈现给同一物体时，这些感受野向下游神经元传递的信号是相似的——换句话说，动物视觉皮层中的感受野负责*规范*数据，并确保视觉分类的过程独立于环境的亮度【18】。

![img/497180_1_En_2_Fig11_HTML.jpg](img/497180_1_En_2_Fig11_HTML.jpg)

图 2-11

卷积神经网络的典型架构。该图像显示了其卷积层(用于特征提取)、汇集层(用于降维)、展平层和下游全连接神经网络(用于分类)(鸣谢:走向数据科学[19])

CNN 可以被看作是这一原则的人工应用。在 CNN 中，一组过滤器被应用于原始图像，以便提取诸如形状和颜色区域之类的特征，并降低初始复杂度。这些特征然后被输入传统的神经网络。由于神经网络对提取的特征集而不是原始像素集进行操作，这些网络通常比相同大小但没有卷积层的等效神经网络在分类图像方面表现更好，因为它们更善于捕捉图像中区域之间的空间和时间依赖性。此外，当输入样本的大小增加时，CNN 的伸缩性更好。我们在前面的例子中设计的网络的输入单元数量与图像中的像素数量完全相同。使网络能够处理更大的图像需要缩小图像或者增加输入层中的单元数量，这反过来通常需要重新训练模型。相反，在 CNN 中，可以简单地调整卷积层/滤波器，以处理不同大小的图像，通常不需要改变下游网络的架构。卷积层的作用是降低图像的维度，以便更容易处理图像，更容易缩放模型，而不会丢失对获得良好预测至关重要的任何特征。CNN 通常由三种类型的组件组成:

![img/497180_1_En_2_Fig12_HTML.jpg](img/497180_1_En_2_Fig12_HTML.jpg)

图 2-12

原始图像上卷积层中的核张量/滤波张量的移动(来源:数据科学[19])

1.  一个或多个**卷积层**，其工作是通过称为**滤波器**或**内核**的矩阵/张量对输入图像迭代应用变换。卷积层的目的是通过不仅查看每个像素中存储的信息，而且查看每个像素与其“邻域”之间的关系(例如，它是否在边上)来捕获输入图像中的高级特征。周围的像素是否有不同程度的颜色/亮度？).随着我们添加越来越多的卷积层，所提取的特征的复杂度也在增加。第一层通常会捕获边缘、颜色渐变和方向等低级特征，而下游层会发现更复杂的特征，如对象、大小、距离等。

2.  一个或多个**池层**，其输入单元通常链接到卷积层的输出单元。他们的工作是进一步降低输入数据的维度，并选择上游卷积层提取的主要特征，特别是那些对旋转或平移等变换不变的特征——池层的目的在功能上类似于我们之前分析的主成分分析算法。

3.  最后，从原始数据中提取的特征矩阵/张量被展平，并被馈送到将执行分类过程的完全连接的神经网络中。

这种网络的最终高层架构如图 2-11 所示。下面我们来逐一分析一下它的层次。

### 2.5.1 卷积层

输入图像通常被提供为 *w* × *h* × *c* 矩阵/张量，其中 *w* 和 *h* 分别是其宽度和高度，而 *c* 是其颜色空间的深度(在单色图像的情况下为 1，在 RGB/HSV/YUV 等的情况下为 3。).一个*滤波器*或*内核*矩阵/张量 *K* 大小为*m*×*n*×*c*，其中 *m* < *h* 和 *n* < *h* ，要么在层中静态编码，要么动态计算。 *K* 在整个图像上移动，如图 2-12 所示。在每次迭代中，如果一行中有更多的像素要处理，则内核从左向右移动，否则从上到下移动(在下一行中将方向从右向左改变)，直到处理完整个图像。在每次迭代中， *K* 、 *k* 、 <sub>00</sub> 的左上元素将与输入矩阵的( *i* 、 *j* )像素 *A* 、*A*<sub>ij</sub>对齐，其中 0 ≤ *i* < *h 让我们定义*A*<sub>*ij*</sub>为 *A* 被 *K* 覆盖的子集:*

![img/497180_1_En_2_Fig13_HTML.jpg](img/497180_1_En_2_Fig13_HTML.jpg)

图 2-13

单色输入图像 *A* 和内核 *K* 之间的 2D 卷积运算的例子

![$$ {A}_{ij}=\left[\begin{array}{cccc}{a}_{ij}&amp; {a}_{\left(i+1\right)j}&amp; \dots &amp; {a}_{\left(i+m-1\right)j}\\ {}{a}_{i\left(j+1\right)}&amp; {a}_{\left(i+1\right)\left(j+1\right)}&amp; \dots &amp; {a}_{\left(i+m-1\right)\left(j+1\right)}\\ {}\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ {}{a}_{i\left(j+n-1\right)}&amp; {a}_{\left(i+1\right)\left(j+n-1\right)}&amp; \dots &amp; {a}_{\left(i+m-1\right)\left(j+n-1\right)}\end{array}\right] $$](img/497180_1_En_2_Chapter_TeX_Equac.png)

*A* <sub>*ij*</sub> 和 *K* 都是大小为*m*×*n*×*c*的张量——即使前面的公式为了简单起见将每个像素显示为单个数字，因此*A*<sub>*ij*</sub>显示为 2D 矩阵。然后，我们可以将内核覆盖的图像子集与内核本身之间的卷积运算*A*<sub>*ij*</sub>∫*K*定义为*A*<sub>*ij*</sub>和 *K* :

![$$ {A}_{ij}\ast K=\sum \limits_{x=0}^{m-1}\sum \limits_{y=0}^{n-1}\sum \limits_{z=0}^{c-1}{a}_{xyz}\ast {k}_{xyz} $$](img/497180_1_En_2_Chapter_TeX_Equad.png)

的元素之间的逐元素乘积之和

这种操作非常类似于我们在反向传播算法中看到的元素矢量积(或 *Hadamard 积*), 2D 的例子如图 2-13 所示。在 Python 中，您可以这样写:

```py
def conv_product(A, K):
    conv = 0.0
    for x in range(len(K)):
        for y in range(len(K[0])):
            for z in range(len(K[0][0])):
                conv += A[x][y][z] * K[x][y][z]

    return conv

```

应用图 2-12 :

![$$ con{v}_{ij}={A}_{ij}\ast K\ \mathrm{for}\ 0\le i&lt;w-m,0\le j&lt;h-n $$](img/497180_1_En_2_Chapter_TeX_Equae.png)

所示的“蛇形”运动，可以计算出整幅图像 *A* 与核 *K* 之间的卷积张量 *Conv*

在 Python 中:

```py
def submatrix(A, i, j, m, n):
    # Calculate the submatrix of a matrix A starting from the
    # element (i, j) up to (i+m, j+n)
    return [
        [
            A[i][j]
            for j in range(j, j+n)
        ]
        for i in range(i, i+m)
    ]

def conv(A, K):
    # The result will be a (w-m)*(h-n) matrix
    return [
        [
            conv_product(submatrix(A, i, j, len(K), len(K[0])), K)
            for j in range(len(A[0])-len(K[0])+1)
        ]
        for i in range(len(A)-len(K)+1)
    ]

```

这种内核和过滤器已经在计算机视觉中使用了很长时间。其中最流行的可以说是*索贝尔图*，或者*索贝尔-费尔德曼算子*【20】。这个滤镜实际上由两个 3 × 3 的矩阵组成， *S* <sub>*x*</sub> 和 *S* <sub>*y*</sub> ，分别用于计算 *x* 和 *y* 维度的亮度/颜色渐变的近似值:

![$$ {S}_x=\left[\begin{array}{ccc}1&amp; 0&amp; -1\\ {}2&amp; 0&amp; -2\\ {}1&amp; 0&amp; -1\end{array}\right] $$](img/497180_1_En_2_Chapter_TeX_Equaf.png)

![$$ {S}_y={S}_x^T=\left[\begin{array}{ccc}1&amp; 2&amp; 1\\ {}0&amp; 0&amp; 0\\ {}1&amp; -2&amp; -1\end{array}\right] $$](img/497180_1_En_2_Chapter_TeX_Equag.png)

这些矩阵与原始图像之间卷积运算的结果分别近似为图像在特定点周围的 *x* 和 *y* 颜色梯度:

![$$ {\displaystyle \begin{array}{r}{G}_x=A\ast {S}_x\\ {}{G}_y=A\ast {S}_y\end{array}} $$](img/497180_1_En_2_Chapter_TeX_Equah.png)

![img/497180_1_En_2_Fig14_HTML.jpg](img/497180_1_En_2_Fig14_HTML.jpg)

图 2-14

应用于图像的 Sobel 内核示例。右图像中的每个像素表示 Sobel 映射和原始图像中的相关像素之间的卷积运算的幅度。物体边缘的像素比其他像素更亮

这个向量的模表示图像中特定点的梯度向量的大小——值越高，该点越有可能属于图像中对象的边缘:

![$$ G=\sqrt{G_x²+{G}_y²} $$](img/497180_1_En_2_Chapter_TeX_Equai.png)

相反，矢量的相位确定了特定点的渐变方向——这可以用来判断物体位于边缘像素的哪一边:

![$$ \Theta =\mathrm{atan}\left(\frac{G_y}{G_x}\right) $$](img/497180_1_En_2_Chapter_TeX_Equaj.png)

卷积层中使用的核类似于 Sobel 映射(有些甚至可以使用 Sobel 映射进行边缘检测)，就像 Sobel 映射一样，它们可以用于检测图像中的边缘和梯度等特征(参见图 2-14 中的示例)。

最后，除了选择核及其大小之外，卷积层中还有两个可以调整的系数如下:

1.  *Stride* :它决定了在卷积乘积的每次迭代中，内核应该在图像上移动多少。在我们在这一段看到的例子中，内核的步幅是 1——我们在图像上一次移动一个位置——这也是最常用的值。较大的步幅将导致较小的输出张量。只要记住非常大的值有更大的机会丢弃有用的信息，就可以使用更大的步幅来执行更大的维度缩减。

2.  *Padding*: The original image can either be processed directly through the convolutional operation or padded with zeros before the operation. In this paragraph, we have shown examples of **valid padding** (or no padding)—the original matrices/tensors were not padded before applying the convolution. If instead you add two rows of zeros to the top and bottom and two columns of zeros to the left and right of the images, you will be performing what is called **same padding** . Valid padding performs dimensional reduction as well as feature extraction (the output tensor will be smaller than the input), while same padding performs feature extraction but keeps the same dimensions.

    ![img/497180_1_En_2_Fig15_HTML.jpg](img/497180_1_En_2_Fig15_HTML.jpg)

    图 2-15

    应用于输入 2D 矩阵的 2 × 2 最大和平均池操作的示例结果

因此，您可以调整*步幅*和*填充*来调整在将输出张量传递给下一层之前，该层应该减少多少输入图像的尺寸。跨距= 1 且填充相同的配置不会导致尺寸的实际减少，在这种情况下，您可能希望在下游的池层上完全执行减少。

### 2.5.2 汇集层

卷积层的输出通常连接到一个*汇集层*。汇集层的目的是减少张量的维数，同时可能不丢失正确分类所需的任何相关信息。此外，提取相对于旋转和位置不变的图像特征是有用的，这使得模型对于图像变换更加鲁棒。最后，它作为一个*降噪器*，消除或减少与周围环境太不相似的噪声像素对模型的影响。

与卷积层类似，池层通过在图像上移动一个 *m* × *n* 过滤器来工作( *m* 和 *n* 不一定要与前一层使用的内核的尺寸匹配)。不同之处在于，这一次过滤器对图像的每个 *m* × *n* 部分应用了减少/分组功能。两个池函数是最常用的:

*   *Max pooling* :选择输入张量底层子集中的最大/最高值。

*   *平均池*:选择输入张量的底层子集中的平均值。

![img/497180_1_En_2_Fig16_HTML.jpg](img/497180_1_En_2_Fig16_HTML.jpg)

图 2-16

一个全连接神经网络上的辍学迭代的例子(学分:[21])

图 2-15 显示了这两种操作的示例。Max pooling 通常比 average pooling 更受欢迎，因为它在降噪方面更有效，它只取滤波器下最高数据点的值，而丢弃其他值。

卷积层和池层的组合实际上构成了一个完整的卷积层。您可以在模型中堆叠许多这样的图层，每个图层都将检测越来越高级别的要素-但是，请记住，添加更多图层也会增加模型定型的计算需求。因此，汇集层的输出可以附加到另一个卷积层或平坦层(“将矩阵/张量展开成 1D 向量”)，该平坦层又将它馈送到完全连接的神经网络。

### 2.5.3 全连接层和漏接

CNN 的最后一部分是完全连接的神经网络，展示了与我们之前看到的相同的架构。它将从卷积层获得展平张量作为输入，并且它将在输出层中具有与我们希望模型识别的类别数量一样多的单元，每个单元的激活值表示特定图像属于特定类别的概率。

**dropout** 技术通常应用于 CNN 的全连接层，以防止过度拟合。我们已经分析了防止过拟合的几种方法(添加偏差单元、从训练集中移除冗余项、减少参数或单元的数量、调整正则化率和学习率、应用主成分分析等)。).辍学在一个稍微不同的层面上起作用。它考虑到，在具有许多神经元和相对较小的训练集的神经网络中，过度拟合主要来自于对最终分类贡献过多或过少的单个神经元，最终对模型的性能产生不利影响。在训练阶段应用参数 *p* 的丢失迭代将以概率 *p* 从网络中移除某个神经元，并触发没有这些神经元的训练迭代，如图 2-16 所示。通过这样做，我们迫使网络在不依赖单个神经元(或一组神经元)进行预测的情况下应对失败。相反，在缺少一些单元的情况下，网络将更多地依赖于层中神经元之间的*共识*。

### 2.5.4 用于识别水果图像的网络

让我们通过挑选一个比以前的时尚 MNIST 更复杂的数据集，来看一个用于图像识别的卷积神经网络的实际例子。例如，让我们选择 Kaggle [22]的 Fruits 360 数据集，但请记住，本章中报告的信息可用于在任何图像数据集上训练模型。

水果 360 数据集包含大约 90，000 个水果图像，分为 131 个类别，每个类别的大小为 100 × 100 像素。从 Kaggle 下载数据集的 zip 文件并提取它—在接下来的例子中，我将假设数据集存储在“/datasets/fruit-360”下。您会注意到数据集具有这种结构(如果数据集具有这种结构，您通常可以发现高质量的数据集):

```py
fruit-360
    \-> Training
      \-> Apple Braeburn
        \-> image01.jpg
        \-> image02.jpg
        ...
      \-> Apple Crimson Snow
        ...
    \-> Test
      \-> Apple Braeburn
        \-> image01.jpg
        \-> image02.jpg
        ...
      \-> Apple Crimson Snow
        ...

```

我们有一个用于训练图像的目录和一个用于测试图像的目录，每个目录包含一个用于每个类的目录，每个类目录包含与该类相关联的图像。这通常被认为是构建图像数据集的良好实践，它使其他开发人员和应用程序可以轻松使用它。

现在，让我们继续导入探索数据集和训练模型所需的模块:

```py
import os
import numpy as np
import matplotlib.pyplot as plt

from tensorflow.keras import Sequential, layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator

```

让我们还定义一个实用函数来从数据集中提取类名:

```py
def parse_classes(directory):
    """
    Get the classes of a dataset directory as a vector of strings.
    """
        return sorted([
            d for d in os.listdir(directory)
             if os.path.isdir(os.path.join(directory, d))
        ])

    classes = parse_classes(train_dir)

```

和一些用于定义模型的变量:

```py
train_dir = os.path.expanduser('~/datasets/fruits-360/Training')
test_dir = os.path.expanduser('~/datasets/fruits-360/Test')
img_size = (100, 100)
channels = 3     # RGB
epochs = 5       # Number of training epochs
batch_size = 64  # Batch size

```

批次大小是模型更新前处理的图像数量，可以通过调整来调整模型的性能。

对于图像识别来说，一个好的实践是在图像集上使用 TensorFlow 的`ImageDataGenerator`类。生成器将应用几个随机变换(旋转，裁剪，缩放等)。)添加到输入影像中，并生成一组新的(混洗的)影像，在对与数据集中提供的原始影像相比被旋转、剪切、模糊、翻转或缩放的影像进行分类时，这些影像可用于使您的模型更加稳健:

```py
train_generator = ImageDataGenerator(rescale=1/255,
    # Rotate the images
    rotation_range=40,
    # Cut the images
    shear_range=0.2,
    # Zoom the images
    zoom_range=0.2,
    # Flip the images
    horizontal_flip=True,
    fill_mode='nearest')

test_generator = ImageDataGenerator(rescale = 1/255)

# Output:
# Found 67692 images belonging to 131 classes.
# Found 22688 images belonging to 131 classes.

```

需要注意一些事情:

*   `rescale`操作对图像进行标准化——每个像素都有范围为[0，255]的数据，我们希望将它映射到范围[0，1]。

*   将所有花哨的变换应用于训练集是一个好主意，但测试集通常只是重新缩放。

![img/497180_1_En_2_Fig17_HTML.jpg](img/497180_1_En_2_Fig17_HTML.jpg)

图 2-17

Fruits 360 数据集的训练集图像示例

让我们来看看这些图片的样子:

```py
# Take the first batch of the training set
batch = train_data.next()
# Initialize the plot
plt.figure(figsize=(10,10))

for i in range(min(25, len(batch[0]))):
    # The first item of batch contains the raw image data
    # The second element contains the labels
    img = batch[0][i]
    label = classes[np.argmax(batch[1][i])]

    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(img, cmap=plt.cm.binary)
    plt.xlabel(label)

plt.show()

```

输出可能看起来如图 2-17 所示。

现在是最后定义和编译模型的时候了:

```py
model = Sequential([
    # First convolutional layer
    layers.Conv2D(filters=32,
        kernel_size=(3,3),
        strides=(1,1),
        padding='valid',
        activation='relu',
        input_shape=(*img_size, channels)
    ),

    # First pooling layer
    layers.MaxPooling2D(pool_size=(2,2)),

    # Second convolutional layer
    layers.Conv2D(filters=64,
        kernel_size=(3,3),
        strides=(1,1),
        padding='valid',
        activation='relu',
        input_shape=(*img_size, channels)
    ),

    # Second pooling layer
    layers.MaxPooling2D(pool_size=(2,2)),

    # Flatten output before feeding it to the network
    layers.Flatten(),

    # Neural network input layer
    layers.Dense(units=100, activation="sigmoid"),

    # Link dropout with 15% probability
    layers.Dropout(0.15),

    # Neural network hidden layer
    layers.Dense(units=200, activation="sigmoid"),

    # Link dropout with 15% probability
    layers.Dropout(0.15),

    # Neural network output layer
    layers.Dense(len(classes), activation="softmax")
])

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

```

在这些方面，我们定义了一个 CNN，它具有两对卷积/池层，连接到一个全连接神经网络，该网络具有一个输入层、一个隐藏层和一个输出层。让我们仔细看看这些层。

首先，卷积层被定义为一个`Conv2D`对象——2D，因为在这种情况下，我们正在对 2D 图像进行操作，但请记住`Conv1D`和`Conv3D`也存在。`filters`指定应用于输入的过滤器数量——模型将学习哪些过滤器从图像中提取最相关的特征。如果构建一个具有多个卷积层的模型，通常会随着网络的深入而增加过滤器的数量-第一层上的过滤器将突出显示低级特征(如边缘和亮度区域)，而下游的层将使用突出显示高级特征(如形状和边界)的过滤器。

`kernel_size`参数定义了要使用的过滤器的大小——在这种情况下，我们将使用简单的 3 × 3 内核——而`strides`定义了过滤器在每次迭代中将在图像上移动多少；我们在 x 和 y 方向上坚持一个像素。`padding`定义输入是否应该填充——同样，`valid`实际上意味着*不填充*(即执行维度缩减)，而`same`将填充输入以保持输出上的维度不变。卷积层具有激活功能，就像神经层的单元一样。`relu` ( *整流线性单元*)通常是最常用的选项:给定一个输入 *x* ，它简单地返回 max( *x* ，0)，但有时也可以使用其他激活函数。最后，我们将每个输入元素的大小指定为(*宽度*、*高度*、*通道*)。

卷积层然后连接到池层—在这种情况下，我们使用一个*最大池*层。`pool_size`参数指定输入上的池应该有多大——在这种情况下，我们使用 2 × 2 池，这意味着输入上的每个 2 × 2 像素正方形将被映射到输出上的一个元素，因此维数减少了 4 倍。然后，我们连接另一对卷积+池层，尝试从输入中提取更多的特征，然后我们将最后一个池层连接到一个`Flatten`层，该层将一个 *n* 维输入“解包”成一个一维数组，该数组可以输入到完全连接的神经网络的输入中。

然后，我们使用前一个示例中探索的结构定义完全连接的网络——输出层具有与我们想要检测的类的数量一样多的单元，同时您可以随意试验中间层和单元的数量，以查看它如何影响性能。我们还引入了两个`Dropout`层，分别位于输入层和隐藏层之间以及隐藏层和输出层之间，其*率*= 0.15——也就是说，在训练期间，与神经元的连接有 15%的可能性被切断。请记住，退出逻辑可以非常有效地防止过度拟合，并有助于使模型更加稳健，减少对单个神经元贡献的依赖，但过高的退出率将对其准确性产生不利影响，因为在训练阶段，太多的神经元将被淘汰。最后，我们使用`categorical_crossentropy`损失函数(我们希望对属于多个类别的项目进行分类)、?? 优化器以及针对`accuracy`的优化来编译模型。

现在我们已经定义了 CNN，是时候训练它并验证它了。当我们使用图像数据生成器类时，可以通过`fit_generator`方法而不是通常的`fit`将训练和验证组合在一起:

```py
history = model.fit(
    train_data,
    steps_per_epoch=train_data.samples/batch_size,
    validation_data=test_data,
    validation_steps=test_data.samples/batch_size,
    epochs=epochs
)

```

是时候去给自己泡杯咖啡或茶了——因为我们正在训练一个比我们之前在时尚 MNIST 上训练的香草神经网络有更多层和更多图像的模型，这个阶段可能需要 30 到 90 分钟才能完成，具体取决于机器的能力:

```py
Epoch 1/5
loss: 2.6444 - accuracy: 0.3622 - val_loss: 1.5080 - val_accuracy: 0.7355
Epoch 2/5
loss: 0.7892 - accuracy: 0.8084 - val_loss: 0.9297 - val_accuracy: 0.8696
Epoch 3/5
loss: 0.3591 - accuracy: 0.9142 - val_loss: 0.2119 - val_accuracy: 0.9212
Epoch 4/5
loss: 0.2093 - accuracy: 0.9474 - val_loss: 0.0216 - val_accuracy: 0.9448
Epoch 5/5
loss: 0.1590 - accuracy: 0.9570 - val_loss: 0.0087 - val_accuracy: 0.9573

```

结果精度历史如图 2-18 所示。

然后，我们可以继续分析训练时期内的精度进展。

![img/497180_1_En_2_Fig18_HTML.jpg](img/497180_1_En_2_Fig18_HTML.jpg)

图 2-18

在 5 个时期内模型精度的进步

```py
epochs = history.epoch
accuracy = history.history['accuracy']

fig = plt.figure()
plot = fig.add_subplot()
plot.set_xlabel('epoch')
plot.set_ylabel('accuracy')
plot.plot(epochs, accuracy)

```

您会注意到训练集和测试集的准确率都非常高(> 95%)，远远高于我们之前涉及简单回归或普通神经网络的示例。考虑到这一次我们有 131 个可能的输出类，这是一个相当令人印象深刻的成就，它显示了如何向神经网络添加一个或多个卷积层，并利用 dropout 等机制来防止过度拟合，可以有效地提高模型的性能。您还可以使用`evaluate`函数在测试集上评估模型的性能，就像前面的例子一样，因为它也支持生成器:

```py
model.evaluate(test_data)

```

最后，我们可以使用模型进行简单的预测，例如，我们可以从测试集中获取一些图像:

```py
test_batch = test_data.next()
test_images = test_batch[0]
test_labels = test_batch[1]

test_img = test_images[0]
expected_class = classes[np.argmax(test_labels[0])]
predicted_class = classes[np.argmax(model.predict(np.asarray([test_img])))]
print(f'Expected class: {expected_class}.\n' +
    f'Predicted class: {predicted_class}')

```

我们还可以对测试集中的一些图像运行该模型，并使用前面示例中定义的`plot_results`函数绘制它们的预期和预测类以及预测的置信水平:

```py
plot_results(
    images=test_images,
    labels=[np.argmax(label_values) for label_values in test_labels],
    classes=classes,
    predictions=predictions,
    rows=6, cols=3
)

```

你可能会看到如图 2-19 所示的图形。最后一步，不要忘记保存你的模型(使用我们在前面的例子中定义的`model_save`函数)；否则，你将不得不再次经历整个训练阶段！

现在，您应该拥有了训练图像识别神经网络的所有基本工具，我们可以将重点从如何在一些样本数据集上构建神经网络转移到如何收集图像以用于我们自己的应用程序。

![img/497180_1_En_2_Fig19_HTML.jpg](img/497180_1_En_2_Fig19_HTML.jpg)

图 2-19

针对测试集中的一些图像评估模型