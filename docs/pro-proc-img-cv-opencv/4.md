# 4.几何与变换

在本章中，您将继续处理数码图像的转换。在前一章中，您主要修改了图像的像素颜色信息，在处理中使用了内置函数和自定义函数。在这一章中，你将关注于在不改变图像内容的情况下使图像的像素网格变形。本质上，这改变了图像中每个像素的位置，从而修改了原始图像的几何形状。由于处理语言缺乏这样的功能，您将使用 OpenCV 来处理这些练习。同时，你将探索在三维特征处理中实现数字图像的几何变换。以下是本章涵盖的主题:

*   图像变换
*   图象取向
*   图像大小调整
*   仿射变换
*   透视变换
*   线性坐标与极坐标
*   三维空间
*   普通像素映射

## 图像变换

第一种类型的图像转换是翻译。在这种类型中，如图 [4-1](#Fig1) 所示，由矩形网格定义的整个数字图像在水平或垂直方向上移动。图像的大小和方向在变换前后保持不变。

![A436326_1_En_4_Fig1_HTML.jpg](A436326_1_En_4_Fig1_HTML.jpg)

图 4-1。

Image translation

本章介绍的第二种和第三种变换会改变图像的方向。它们是旋转和翻转。旋转时，图像在 2D 平面上沿假想的 z 轴旋转，没有任何尺寸变化或变形，如图 [4-2](#Fig2) 所示。在处理过程中，旋转的锚点是左上角(0，0)。

![A436326_1_En_4_Fig2_HTML.jpg](A436326_1_En_4_Fig2_HTML.jpg)

图 4-2。

Image rotation

翻转是沿着 x 轴和/或 y 轴的反射。在您将要进行的练习中，您可以在单个轴或两个轴上翻转图像。图 [4-3](#Fig3) 显示了正方形图像的垂直翻转。

![A436326_1_En_4_Fig3_HTML.jpg](A436326_1_En_4_Fig3_HTML.jpg)

图 4-3。

Image flipping

这三种类型的变换保留了原始图像的大小和形状。然而，图 [4-4](#Fig4) 所示的下一种变换将改变图像的大小。这是一个调整大小的变换。

![A436326_1_En_4_Fig4_HTML.jpg](A436326_1_En_4_Fig4_HTML.jpg)

图 4-4。

Image resize

前面介绍的四种变换保持了图像的形状。下一种类型，仿射变换，将扭曲原始形状，但它仍然保留平行线。矩形像素网格会变换成平行四边形，如图 [4-5](#Fig5) 所示。

![A436326_1_En_4_Fig5_HTML.jpg](A436326_1_En_4_Fig5_HTML.jpg)

图 4-5。

Affine transform

我要介绍的最后一种几何变换是透视变换。它将矩形图像网格转换为任意四点凸多边形。该变换还对应于透视投影，其中用附近的照相机将 3D 对象投影到 2D 平面上。图 [4-6](#Fig6) 显示了一个透视变换的例子。

![A436326_1_En_4_Fig6_HTML.jpg](A436326_1_En_4_Fig6_HTML.jpg)

图 4-6。

Perspective transform

## 图象取向

通过图像定向，我指的是诸如在二维平面中翻转和旋转图像的任务。通过使用`flip()`函数，在 OpenCV 中很容易实现翻转或反射图像。在二维图形中，您可以让沿水平轴、垂直轴或两个轴翻转。`flip()`函数的语法和参数如下:

```py
public static void flip(Mat src, Mat dst, int flipCode);

```

该命令将根据`flipCode`值中指定的内容，将`src`矩阵翻转为`dst`矩阵。`flipCode`的零值将沿 x 轴翻转，正值将沿 y 轴翻转，负值将沿两个轴翻转。下面的练习`Chapter04_01`演示了翻转在 OpenCV 处理中的使用。记住，如第 [1](1.html) 章所述，在加工草图和`CVImage`类定义中包含`code`文件夹。`code`文件夹包含所有必需的 OpenCV Java 和本地文件。处理窗口大小适合并排显示两个图像。原始图像(600×600 像素)将位于左侧，翻转后的图像将位于右侧。

```py
import org.opencv.core.*;

PImage img;
CVImage cv;

void setup() {

  size(1200, 600);

  System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
  img = loadImage("hongkong.png");
  cv = new CVImage(img.width, img.height);
  noLoop();
}

void draw() {
  background(0);
  cv.copyTo(img);
  Mat mat = cv.getBGR();
  Core.flip(mat, mat, -1);
  cv.copyTo(mat);
  image(img, 0, 0);
  image(cv, img.width, 0);
  mat.release();
}

```

程序生成的图像包含两部分，如图 [4-7](#Fig7) 所示。左边是原始图像，右边是沿两个轴翻转的图像。

![A436326_1_En_4_Fig7_HTML.jpg](A436326_1_En_4_Fig7_HTML.jpg)

图 4-7。

Transform with flip in both axes

下一个练习`Chapter04_02`，将帮助您学习图像旋转的命令。旋转图像需要遵循两个步骤。第一步是计算旋转变换矩阵。第二步是对源图像应用旋转变换矩阵。获取旋转矩阵的第一个命令的语法如下:

```py
public static Mat Imgproc.getRotationMatrix2D(Point center, double angle, double scale)

```

第一个参数`center`，是源图像中旋转中心点的坐标。第二个参数`angle`是以度为单位测量的旋转角度。请注意，处理旋转以弧度为单位，而 OpenCV 旋转以度为单位。第三个参数`scale`，是转换中应用的比例因子。该函数将输出一个 2×3 的矩阵，如下所示:

```py
 a     b     (1-a)*center.x-b*center.y
-b     a     b*center.x+(1-a)*center.y

```

这里，`a = scale*cos(angle)`和`b = scale*sin(angle)`。

一旦你有了旋转变换矩阵，你可以用`warpAffine()`函数将矩阵应用到源图像。语法如下:

```py
public static void Imgproc.warpAffine(Mat src, Mat dst, Mat m, Size dsize)

```

第一个参数`src`是源图像。第二个参数`dst`是目标图像，其类型与`src`相同，大小与第四个参数`dsize`中指定的相同。第三个参数，`m`，是从上一步获得的旋转变换矩阵。第四个参数`dsize`是目标图像的大小。同样，确保带有 OpenCV 库和`CVImage`类的`code`文件夹在加工草图文件夹中。原始图像为 600×600 像素。旋转后的图像将显示在原始图像的右侧。本练习的完整源代码`Chapter04_02`如下所示:

```py
import org.opencv.core.*;
import org.opencv.imgproc.*;

CVImage cvout;
Mat in;
PImage img;
Point ctr;
float angle;

void setup() {
  size(1200, 600);
  System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
  img = loadImage("hongkong.png");
  CVImage cvin = new CVImage(img.width, img.height);
  cvout = new CVImage(cvin.width, cvin.height);
  cvin.copyTo(img);
  in = cvin.getBGR();
  ctr = new Point(img.width/2, img.height/2);
  angle = 0;
  frameRate(30);
}

void draw() {
  background(0);
  Mat rot = Imgproc.getRotationMatrix2D(ctr, angle, 1.0);
  Mat out = new Mat(in.size(), in.type());
  Imgproc.warpAffine(in, out, rot, out.size());
  cvout.copyTo(out);
  image(img, 0, 0);
  image(cvout, img.width, 0);
  angle += 0.5;
  angle %= 360;
  out.release();
  rot.release();

}

```

在代码中，你使用`CVImage cvout`来保持旋转后的图像。`Mat in`以 OpenCV 矩阵格式保存输入图像。OpenCV 类`Point ctr`以图像的中心作为旋转的支点。`float angle`是当前旋转角度。在`draw()`功能中，每转一圈，它将增加半度。图 [4-8](#Fig8) 显示了运行草图的加工窗口示例。

![A436326_1_En_4_Fig8_HTML.jpg](A436326_1_En_4_Fig8_HTML.jpg)

图 4-8。

Rotation transform with digital image

通过使用处理`tint()`功能，您可以在旋转显示中获得更多乐趣。在使用`image()`函数之前，你可以通过指定一个小于 255 的 alpha 值来改变填充颜色的透明度，比如`tint(255, 20)`。在`draw()`功能中，如果去掉`background(0)`，增加两个`tint()`功能，就可以实现旋转图像中的运动模糊效果。新的`draw()`功能如下:

```py
void draw() {
  //  background(0);
  Mat rot = Imgproc.getRotationMatrix2D(ctr, angle, 1.0);
  Mat out = new Mat(in.size(), in.type());
  Imgproc.warpAffine(in, out, rot, out.size());
  cvout.copyTo(out);
  tint(255, 255);
  image(img, 0, 0);
  tint(255, 20);
  image(cvout, img.width, 0);
  angle += 0.5;
  angle %= 360;
  out.release();
  rot.release();
}

```

在`image(cvout, img.width, 0)`之前的`tint(255, 20)`函数将设置透明的填充颜色。在这种情况下，只有旋转图像会有运动模糊效果，而不是左侧的原始图像。图 [4-9](#Fig9) 显示了结果。

![A436326_1_En_4_Fig9_HTML.jpg](A436326_1_En_4_Fig9_HTML.jpg)

图 4-9。

Rotation transform with motion blur

## 图像大小调整

在前面的部分中，变换翻转和旋转不会改变图像的大小/面积。如果您想要更改图像大小，同时保持其形状，可以使用调整大小变换。该函数是来自 OpenCV `Imgproc`模块的`resize()`，如下图所示:

```py
public static void Imgproc.resize(Mat src, Mat dst, Size dsize)

```

第一个参数`src`是源图像。第二个参数`dst`是目标图像。第三个参数，`dsize`，是目标图像的大小。它属于 OpenCV `Size`类。下图`Chapter04_03`展示了`resize()`功能在图形合成中的使用。程序中原始图像的大小为 800×600 像素。

```py
import org.opencv.core.*;
import org.opencv.imgproc.*;

PImage img;
CVImage cv;

void setup() {
  size(1200, 600);
  System.loadLibrary(Core.NATIVE_LIBRARY_NAME);

  img = loadImage("hongkong.png");

  cv = new CVImage(img.width, img.height);
  cv.copyTo(img);
  noLoop();
}

void draw() {
  background(0);
  Mat in = cv.getBGR();
  Mat out = new Mat(new Size(img.width*0.5, img.height*0.5), in.type());
  Imgproc.resize(in, out, out.size());
  CVImage small = new CVImage(out.cols(), out.rows());
  small.copyTo(out);
  image(img, 0, 0);
  tint(255, 100, 100);
  image(small, img.width, 0);
  tint(100, 100, 255);
  image(small, img.width, small.height);
}

```

该程序创建了原始图像`img`的副本，宽度和高度都是原来的一半。较小的图像`small`在加工窗口的右侧以不同的色调显示两次，如图 [4-10](#Fig10) 所示。

![A436326_1_En_4_Fig10_HTML.jpg](A436326_1_En_4_Fig10_HTML.jpg)

图 4-10。

Resize transform with color tint

不使用 OpenCV，您也可以使用`PImage`类的`copy()`方法获得相同的结果。下一个练习，`Chapter04_04`，将展示你如何用`copy()`方法创作同样的作品。测试图像的尺寸为 800×600 像素。

```py
PImage img;

void setup() {
  size(1200, 600);
  img = loadImage("hongkong.png");
  noLoop();
}

void draw() {
  background(0);
  PImage small = createImage(round(img.width*0.5),
    round(img.height*0.5), ARGB);
  small.copy(img, 0, 0, img.width, img.height,
    0, 0, small.width, small.height);
  small.updatePixels();
  image(img, 0, 0);
  tint(255, 100, 100);
  image(small, img.width, 0);
  tint(100, 100, 255);
  image(small, img.width, small.height);

}

```

`copy()`方法将像素从原始图像`img`复制到目标图像`small`。除了源图像之外，这些参数还包括源图像和目标图像的偏移量(`x, y`)和大小(`width, height`)。

## 仿射变换

下一个几何变换是仿射变换，它可以在变换中保留平行线。要定义转换矩阵，您需要在源图像中有三个点，以及它们在目标图像中的相应位置。在下一个练习`Chapter04_05`中，您将使用图像的左上角、右上角和右下角来定义变换。假设你有原始图像，`img`。来自源图像的三个点如下:

*   `0, 0`
*   `img.width-1, 0`
*   `img.width-1, img.height-1`

仿射变换后，假设这三个点将分别移动到以下位置:

*   `50, 50`
*   `img.width-100, 100`
*   `img.width-50, img.height-100`

在这个程序中，你需要根据六个角点的映射来计算变换矩阵。使用矩阵，您可以将其应用于整个图像以创建输出图像。用于测试的图像尺寸为 600×600 像素。代码如下:

```py
import org.opencv.core.*;
import org.opencv.imgproc.*;

PImage img;
CVImage cv;

void setup() {
  size(1200, 600);
  System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
  img = loadImage("hongkong.png");
  cv = new CVImage(img.width, img.height);
  cv.copyTo(img);
  noLoop();
}

void draw() {
  background(0);

  MatOfPoint2f srcMat = new MatOfPoint2f(new Point(0, 0),
    new Point(img.width-1, 0),
    new Point(img.width-1, img.height-1));
  MatOfPoint2f dstMat = new MatOfPoint2f(new Point(50, 50),
    new Point(img.width-100, 100),
    new Point(img.width-50, img.height-100));

  Mat affine = Imgproc.getAffineTransform(srcMat, dstMat);
  Mat in = cv.getBGR();
  Mat out = new Mat(in.size(), in.type());
  Imgproc.warpAffine(in, out, affine, out.size());
  cv.copyTo(out);
  image(img, 0, 0);
  image(cv, img.width, 0);
  in.release();
  out.release();
  affine.release();
}

```

`draw()`功能有两个步骤。第一个是基于六个角点计算变换矩阵。这是通过`Imgproc.getAffineTransform()`功能完成的。

```py
public static Mat Imgproc.getAffineTransform(MatOfPoint2f src, MatOfPoint2f dst)

```

第一个参数由源图像中的三个点组成。第二个参数由目标图像中的三个对应点组成。两个参数都属于 OpenCV 类`MatOfPoint2f`。它类似于 C++中的`vector`和 Java 中的`ArrayList`。你可以把它看作是基类`Point`的有序集合。第二步是对源图像`in`应用仿射矩阵，并使用您在上一节中学习的`warpAffine()`函数生成目标矩阵`out`。图 [4-11](#Fig11) 显示了加工窗口中显示的结果图像。

![A436326_1_En_4_Fig11_HTML.jpg](A436326_1_En_4_Fig11_HTML.jpg)

图 4-11。

Affine transform

下一个练习`Chapter04_06`，是仿射变换在图像处理中更实际的应用。该计划将允许用户改变锚点，以操纵变形的程度。在源代码中，您将引入另外一个类`Corner`，来表示您可以拖动来改变转换的每个锚点。`Corner`类的定义如下:

```py
public class Corner {
  float radius;
  PVector pos;
  boolean picked;

  public Corner(float x, float y) {
    pos = new PVector(x, y);
    radius = 10.0;
    picked = false;
  }

  PVector getPos() {
    return pos;
  }

  void drag(float x, float y) {
    if (picked) {
      PVector p = new PVector(x, y);
      pos.set(p.x, p.y);
    }
  }

  void pick(float x, float y) {
    PVector p = new PVector(x, y);
    float d = p.dist(pos);
    if (d < radius) {
      picked = true;
      pos.set(p.x, p.y);
    }
  }

  void unpick() {
    picked = false;
  }

  void draw() {
    pushStyle();
    fill(255, 255, 0, 160);
    noStroke();
    ellipse(pos.x, pos.y, radius*2, radius*2);
    popStyle();
  }
}

```

该类将显示一个圆圈来指示数字图像的角。在仿射变换中，只使用三个角。在本练习中，您将使用左上角、右上角和右下角。用户可以单击并拖动来移动角点。在下一节中使用透视转换时，您将重用该类。这里显示了`Chapter04_06`的主程序:

```py
import org.opencv.core.*;
import org.opencv.imgproc.*;

PImage img;
CVImage cvout;
PVector offset;
MatOfPoint2f srcMat, dstMat;
Mat in;
Corner [] corners;

void setup() {
  size(720, 720);
  System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
  img = loadImage("hongkong.png");
  CVImage cvin = new CVImage(img.width, img.height);
  cvin.copyTo(img);
  in = cvin.getBGR();
  cvout = new CVImage(img.width, img.height);
  offset = new PVector((width-img.width)/2, (height-img.height)/2);
  srcMat = new MatOfPoint2f(new Point(0, 0),
    new Point(img.width-1, 0),
    new Point(img.width-1, img.height-1));
  dstMat = new MatOfPoint2f();
  corners = new Corner[srcMat.rows()];
  corners[0] = new Corner(0+offset.x, 0+offset.y);
  corners[1] = new Corner(img.width-1+offset.x, 0+offset.y);
  corners[2] = new Corner(img.width-1+offset.x, img.height-1+offset.y);
}

void draw() {
  background(0);
  drawFrame();
  Point [] points = new Point[corners.length];
  for (int i=0; i<corners.length; i++) {
    PVector p = corners[i].getPos();
    points[i] = new Point(p.x-offset.x, p.y-offset.y);
  }
  dstMat.fromArray(points);
  Mat affine = Imgproc.getAffineTransform(srcMat, dstMat);
  Mat out = new Mat(in.size(), in.type());
  Imgproc.warpAffine(in, out, affine, out.size());
  cvout.copyTo(out);
  image(cvout, offset.x, offset.y);
  for (Corner c : corners) {
    c.draw();
  }
  out.release();
  affine.release();
}

void

drawFrame() {
  pushStyle();
  noFill();
  stroke(100);
  line(offset.x-1, offset.y-1,
    img.width+offset.x, offset.y-1);
  line(img.width+offset.x, offset.y-1,
    img.width+offset.x, img.height+offset.y);
  line(offset.x-1, img.height+offset.y,
    img.width+offset.x, img.height+offset.y);
  line(offset.x-1, offset.y-1,
    offset.x-1, img.height+offset.y);
  popStyle();
}

void

mousePressed() {
  for (Corner c : corners) {
    c.pick(mouseX, mouseY);
  }
}

void mouseDragged() {
  for (Corner c : corners) {
    if (mouseX<offset.x ||
      mouseX>offset.x+img.width ||
      mouseY<offset.y ||
      mouseY>offset.y+img.height)
      continue;
    c.drag(mouseX, mouseY);
  }
}

void mouseReleased() {
  for (Corner c : corners) {
    c.unpick();
  }
}

```

该程序添加了鼠标事件处理程序来管理由`Corner`类定义的带有锚点的鼠标点击动作。在`draw()`函数中，使用另一种方法来初始化`dstMat`矩阵。您已经将`points`定义为一个`Point`数组。在每一帧中，将锚点信息从`corners`复制到`points`，并使用`fromArray()`方法初始化`dstMat`以进行后续处理。程序的其余部分与上一个类似。图 [4-12](#Fig12) 显示了程序的可视化显示。

![A436326_1_En_4_Fig12_HTML.jpg](A436326_1_En_4_Fig12_HTML.jpg)

图 4-12。

Interactive affine transform

## 透视变换

透视变换的用法类似于上一节中的仿射变换，只是您需要使用四个点而不是三个点来定义变换。在变换之后，它不能像在仿射变换中那样保持平行线。生成透视变换矩阵的函数如下:

```py
public static Mat Imgproc.getPerspectiveTransform(MatOfPoint2f src, MatOfPoint2f dst)

```

第一个参数`src`，是来自源图像的四个锚点的集合(`MatOfPont2f)`)。在练习中，`Chapter04_07`，你使用输入图像的四个角，`img`。它们如下:

*   `0, 0`:左上角
*   `img.width-1, 0`:右上角
*   `img.width-1, img.height-1`:右下角
*   `0, img.height-1`:左下角

第二个参数`dst`，是变换后输出图像的四个角点的集合(`MatOfPoint2f)`)。您采用上一个练习中的类`Corner`。用户可以单击/拖动角点，以交互方式更改变换矩阵。源代码和前面的差不多。您只需用透视变换替换仿射变换，并使用四个点而不是三个点。这里使用的原始图像的大小是 700×700 像素。

```py
PImage img;
CVImage cvout;
PVector offset;
MatOfPoint2f srcMat, dstMat;
Mat in;
Corner [] corners;

void
setup() {
  size(720, 720);
  System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
  img = loadImage("hongkong.png");
  CVImage cvin = new CVImage(img.width, img.height);
  cvin.copyTo(img);
  in = cvin.getBGR();
  cvout = new CVImage(img.width, img.height);
  offset = new PVector((width-img.width)/2, (height-img.height)/2);
  srcMat = new MatOfPoint2f(new Point(0, 0),
    new Point(img.width-1, 0),
    new Point(img.width-1, img.height-1),
    new Point(0, img.height-1));
  dstMat = new MatOfPoint2f();
  corners = new Corner[srcMat.rows()];
  corners[0] = new Corner(0+offset.x, 0+offset.y);
  corners[1] = new Corner(img.width-1+offset.x, 0+offset.y);
  corners[2] = new Corner(img.width-1+offset.x, img.height-1+offset.y);
  corners[3] = new Corner(0+offset.x, img.height-1+offset.y);
}

void

draw() {
  background(0);
  drawFrame();
  Point [] points = new Point[corners.length];
  for (int i=0; i<corners.length; i++) {
    PVector p = corners[i].getPos();
    points[i] = new Point(p.x-offset.x, p.y-offset.y);
  }
  dstMat.fromArray(points);
  Mat transform = Imgproc.getPerspectiveTransform(srcMat, dstMat);
  Mat out = new Mat(in.size(), in.type());
  Imgproc.warpPerspective(in, out, transform, out.size());
  cvout.copyTo(out);
  image(cvout, offset.x, offset.y);
  for (Corner c : corners) {
    c.draw();
  }
  out.release();
  transform.release();
}

void
drawFrame() {
  pushStyle();
  noFill();
  stroke(100);
  line(offset.x-1, offset.y-1,
    img.width+offset.x, offset.y-1);
  line(img.width+offset.x, offset.y-1,
    img.width+offset.x, img.height+offset.y);
  line(offset.x-1, img.height+offset.y,
    img.width+offset.x, img.height+offset.y);
  line(offset.x-1, offset.y-1,
    offset.x-1, img.height+offset.y);
  popStyle();
}

void

mousePressed() {
  for (Corner c : corners) {
    c.pick(mouseX, mouseY);
  }
}

void mouseDragged() {
  for (Corner c : corners) {
    if (mouseX<offset.x ||
      mouseX>offset.x+img.width ||
      mouseY<offset.y ||
      mouseY>offset.y+img.height)
      continue;
    c.drag(mouseX, mouseY);
  }
}

void mouseReleased() {
  for (Corner c : corners) {
    c.unpick();
  }
}

```

为了执行透视变换，你使用新的`warpPerspective()`函数和矩阵`transform`，它是从上一个`getPerspectiveTransform()`矩阵生成的，如图 [4-13](#Fig13) 所示。

![A436326_1_En_4_Fig13_HTML.jpg](A436326_1_En_4_Fig13_HTML.jpg)

图 4-13。

Perspective transform with interactivity

请注意，当用户单击/拖动角点时，您不会检查新形状是否是凸形的。当新形状不是凸形时，可能会导致图像失真。

## 线性坐标与极坐标

您使用的 x，y 坐标系统是线性的，或笛卡尔坐标。这两个轴是互相垂直的直线。除了线性坐标系，你还可以用半径和角度的测量来表示二维平面上的一个点(x，y)，如图 [4-14](#Fig14) 所示。

![A436326_1_En_4_Fig14_HTML.jpg](A436326_1_En_4_Fig14_HTML.jpg)

图 4-14。

Linear and polar coordinates

OpenCV 通过图像处理模块`Imgproc`提供了将图像从线性坐标空间转换到极坐标空间的转换函数。该功能如下所示:

```py
public static void Imgproc.linearPolar(Mat src, Mat dst, Point center, double maxRadius, int flags)

```

第一个参数`src`是源图像。第二个参数`dst`是目标图像，其大小和类型与源图像相同。第三个参数，`center`，是转换中心。你通常把它设置在图像的中心。第四个参数`maxRadius`是要变换的边界圆的半径。第五个参数`flags`，是插值方法的组合。使用双线性插值`INTER_LINEAR`，填充所有目标像素`WARP_FILL_OUTLIERS`。在演示练习`Chapter04_08`中，您将使用实时网络摄像头作为输入图像，并并排显示源图像和转换后的图像。

```py
import processing.video.*;
import org.opencv.core.*;
import org.opencv.imgproc.*;

Capture cap;
CVImage img, out;
int capW, capH;

void setup() {
  size(1280, 480);
  System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
  capW = width/2;
  capH = height;
  cap = new Capture(this, capW, capH);
  cap.start();
  img = new CVImage(cap.width, cap.height);
  out = new CVImage(cap.width, cap.height);
}

void draw() {
  if (!cap.available())
    return;
  background(0);
  cap.read();
  img.copyTo(cap);
  Mat linear = img.getBGR();
  Mat polar = new Mat();
  Point ctr = new Point(cap.width/2, cap.height/2);
  double radius = min(cap.width, cap.height)/2.0;
  Imgproc.linearPolar(linear, polar, ctr, radius,
    Imgproc.INTER_LINEAR+Imgproc.WARP_FILL_OUTLIERS);
  out.copyTo(polar);
  image(cap, 0, 0);
  image(out, cap.width, 0);
  linear.release();
  polar.release();
}

```

在本练习中，您将半径设置为视频图像高度的一半。图 [4-15](#Fig15) 显示了加工窗口图像。

![A436326_1_En_4_Fig15_HTML.jpg](A436326_1_En_4_Fig15_HTML.jpg)

图 4-15。

Linear to polar transform

OpenCV 还提供了另一种极坐标变换，`logPolar()`。它类似于`linearPolar()`函数，只是它使用距离的自然对数。以下练习`Chapter04_09`展示了如何使用`logPolar()`功能处理网络摄像头图像:

```py
import processing.video.*;
import org.opencv.core.*;
import org.opencv.imgproc.*;

Capture cap;
CVImage img, out;
int capW, capH;

void setup() {
  size(1280, 480);
  System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
  capW = width/2;
  capH = height;
  cap = new Capture(this, capW, capH);
  cap.start();
  img = new CVImage(cap.width, cap.height);
  out = new CVImage(cap.width, cap.height);
}

void
draw() {
  if (!cap.available())
    return;
  background(0);
  cap.read();
  img.copyTo(cap);
  Mat linear = img.getBGR();
  Mat polar = new Mat();
  Point ctr = new Point(cap.width/2, cap.height/2);
  double radius = (double)min(cap.width, cap.height)/2.0;
  double m = (double)cap.width/log((float)radius);
  Imgproc.logPolar(linear, polar, ctr, m,
    Imgproc.INTER_LINEAR+Imgproc.WARP_FILL_OUTLIERS);
  out.copyTo(polar);
  image(cap, 0, 0);
  image(out, cap.width, 0);
  linear.release();
  polar.release();
}

```

该功能声称模仿人类的“视网膜中央凹”视觉，看起来更“自然”图 [4-16](#Fig16) 显示了结果图像。

![A436326_1_En_4_Fig16_HTML.jpg](A436326_1_En_4_Fig16_HTML.jpg)

图 4-16。

Linear to log polar transform

## 三维空间

除了使用 OpenCV 中的图像处理模块，您还可以使用处理中的 3D 图形功能来转换图像。在本书的大部分练习中，您使用`image()`函数直接在屏幕上显示`PImage`对象实例。在处理过程中，还有其他方式来显示图像。下面的练习`Chapter04_10`演示了如何使用`PShape`类( [`https://processing.org/reference/PShape.html`](https://processing.org/reference/PShape.html) )和`PImage`类作为贴图纹理。这个练习由两幅图像组成。第一个是来自一个`PImage`实例的背景图像。第二个是来自`Capture`实例的前景图像。3D 空间中的旋转模拟透视变换。

```py
import processing.video.*;

Capture cap;
PImage img;
PShape canvas;
int capW, capH;
float angle;

void setup() {
  size(800, 600, P3D);
  hint(DISABLE_DEPTH_TEST);
  capW = 640;
  capH = 480;
  cap = new Capture(this, capW, capH);
  cap.start();
  img = loadImage("hongkong.png");
  canvas = createShape(RECT, 0, 0, cap.width, cap.height);
  canvas.setStroke(false);
  canvas.setTexture(cap);
  shapeMode(CENTER);
  angle = 0;
}

void draw() {
  if (!cap.available())
    return;
  cap.read();
  background(0);
  image(img, 0, 0);
  translate(width/2, height/2, -100);
  rotateX(radians(angle));
  shape(canvas, 0, 0);
  angle += 0.5;
  angle %= 360;
}

```

程序的第一个变化是`size()`功能。它有一个额外的参数`P3D`，表示您现在处于 3D 显示模式。高级用户可以使用 OpenGL 提示功能来控制渲染参数( [`https://processing.org/tutorials/rendering/`](https://processing.org/tutorials/rendering/) )。您在这里使用的`hint()`函数有一个参数来禁用渲染中的深度测试，这样前面的表面就不会遮挡后面的表面。在`setup()`函数中，您用下面的函数定义了`PShape`实例`canvas`:

```py
createShape(RECT, 0, 0, cap.width, cap.height);

```

这将创建一个矩形形状`RECT`，左上角为(0，0)，宽度和高度等于网络摄像头捕捉的宽度和高度。下一条语句禁用描边颜色。您还可以使用`canvas.setTexture(cap)`将来自网络摄像头的`PImage cap`关联为形状的纹理`canvas`。在`draw()`功能中，首先将背景清除为黑色，然后在加工窗口上直接显示背景图像`img`。`translate()`功能将图形移动到屏幕中心，在 z 方向也是负值。`rotateX()`功能将图形沿 X 轴旋转`angle`中指定的量。请注意，旋转以弧度为度量单位。如果使用的是度，则需要使用`radians()`功能进行转换。最后一步是使用`shape()`函数在中心(0，0)显示`PShape`实例`canvas`。还要注意，在`setup()`函数中，您将`shapeMode`设置为`CENTER`，而不是左上角。示例显示将类似于图 [4-17](#Fig17) 所示。

![A436326_1_En_4_Fig17_HTML.jpg](A436326_1_En_4_Fig17_HTML.jpg)

图 4-17。

Perspective transform in Processing by rotation

在上一个练习中，您使用内置矩形形状来定义形状。事实上，你可以定义你自己的顶点。下面的练习`Chapter04_11`，将使用一系列`vertex()`命令定义相同的图形。之后，您可以检索单个顶点并改变其位置，以实现更动态的动画。

```py
import processing.video.*;

Capture cap;
PImage img;
PShape canvas;
int capW, capH;
float angle;
int vCnt;

void setup() {
  size(800, 600, P3D);
  hint(DISABLE_DEPTH_TEST);
  capW = 640;
  capH = 480;
  cap = new Capture(this, capW, capH);
  cap.start();
  img = loadImage("hongkong.png");
  canvas = createShape();
  canvas.beginShape();
  canvas.textureMode(NORMAL);
  canvas.texture(cap);
  canvas.noStroke();
  canvas.vertex(0, 0, 0, 0, 0);
  canvas.vertex(cap.width, 0, 0, 1, 0);
  canvas.vertex(cap.width, cap.height, 0, 1, 1);
  canvas.vertex(0, cap.height, 0, 0, 1);
  canvas.endShape(CLOSE);
  shapeMode(CENTER);
  angle = 0;
  vCnt = canvas.getVertexCount();
}

void draw() {
  if (!cap.available())
    return;
  cap.read();
  background(0);
  image(img, 0, 0);
  for (int i=0; i<vCnt; i++) {
    PVector pos = canvas.getVertex(i);
    if (i < 2) {
      pos.z = 100*cos(radians(angle*3));
    } else {
      pos.z = 100*sin(radians(angle*5));
    }
    canvas.setVertex(i, pos);
  }
  translate(width/2, height/2, -100);
  rotateY(radians(angle));
  shape(canvas, 0, 0);
  angle += 0.5;
  angle %= 360;
}

```

图 [4-18](#Fig18) 显示了结果。

![A436326_1_En_4_Fig18_HTML.jpg](A436326_1_En_4_Fig18_HTML.jpg)

图 4-18。

Perspective transform with custom shape

前面的练习仅使用矩形的四个角来指定矩形。图像没有失真太多。如果使用线框栅格作为纹理贴图的骨架，可以修改每个点以进一步扭曲图像。图 [4-19](#Fig19) 显示了网格和映射在其上的图像。

![A436326_1_En_4_Fig19_HTML.jpg](A436326_1_En_4_Fig19_HTML.jpg)

图 4-19。

Image text-mapped on a grid

要在处理中定义网格，您可以使用`QUAD_STRIP`形状。首先，为整个网格定义一个`GROUP`形状。第二，将网格的每一行创建为一个`QUAD_STRIP`形状。要在`QUAD_STRIP`中创建一个单元格，您必须按以下顺序定义点:左上、左下、右上和右下。第三，将每一行作为子对象添加到`GROUP`形状中。图 [4-20](#Fig20) 说明了该形状的详细配置。

![A436326_1_En_4_Fig20_HTML.jpg](A436326_1_En_4_Fig20_HTML.jpg)

图 4-20。

A GROUP shape with QUAD_STRIP as children

下一个练习`Chapter04_12`，展示了如何使用一个叫做`canvas`的`GROUP PShape`来定义详细纹理映射的网格:

```py
import processing.video.*;

Capture cap;
PShape canvas;
int capW, capH;
float step;

void setup() {
  size(800, 600, P3D);
  hint(DISABLE_DEPTH_TEST);
  capW = 640;
  capH = 480;
  step = 40;
  cap = new Capture(this, capW, capH);
  cap.start();
  initShape();
  shapeMode(CENTER);
}

void initShape() {
  // initialize the GROUP PShape grid
  canvas = createShape(GROUP);
  int nRows = floor(cap.height/step) + 1;
  int nCols = floor(cap.width/step) + 1;
  for (int y=0; y<nRows-1; y++) {
    // initialize each row of the grid
    PShape tmp = createShape();
    tmp.beginShape(QUAD_STRIP);
    tmp.texture(cap);
    for (int x=0; x<nCols; x++) {
      // initialize the top-left, bottom-left points
      int x1 = (int)constrain(x*step, 0, cap.width-1);
      int y1 = (int)constrain(y*step, 0, cap.height-1);
      int y2 = (int)constrain((y+1)*step, 0, cap.height-1);
      tmp.vertex(x1, y1, 0, x1, y1);
      tmp.vertex(x1, y2, 0, x1, y2);
    }
    tmp.endShape();
    canvas.addChild(tmp);
  }
}

void draw() {
  if (!cap.available())
    return;
  cap.read();
  background(100);
  translate(width/2, height/2, -80);
  rotateX(radians(20));
  shape(canvas, 0, 0);
}

```

难的部分在`initShape()`函数中完成。首先将整个网格的`PShape`定义为

```py
canvas = createShape(GROUP)

```

然后遍历网格中的每个单元格。请注意，您需要通过将总行数`nRows`和总列数`nCols`加 1 来处理右边距和下边距。对于每一行，您将临时变量`tmp`定义为一个`QUAD_STRIP`形状。创建完`QUAD_STRIP`中的所有顶点后，使用`canvas.addChild(tmp)`将其添加到`canvas`形状中。现在，您可以将视频捕获图像作为纹理映射到网格上。然而，你不会就此止步。您的目的是改变顶点在屏幕上的 z 位置，这样您就可以获得视频捕获的失真图像。

下一个练习`Chapter04_13`，将在网格中维护一个二维的顶点数组。此外，您将为每个顶点设置一个随机的初始 z 位置。

```py
import processing.video.*;

Capture cap;
PShape canvas;
int capW, capH;
float step;
PVector [][] points;
float angle;

void setup() {
  size(800, 600, P3D);
  hint(DISABLE_DEPTH_TEST);
  capW = 640;
  capH = 480;
  step = 20;
  cap = new Capture(this, capW, capH);
  cap.start();
  initGrid();
  initShape();
  shapeMode(CENTER);
  angle = 0;
}

void initGrid() {
  // initialize the matrix of points for texture mapping
  points = new PVector[floor(cap.height/step)+1][floor(cap.width/step)+1];
  for (int y=0; y<points.length; y++) {
    for (int x=0; x<points[y].length; x++) {
      float xVal = constrain(x*step, 0, cap.width-1);
      float yVal = constrain(y*step, 0, cap.height-1);
      // random z value
      points[y][x] = new PVector(xVal, yVal, noise(x*0.2, y*0.2)*60-30);
    }
  }
}

void initShape() {
  // initialize the GROUP PShape grid
  canvas = createShape(GROUP);
  for (int y=0; y<points.length-1; y++) {
    // initialize each row of the grid
    PShape tmp = createShape();
    tmp.beginShape(QUAD_STRIP);
    tmp.noStroke();
    tmp.texture(cap);
    for (int x=0; x<points[y].length; x++) {
      PVector p1 = points[y][x];
      PVector p2 = points[y+1][x];
      tmp.vertex(p1.x, p1.y, p1.z, p1.x, p1.y);
      tmp.vertex(p2.x, p2.y, p2.z, p2.x, p2.y);
    }
    tmp.endShape();
    canvas.addChild(tmp);
  }
}

void draw() {
  if (!cap.available())
    return;
  cap.read();
  lights();
  background(100);
  translate(width/2, height/2, -100);
  rotateX(radians(angle*1.3));
  rotateY(radians(angle));
  shape(canvas, 0, 0);
  angle += 0.5;
  angle %= 360;
}

```

被称为`points`的`PVector`的 2D 数组维护网格的所有顶点。函数`initGrid()`初始化位置信息。对于 z 位置，您使用 Perlin 噪声函数来初始化它。`initShape()`函数将复制`points`数组中的信息，用适当的纹理映射创建`GROUP PShape`、`canvas`。请注意，您还可以使用`lights()`功能来启用`draw()`功能中的默认照明条件。生成的图像(如图 [4-21](#Fig21) 所示)将类似于 3D 地形，网络摄像头图像映射在其上。

![A436326_1_En_4_Fig21_HTML.jpg](A436326_1_En_4_Fig21_HTML.jpg)

图 4-21。

Texture map with irregular surface

在上一个练习中，请注意栅格中的顶点没有移动。它们在`setup()`函数中创建一次，没有任何进一步的改变。在下一个练习`Chapter04_14`中，您将尝试根据网络摄像头图像制作顶点动画，以便获得交互式观看体验。不是为每个顶点的 z 位置输入一个随机数，而是通过使用来自网络摄像头的颜色信息来改变它的值。在加工中，默认的颜色模式是`RGB`。但是，如果您想要明确使用亮度信息，可以将其切换到 HSB(色调、饱和度、亮度)。在本练习中，您的目标是用该像素的亮度信息交换顶点的 z 位置。可以使用的功能是`brightness()`。

```py
import processing.video.*;

Capture cap;
int capW, capH;
float step;
PVector [][] points;
float angle;
PShape canvas;

void setup() {
  size(800, 600, P3D);
  hint(DISABLE_DEPTH_TEST);
  capW = 640;
  capH = 480;
  step = 10;
  cap = new Capture(this, capW, capH);
  cap.start();
  initGrid();
  initShape();
  shapeMode(CENTER);
  angle = 0;
}

void initGrid() {
  // initialize the matrix of points for texture mapping
  points = new PVector[floor(cap.height/step)+1][floor(cap.width/step)+1];
  for (int y=0; y<points.length; y++) {
    for (int x=0; x<points[y].length; x++) {
      float xVal = constrain(x*step, 0, cap.width-1);
      float yVal = constrain(y*step, 0, cap.height-1);
      points[y][x] = new PVector(xVal, yVal, 0);
    }
  }
}

void initShape() {
  canvas = createShape(GROUP);
  for (int y=0; y<points.length-1; y++) {
    // initialize each row of the grid
    PShape tmp = createShape();
    tmp.beginShape(QUAD_STRIP);
    tmp.noFill();
    for (int x=0; x<points[y].length; x++) {
      PVector p1 = points[y][x];
      PVector p2 = points[y+1][x];
      tmp.vertex(p1.x, p1.y, p1.z);
      tmp.vertex(p2.x, p2.y, p2.z);
    }
    tmp.endShape();
    canvas.addChild(tmp);
  }
}

color getColor(int x, int y) {
  // obtain color information from cap
  int x1 = constrain(floor(x*step), 0, cap.width-1);
  int y1 = constrain(floor(y*step), 0, cap.height-1);
  return cap.get(x1, y1);
}

void updatePoints() {
  // update the depth of vertices using color
  // brightness from cap
  float factor = 0.3;
  for (int y=0; y<points.length; y++) {
    for (int x=0; x<points[y].length; x++) {
      color c = getColor(x, y);
      points[y][x].z = brightness(c)*factor;
    }
  }
}

void updateShape() {
  // update the color and depth of vertices
  for (int i=0; i<canvas.getChildCount(); i++) {
    for (int j=0; j<canvas.getChild(i).getVertexCount(); j++) {
      PVector p = canvas.getChild(i).getVertex(j);
      int x = constrain(floor(p.x/step), 0, points[0].length-1);
      int y = constrain(floor(p.y/step), 0, points.length-1);
      p.z = points[y][x].z;
      color c = getColor(x, y);
      canvas.getChild(i).setStroke(j, c);
      canvas.getChild(i).setVertex(j, p);
    }
  }
}

void draw() {
  if (!cap.available())
    return;
  cap.read();
  updatePoints();
  updateShape();
  background(0);
  translate(width/2, height/2, -100);
  rotateX(radians(angle));
  shape(canvas, 0, 0);
  angle += 0.5;
  angle %= 360;
}

```

`initGrid()`函数初始化点数组。`initShape()`函数使用来自点数组的信息来初始化`PShape canvas`。在该函数中，您不需要直接在每个`QUAD_STRIP`子节点中设置纹理。您可以启用描边颜色，但禁用子形状的填充颜色。在`draw()`函数中，你编写了`updatePoints()`函数来根据颜色亮度更新顶点的 z 位置。`updateShape()`函数遍历`PShape canvas`的所有子节点，并更新顶点的 z 位置和笔画颜色。图 [4-22](#Fig22) 显示了显示窗口的示例。

![A436326_1_En_4_Fig22_HTML.jpg](A436326_1_En_4_Fig22_HTML.jpg)

图 4-22。

3D effect using brightness as depth

请注意，在图像中，颜色较深的区域看起来较深，而较亮的区域在网格平面中较高。如果将`initShape()`函数中的`tmp.noFill()`语句改为`tmp.noStroke()`，将`updateShape()`函数中的`canvas.getChild(i).setStroke(j, c)`语句改为`canvas.getChild(i).setFill(j, c)`，就可以将线框显示切换为实心版本，如图 [4-23](#Fig23) 所示。

![A436326_1_En_4_Fig23_HTML.jpg](A436326_1_En_4_Fig23_HTML.jpg)

图 4-23。

3D effect with brightness as depth

## 普通像素映射

除了 Processing 和 OpenCV 中用于图像转换的内置函数之外，您还可以通过从源图像到目标图像的逐像素映射来编写通用图像转换算法。在本章的最后一个练习`Chapter04_15`中，您将尝试将第一幅图像`img1`中的单个像素复制到第二幅图像`img2`中。该变换将基于正弦和余弦函数产生的谐波运动。这里使用的图像大小为 600×600 像素。

```py
PImage img1, img2;
float angle;

void setup() {
  size(1200, 600);
  img1 = loadImage("hongkong.png");
  img2 = createImage(img1.width, img1.height, ARGB);
  angle = 0;
}

void draw() {
  // Variables rx, ry are for the radii of the sine/cosine functions
  // Variables ax, ay are for the angles of the sine/cosine functions
  background(0);
  for (int y=0; y<img2.height; y++) {
    float ay = y*angle/img2.height;
    float ry = y*angle/360.0;
    for (int x=0; x<img2.width; x++) {
      float ax = x*angle/img2.width;
      float rx = x*angle/360.0;
      int x1 = x + (int)(rx*cos(radians(ay)));
      int y1 = y + (int)(ry*sin(radians(ax)));
      x1 = constrain(x1, 0, img1.width-1);
      y1 = constrain(y1, 0, img1.height-1);
      img2.pixels[y*img2.width+x] = img1.pixels[y1*img1.width+x1];
    }
  }
  angle += 1;
  angle %= 360;
  img2.updatePixels();
  image(img1, 0, 0);
  image(img2, img1.width, 0);
}

```

第一个图像`img1`是源图像。第二个图像`img2`，与`img1`大小相同。在`draw()`函数的嵌套`for`循环中，你从相反的方向穿过目标图像中的每个像素`img2`。对于每个像素，您可以从源图像中找到应该将哪个像素复制到目标图像中。对于源像素，采用正弦和余弦函数，变量影响半径和角度。总体结果是一个扭曲效果作用于源图像的动画，如图 [4-24](#Fig24) 所示。图 [4-24](#Fig24) 和图 [4-25](#Fig25) 显示了不同时间点的两个样本显示。

![A436326_1_En_4_Fig25_HTML.jpg](A436326_1_En_4_Fig25_HTML.jpg)

图 4-25。

General mapping of pixels sample 2

![A436326_1_En_4_Fig24_HTML.jpg](A436326_1_En_4_Fig24_HTML.jpg)

图 4-24。

General mapping of pixels sample 1

这是你从动画中捕捉到的第二个瞬间(图 [4-25](#Fig25) )。

从目标图像返回到源图像的原因是不要让任何目标像素为空。这是开发像素映射转换时的常见做法。

## 结论

本章描述了通过改变像素位置从而改变几何图形来修改图像的步骤。Processing 和 OpenCV 都具有几何变换功能。为了简化编码任务，您可以根据应用程序需求选择使用哪一个。或者，您可以通过指定目标图像中的所有像素以及它们在源图像中的来源来编写自己的图像转换函数。到目前为止，您只为创造性结果修改了图像。你还没有尝试去理解这些图像。在下一章，你将开始理解图像中的内容。