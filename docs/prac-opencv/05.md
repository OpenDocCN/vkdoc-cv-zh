# 五、过滤图像

Abstract

在本章中，我们将继续讨论对图像的基本操作。特别是，我们将讨论一些滤波器理论和不同种类的滤波器，您可以将它们应用于图像，以便提取各种信息或抑制各种噪声。

在本章中，我们将继续讨论对图像的基本操作。特别是，我们将讨论一些滤波器理论和不同种类的滤波器，您可以将它们应用于图像，以便提取各种信息或抑制各种噪声。

图像处理和计算机视觉之间只有一线之隔。图像处理主要处理通过以各种方式变换图像来获得图像的不同表示。通常(但不总是)这样做是为了“查看”,例如更改图像的色彩空间、锐化或模糊图像、更改对比度、仿射变换、裁剪、调整大小等等。相比之下，计算机视觉关注的是从图像中提取信息，以便人们做出决策。通常，必须从有噪声的图像中提取信息，因此还必须分析噪声，并想办法抑制噪声，同时不会过多影响图像的相关信息内容。

举个例子，一个问题是你必须制造一个简单的轮式自动机器人，它可以向一个方向移动，跟踪并拦截一个红色的球。

这里的计算机视觉问题是双重的:查看从机器人上的摄像头获取的图像中是否有一个红球，如果有，知道它沿着机器人的运动方向相对于机器人的位置。请注意，这两个都是决定性的信息，基于这些信息，机器人可以决定是否移动，如果是，向哪个方向移动。

滤镜是最基本的操作，您可以对图像执行这些操作来提取信息。(它们可能极其复杂。但是我们将从简单的开始。)为了让您对本章的内容有一个大致的了解，我们将首先从一些图像滤镜理论开始，然后研究一些简单的滤镜。在许多计算机视觉流水线中，应用这些过滤器可以作为有用的预处理或后处理步骤。这些操作包括:

*   模糊
*   上下调整图像大小
*   侵蚀和扩张
*   检测边缘和拐角

然后，我们将讨论如何有效地检查图像中像素值的界限。利用这一新发现的知识，我们将制作第一个非常简单的 objector 探测器应用。接下来将讨论打开和关闭的图像形态学操作，这是从图像中消除噪声的有用工具(我们将通过向我们的 object detector 应用添加打开和关闭步骤来消除噪声来演示这一点)。

## 图像过滤器

滤波器只不过是一个函数，它获取信号的局部值，并给出以某种方式与信号中包含的信息成比例的输出。通常，一个“滑动”滤波器通过信号。为了明确这两个重要的陈述，考虑下面的一维时变信号，它可以是一个城市每天的温度(或类似的东西)。

我们想要提取的信息是温度波动；具体来说，我们想看看每天的气温变化有多剧烈。所以我们做了一个过滤函数，它给出了今天的温度和昨天的温度之差的绝对值。我们遵循的等式是 y[n]= | x[n]—x[n 1]|，其中 y[n]是第 n 天的滤波器输出，x[n]是信号，即第 n 天的城市温度。

这个滤波器(长度为 2)在信号中“滑动”，输出类似于图 [5-1](#Fig1) 。

![A978-1-4302-6080-6_5_Fig1_HTML.jpg](A978-1-4302-6080-6_5_Fig1_HTML.jpg)

图 5-1。

A simple signal (above) and output of a differential filter on that signal (below)

正如您所观察到的，滤波器增强了信号的差异。简单地说，如果今天的温度与昨天有很大不同，那么今天的过滤器输出将会更高。如果今天的温度和昨天差不多，那么今天的滤波器输出几乎为零。希望这个非常简单的例子能让您相信，滤波器设计基本上就是计算出一个函数，它将接收信号值，并增强其中所选的信息内容。还有一些其他的条件和规则需要注意，但是对于我们简单的应用，我们可以忽略它们。

现在让我们继续讨论图像滤波器，它与我们之前讨论的 1-D 滤波器有些不同，因为图像信号是 2-D 的，因此滤波器也必须是 2-D 的(如果我们想考虑所有四边的像素邻居)。检测图像中垂直边缘的示例过滤器将帮助您更好地理解。第一步是确定滤波器矩阵。筛选器矩阵是筛选器函数的离散化版本，使在计算机上应用筛选器成为可能。它们的长度和宽度通常是奇数，因此可以明确地确定中心元素。对于我们检测垂直边缘的情况，矩阵非常简单:

`0 0 0`

`-1 2 -1`

`0 0 0`

或者如果我们想考虑两个相邻的像素:

`0 0 0 0 0`

`0 0 0 0 0`

`-1 -2 6 -2 -1`

`0 0 0 0 0`

`0 0 0 0 0`

现在，让我们滑动这个过滤器通过一个图像，看看它是否工作！在此之前，我必须详细说明什么是“应用”一个过滤器矩阵(或内核)的图像意味着什么。内核放在图像上，通常从图像的左上角开始。每次迭代都会执行以下步骤:

*   在内核的元素和由内核覆盖的图像的像素之间执行逐元素乘法
*   函数用于使用所有这些元素乘法的结果来计算一个数字。这个函数可以是总和、平均值、最小值、最大值或者非常复杂的东西。如此计算的值被称为图像在该迭代中对滤波器的“响应”
*   位于内核中心元素下方的像素采用响应值
*   内核向右移动，必要时向下移动

用这个过滤器矩阵(也称为内核)过滤一个仅由水平和垂直边缘组成的图像，得到如图 [5-2](#Fig2) 所示的过滤图像。

![A978-1-4302-6080-6_5_Fig2_HTML.jpg](A978-1-4302-6080-6_5_Fig2_HTML.jpg)

图 5-2。

A simple image with horizontal and vertical edges (left) and output of filtering with kernel (right)

OpenCV 有一个名为`filter2D()`的函数，我们可以使用它进行高效的基于内核的过滤。要了解如何使用它，请研究前面讨论的用于过滤的代码，并阅读它的文档。这个函数非常强大，因为它允许您通过指定的任何内核过滤图像。清单 5-1 展示了这个函数的使用。

清单 5-1。程序应用一个简单的过滤器矩阵来检测图像的水平边缘

`// Program to apply a simple filter matrix to an image`

`// Author: Samarth Manoj Brahmbhatt, University of Pennsylvania`

`#include <opencv2/opencv.hpp>`

`#include <opencv2/highgui/highgui.hpp>`

`using namespace std;`

`using namespace cv;`

`int main() {`

`Mat img = imread("image.jpg", CV_LOAD_IMAGE_GRAYSCALE), img_filtered;`

`// Filter kernel for detecting vertical edges`

`float vertical_fk[5][5] = {{0,0,0,0,0}, {0,0,0,0,0}, {-1,-2,6,-2,-1}, {0,0,0,0,0}, {0,0,0,0,0}};`

`// Filter kernel for detecting horizontal edges`

`float horizontal_fk[5][5] = {{0,0,-1,0,0}, {0,0,-2,0,0}, {0,0,6,0,0}, {0,0,-2,0,0}, {0,0,-1,0,0}};`

`Mat filter_kernel = Mat(5, 5, CV_32FC1, horizontal_fk);`

`// Apply filter`

`filter2D(img, img_filtered, -1, filter_kernel);`

`namedWindow("Image");`

`namedWindow("Filtered image");`

`imshow("Image", img);`

`imshow("Filtered image", img_filtered);`

`// imwrite("filtered_image.jpg", img_filtered);`

`while(char(waitKey(1)) != 'q') {}`

`return 0;`

`}`

您可能已经猜到，检测垂直边缘的内核是:

`0 0 -1 0 0`

`0 0 -2 0 0`

`0 0 6 0 0`

`0 0 -2 0 0`

`0 0 -1 0 0`

它可以很好地检测垂直边缘，如图 [5-3](#Fig3) 所示。

![A978-1-4302-6080-6_5_Fig3_HTML.jpg](A978-1-4302-6080-6_5_Fig3_HTML.jpg)

图 5-3。

Detecting vertical edges in an image

尝试制作不同的检测器内核和实验各种图像是很有趣的！

如果您给多通道彩色图像作为`filter2D()`的输入，它将相同的内核矩阵应用于所有通道。有时，您可能希望只检测某个通道中的边缘，或者对不同的通道使用不同的核，并选择最强的边缘(或平均边缘强度)。在这种情况下，您应该使用`split()`函数分割图像，并分别应用内核。

不要忘记查看 OpenCV 文档中所有你正在学习的新函数！

因为边缘检测是计算机视觉中非常重要的操作，所以已经进行了大量的研究来设计可以在任意方向检测边缘的方法和智能滤波器矩阵。OpenCV 提供了其中一些算法的实现，在这一章的后面我会有更多的介绍。同时，让我们坚持我们的章节计划，讨论第一个图像预处理步骤，模糊。

### 模糊图像

模糊图像是在不改变图像外观的情况下缩小图像尺寸的第一步。模糊可以被认为是低通滤波操作，并使用简单直观的核矩阵来完成。可以认为一幅图像沿其两个轴的方向都有不同的“频率成分”。边缘具有高频率，而缓慢变化的强度值具有低频率。更具体地说，垂直边缘沿着图像的水平轴产生高频分量，反之亦然。精细纹理区域也具有高频率(请注意，如果一个区域中的像素强度值在短像素距离内变化很大，则该区域称为精细纹理区域)。较小的图像不能很好地处理高频。

可以这样想:假设你有一张纹理清晰的 640 x 480 的图片。您无法在 320 x 240 的图像中保持所有这些短时间间隔的高强度像素值变化，因为它只有像素数量的四分之一。所以无论何时你想缩小一幅图像的尺寸，你都应该从中去除高频成分。换句话说，模糊它。平滑掉那些高量级的短间隔变化。如果在调整大小之前没有模糊，您可能会在调整大小后的图像中看到伪像。原因很简单，取决于信号理论的一个基本定理，即采样一个信号会导致该信号的频域出现无限重复。因此，如果信号有许多高频成分，重复频域表示的边缘会相互干扰。一旦发生这种情况，信号就无法准确恢复。这里，信号是我们的图像，调整大小是通过移除行和列来完成的，也就是下采样。这种现象被称为混叠。如果你想了解更多，你应该能够在任何好的数字信号处理资源中找到详细的解释。因为模糊去除了图像中的高频成分，所以有助于避免混叠。

当您想要增加图像的大小时，模糊也是一个重要的后处理步骤。如果您想要将图像的大小增加一倍，可以为每一行(列)添加一个空白行(列)，然后模糊生成的图像，使空白行(列)的外观与相邻行(列)相似。

模糊可以通过用图像周围区域中像素的某种平均值替换图像中的每个像素来实现。为了有效地做到这一点，该区域保持矩形并围绕像素对称，并且图像与“归一化”核进行卷积(归一化是因为我们想要平均值，而不是总和)。一个非常简单的内核是箱式内核:

`1 1 1 1 1`

`1 1 1 1 1`

`1 1 1 1 1`

`1 1 1 1 1`

`1 1 1 1 1`

这个内核认为每个像素都同等重要。一个更好的核应该是随着像素与中心像素的距离的增加而减少像素的影响。高斯核可以做到这一点，并且是最常用的模糊核:

`1 4 6 4 1`

`4 16 24 16 4`

`6 24 36 24 6`

`4 16 24 16 4`

`1 4 6 4 1`

一种方法是通过除以所有元素的总和来“归一化”核，25 用于盒核，256 用于高斯核。您可以使用 OpenCV 函数`getGaussianKernel()`创建不同大小的高斯内核。查看这个函数的文档，了解 OpenCV 用来计算内核的公式。您可以将这些内核插入到清单 5-1 中，以模糊一些图像(不要忘记将内核除以其元素的总和)。然而，OpenCV 也提供了更高级的函数`GaussianBlur()`,它只是将高斯函数的核大小和方差作为输入，并为我们完成所有其他工作。我们在清单 5-2 的代码中使用了这个函数，它用一个滑块指示大小的高斯核来模糊一个图像。它应该有助于你实际理解模糊。图 [5-4](#Fig4) 显示了运行中的代码。

清单 5-2。使用不同大小的高斯核交互式模糊图像的程序

`// Program to interactively blur an image using a Gaussian kernel of varying size`

`// Author: Samarth Manoj Brahmbhatt, University of Pennyslvania`

`#include <opencv2/opencv.hpp>`

`#include <opencv2/highgui/highgui.hpp>`

`#include <opencv2/imgproc/imgproc.hpp>`

`using namespace std;`

`using namespace cv;`

`Mat image, image_blurred;`

`int slider = 5;`

`float sigma = 0.3 * ((slider - 1) * 0.5 - 1) + 0.8;`

`void on_trackbar(int, void *) {`

`int k_size = max(1, slider);`

`k_size = k_size % 2 == 0 ? k_size + 1 : k_size;`

`setTrackbarPos("Kernel Size", "Blurred image", k_size);`

`sigma = 0.3 * ((k_size - 1) * 0.5 - 1) + 0.8;`

`GaussianBlur(image, image_blurred, Size(k_size, k_size), sigma);`

`imshow("Blurred image", image_blurred);`

`}`

`int main() {`

`image = imread("baboon.jpg");`

`namedWindow("Original image");`

`namedWindow("Blurred image");`

`imshow("Original image", image);`

`sigma = 0.3 * ((slider - 1) * 0.5 - 1) + 0.8;`

`GaussianBlur(image, image_blurred, Size(slider, slider), sigma);`

`imshow("Blurred image", image_blurred);`

`createTrackbar("Kernel Size", "Blurred image", &slider, 21, on_trackbar);`

`while(char(waitKey(1) != 'q')) {}`

`return 0;`

`}`

![A978-1-4302-6080-6_5_Fig4_HTML.jpg](A978-1-4302-6080-6_5_Fig4_HTML.jpg)

图 5-4。

Blurring an image with a Gaussian kernel

请注意我们使用的基于内核大小计算方差的启发式公式，以及使用`setTrackbarPos()`函数强制内核大小为奇数且大于 0 的工具栏“锁定”机制。

### 上下调整图像大小

现在我们知道了在调整图像大小时模糊图像的重要性，我们准备好调整图像大小并验证我所阐述的理论是否正确。

你可以通过使用如图 [5-5](#Fig5) 所示的`resize()`函数来做一个简单的几何尺寸调整(简单地抛出行和列)。

![A978-1-4302-6080-6_5_Fig5a_HTML.jpg](A978-1-4302-6080-6_5_Fig5a_HTML.jpg) ![A978-1-4302-6080-6_5_Fig5b_HTML.jpg](A978-1-4302-6080-6_5_Fig5b_HTML.jpg)

图 5-5。

Aliasing artifacts—simple geometric resizing of an image down by a factor of 4

观察由于混叠而在调整大小的图像中产生的伪像。`pyrDown()`函数通过高斯核模糊图像，并将其缩小 2 倍。图 [5-6](#Fig6) 中的图像是原始图像的四倍缩小版，通过使用两次`pyrDown()`获得(注意没有混叠伪影)。

![A978-1-4302-6080-6_5_Fig6_HTML.jpg](A978-1-4302-6080-6_5_Fig6_HTML.jpg)

图 5-6。

Avoiding aliasing while resizing images by first blurring them with a Gaussian kernel

如果你想放大一幅图像，函数`resize()`也是有效的，它采用了一系列你可以选择的插值技术。如果您想在放大后模糊图像，请使用`pyrUp()`功能适当的次数(因为它的工作系数是 2)。

### 侵蚀和扩张图像

腐蚀和膨胀是图像的两种基本形态学操作。顾名思义，形态学运算作用于图像的形式和结构。

侵蚀是通过在图像上滑动所有 1 的矩形核(盒核)来完成的。响应被定义为内核元素和属于内核的像素之间的所有元素乘法的最大值。因为所有的核元素都是一，所以应用这个核意味着用围绕像素的矩形区域中的最小值替换每个像素值。您可以想象这将导致图像中的黑色区域“侵占”到白色区域(因为白色的像素值高于黑色)。

放大图像是相同的，唯一的区别是响应被定义为元素方式乘法的最大值而不是最小值。这将导致白色区域侵占黑色区域。

内核的大小决定了腐蚀或膨胀的程度。清单 5-3 制作了一个在腐蚀和膨胀之间切换的应用，并允许您选择内核的大小(在形态学操作的上下文中也称为结构化元素)。

清单 5-3。检查图像腐蚀和膨胀的程序

`// Program to examine erosion and dilation of images`

`// Author: Samarth Manoj Brahmbhatt, University of Pennyslvania`

`#include <opencv2/opencv.hpp>`

`#include <opencv2/highgui/highgui.hpp>`

`#include <opencv2/imgproc/imgproc.hpp>`

`using namespace std;`

`using namespace cv;`

`Mat image, image_processed;`

`int choice_slider = 0, size_slider = 5; // 0 - erode, 1 - dilate`

`void process() {`

`Mat st_elem = getStructuringElement(MORPH_RECT, Size(size_slider, size_slider));`

`if(choice_slider == 0) {`

`erode(image, image_processed, st_elem);`

`}`

`else {`

`dilate(image, image_processed, st_elem);`

`}`

`imshow("Processed image", image_processed);`

`}`

`void on_choice_slider(int, void *) {`

`process();`

`}`

`void on_size_slider(int, void *) {`

`int size = max(1, size_slider);`

`size = size % 2 == 0 ? size + 1 : size;`

`setTrackbarPos("Kernel Size", "Processed image", size);`

`process();`

`}`

`int main() {`

`image = imread("j.png");`

`namedWindow("Original image");`

`namedWindow("Processed image");`

`imshow("Original image", image);`

`Mat st_elem = getStructuringElement(MORPH_RECT, Size(size_slider, size_slider));`

`erode(image, image_processed, st_elem);`

`imshow("Processed image", image_processed);`

`createTrackbar("Erode/Dilate", "Processed image", &choice_slider, 1, on_choice_slider);`

`createTrackbar("Kernel Size", "Processed image", &size_slider, 21, on_size_slider);`

`while(char(waitKey(1) != 'q')) {}`

`return 0;`

`}`

图 [5-7](#Fig7) 显示了用户使用滑块指定的不同侵蚀和放大量的图像。

![A978-1-4302-6080-6_5_Fig7_HTML.jpg](A978-1-4302-6080-6_5_Fig7_HTML.jpg)

图 5-7。

Eroding and dilating images

除了函数`erode()`和`dilate()`之外，这段代码中值得注意的是函数`getStructuralElement()` `,`，它返回指定形状和大小的结构元素(核矩阵)。预定义的形状包括矩形、椭圆形和十字形。您甚至可以创建自定义形状。所有这些形状都嵌入在一个由零组成的矩形矩阵中返回(属于该形状的元素是 1)。

### 有效检测图像中的边缘和角点

您之前已经看到，使用滤波器可以很容易地检测出垂直和水平边缘。如果你构建了一个合适的内核，你可以检测任何方向的边缘，只要它是一个固定的方向。然而，在实践中，人们必须在同一图像中检测所有方向的边缘。我们将讨论一些智能的方法来做到这一点。也可以通过使用适当种类的核来检测角点。

### 优势

边缘是图像中图像梯度非常高的点。我们所说的梯度是指像素强度值的变化。通过计算 X 和 Y 方向上的梯度，然后使用毕达哥拉斯定理将它们结合，来计算图像的梯度。虽然通常不需要，但是您可以通过分别取 Y 和 X 方向的梯度比的反正切来计算梯度的角度。

x 和 Y 方向梯度分别通过用以下核卷积图像来计算:

`-3 0 3`

`-10 0 10`

`-3 0 3 (for X direction)`

和

`-3 -10 -3`

`0 0 0`

`3 10 3 (for Y direction)`

整体梯度，G = sqrt(Gx <sup>2</sup> + Gy <sup>2</sup>

倾斜角，ф=反正切(Gy / Gx)

上面显示的两个内核被称为 Scharr 操作符，OpenCV 提供了一个名为 Scharr()的函数，它将指定大小和指定方向(X 或 Y)的 Scharr 操作符应用于图像。所以让我们制作如清单 5-4 所示的 Scharr 边缘检测程序。

清单 5-4。使用 Scharr 算子检测图像边缘的程序

`// Program to detect edges in an image using the Scharr operator`

`// Author: Samarth Manoj Brahmbhatt, University of Pennyslvania`

`#include <opencv2/opencv.hpp>`

`#include <opencv2/highgui/highgui.hpp>`

`#include <opencv2/imgproc/imgproc.hpp>`

`using namespace std;`

`using namespace cv;`

`int main() {`

`Mat image = imread("lena.jpg"), image_blurred;`

`// Blur image with a Gaussian kernel to remove edge noise`

`GaussianBlur(image, image_blurred, Size(3, 3), 0, 0);`

`// Convert to gray`

`Mat image_gray;`

`cvtColor(image_blurred, image_gray, CV_RGB2GRAY);`

`// Gradients in X and Y directions`

`Mat grad_x, grad_y;`

`Scharr(image_gray, grad_x, CV_32F, 1, 0);`

`Scharr(image_gray, grad_y, CV_32F, 0, 1);`

`// Calculate overall gradient`

`pow(grad_x, 2, grad_x);`

`pow(grad_y, 2, grad_y);`

`Mat grad = grad_x + grad_y;`

`sqrt(grad, grad);`

`// Display`

`namedWindow("Original image");`

`namedWindow("Scharr edges");`

`// Convert to 8 bit depth for displaying`

`Mat edges;`

`grad.convertTo(edges, CV_8U);`

`imshow("Original image", image);`

`imshow("Scharr edges", edges);`

`while(char(waitKey(1)) != 'q') {}`

`return 0;`

`}`

图 [5-8](#Fig8) 显示了美丽的莉娜图像的沙尔边缘。

![A978-1-4302-6080-6_5_Fig8_HTML.jpg](A978-1-4302-6080-6_5_Fig8_HTML.jpg)

图 5-8。

Scharr edge detector

您可以看到 Scharr 操作符像承诺的那样找到了梯度。然而，在边缘图像中有许多噪声。因为边缘图像具有 8 位深度，所以您可以用 0 到 255 之间的一个数字对其进行阈值处理，以消除噪声。像往常一样，你可以制作一个带有滑块的应用。该应用的代码如清单 5-5 所示，不同阈值的阈值 Scharr 输出如图 [5-9](#Fig9) 所示。

清单 5-5。使用阈值 Scharr 算子检测图像边缘的程序

`// Program to detect edges in an image using the thresholded Scharr operator`

`// Author: Samarth Manoj Brahmbhatt, University of Pennyslvania`

`#include <opencv2/opencv.hpp>`

`#include <opencv2/highgui/highgui.hpp>`

`#include <opencv2/imgproc/imgproc.hpp>`

`using namespace std;`

`using namespace cv;`

`Mat edges, edges_thresholded;`

`int slider = 50;`

`void on_slider(int, void *) {`

`if(!edges.empty()) {`

`Mat edges_thresholded;`

`threshold(edges, edges_thresholded, slider, 255, THRESH_TOZERO);`

`imshow("Thresholded Scharr edges", edges_thresholded);`

`}`

`}`

`int main() {`

`//Mat image = imread("lena.jpg"), image_blurred;`

`Mat image = imread("lena.jpg"), image_blurred;`

`// Blur image with a Gaussian kernel to remove edge noise`

`GaussianBlur(image, image_blurred, Size(3, 3), 0, 0);`

`// Convert to gray`

`Mat image_gray;`

`cvtColor(image_blurred, image_gray, CV_BGR2GRAY);`

`// Gradients in X and Y directions`

`Mat grad_x, grad_y;`

`Scharr(image_gray, grad_x, CV_32F, 1, 0);`

`Scharr(image_gray, grad_y, CV_32F, 0, 1);`

`// Calculate overall gradient`

`pow(grad_x, 2, grad_x);`

`pow(grad_y, 2, grad_y);`

`Mat grad = grad_x + grad_y;`

`sqrt(grad, grad);`

`// Display`

`namedWindow("Original image");`

`namedWindow("Thresholded Scharr edges");`

`// Convert to 8 bit depth for displaying`

`grad.convertTo(edges, CV_8U);`

`threshold(edges, edges_thresholded, slider, 255, THRESH_TOZERO);`

`imshow("Original image", image);`

`imshow("Thresholded Scharr edges", edges_thresholded);`

`createTrackbar("Threshold", "Thresholded Scharr edges", &slider, 255, on_slider);`

`while(char(waitKey(1)) != 'q') {}`

`return 0;`

`}`

![A978-1-4302-6080-6_5_Fig9a_HTML.jpg](A978-1-4302-6080-6_5_Fig9a_HTML.jpg) ![A978-1-4302-6080-6_5_Fig9b_HTML.jpg](A978-1-4302-6080-6_5_Fig9b_HTML.jpg)

图 5-9。

Scharr edge detector with thresholds of 100 (top) and 200 (bottom)

### 锐利的边缘

Canny 算法使用一些后处理来清理边缘输出，并给出细而锐利的边缘。计算 Canny 边缘的步骤包括:

*   通过用大小为 5 的归一化高斯核卷积图像来去除边缘噪声
*   使用两种不同的内核计算 X 和 Y 梯度:

`-1 0 1`

`-2 0 2`

`-1 0 1 for X direction and`

`-1 -2 -1`

`0 0 0`

`1 2 1 for Y direction`

*   如前所述，通过毕达哥拉斯定理找到总梯度强度，通过反正切找到梯度角度。角度四舍五入为四个选项:0 度、45 度、90 度和 135 度
*   非最大抑制:只有当像素的梯度幅度大于其在梯度方向上的相邻像素的梯度幅度时，该像素才被视为在边缘上。这产生了尖锐而薄的边缘
*   滞后阈值:这个过程使用两个阈值。如果像素的梯度幅度高于上阈值，则该像素被接受为边缘，如果其梯度幅度低于下阈值，则该像素被拒绝。如果梯度幅度在两个阈值之间，则只有当它连接到作为边缘的像素时，它才会被接受为边缘

你可以在 Lena 图片上运行 OpenCV Canny edge 演示，看看 Canny 和 Scharr edges 的区别。图 [5-10](#Fig10) 显示了从相同的 Lena 照片中提取的 Canny 边缘。

![A978-1-4302-6080-6_5_Fig10_HTML.jpg](A978-1-4302-6080-6_5_Fig10_HTML.jpg)

图 5-10。

Canny edge detector

### 困境

OpenCV 函数`goodFeaturesToTrack()`实现了一个鲁棒的角点检测器。该算法采用了史和托马西提出的兴趣点检测算法。关于这个函数内部工作的更多信息可以在 [`http://docs.opencv.org/modules/imgproc/doc/feature_detection.html?highlight=goodfeaturestotrack#goodfeaturestotrack`](http://docs.opencv.org/modules/imgproc/doc/feature_detection.html?highlight=goodfeaturestotrack#goodfeaturestotrack) 的文档页面中找到。

该函数接受以下输入:

*   灰度图像
*   一个点 2d 的 STL 向量，用来存储角点的位置(稍后会详细介绍 STL 向量)
*   要返回的最大拐角数。如果算法检测到的角多于这个数量，则只返回最强的适当数量的角
*   质量水平:拐角的最低可接受质量。拐角的质量被定义为在一个像素处的图像强度梯度矩阵的最小特征值，或者(如果使用哈里斯边角侦测)图像在该像素处对哈里斯函数的响应。有关更多详细信息，请阅读`cornerHarris()`和`cornerMinEigenVal()`的文档
*   两个返回角点位置之间的最小欧几里德距离
*   一个标志，指示是使用哈里斯边角侦测还是最小特征值角检测器(默认为最小特征值)
*   如果使用哈里斯边角侦测，调整哈里斯检测器的参数(关于该参数的用法，参见`cornerHarris()`的文档)

STL 是标准模板库的缩写，它提供了非常有用的数据结构，可以模板化成任何数据类型。其中一个数据结构是`vector`，我们将使用 OpenCV 的`Point2d`的`vector`来存储角的位置。您可能还记得，`Point2d`是 OpenCV 存储一对整数值(通常是图像中一个点的位置)的方式。清单 5-6 显示了使用`goodFeaturesToTrack()`函数从图像中提取角点的代码，允许用户决定角点的最大数量。

清单 5-6。检测图像中的角点的程序

`// Program to detect corners in an image`

`// Author: Samarth Manoj Brahmbhatt, University of Pennyslvania`

`#include <opencv2/opencv.hpp>`

`#include <opencv2/highgui/highgui.hpp>`

`#include <opencv2/imgproc/imgproc.hpp>`

`#include <stdlib.h>`

`using namespace std;`

`using namespace cv;`

`Mat image, image_gray;`

`int max_corners = 20;`

`void on_slider(int, void *) {`

`if(image_gray.empty()) return;`

`max_corners = max(1, max_corners);`

`setTrackbarPos("Max no. of corners", "Corners", max_corners);`

`float quality = 0.01;`

`int min_distance = 10;`

`vector<Point2d> corners;`

`goodFeaturesToTrack(image_gray, corners, max_corners, quality, min_distance);`

`// Draw the corners as little circles`

`Mat image_corners = image.clone();`

`for(int i = 0; i < corners.size(); i++) {`

`circle(image_corners, corners[i], 4, CV_RGB(255, 0, 0), -1);`

`}`

`imshow("Corners", image_corners);`

`}`

`int main() {`

`image = imread("building.jpg");`

`cvtColor(image, image_gray, CV_RGB2GRAY);`

`namedWindow("Corners");`

`on_slider(0, 0);`

`createTrackbar("Max. no. of corners", "Corners", &max_corners, 250, on_slider);`

`while(char(waitKey(1)) != 'q') {}`

`return 0;`

`}`

在这个应用中，我们通过一个滑块来改变可返回拐角的最大数量。观察我们如何使用`circle()`函数在角的位置绘制红色填充的小圆圈。app 产生的输出如图 [5-11](#Fig11) 所示。

![A978-1-4302-6080-6_5_Fig11a_HTML.jpg](A978-1-4302-6080-6_5_Fig11a_HTML.jpg) ![A978-1-4302-6080-6_5_Fig11b_HTML.jpg](A978-1-4302-6080-6_5_Fig11b_HTML.jpg)

图 5-11。

Corners at different values of `max_corners`

## 物体探测器应用

我们的第一个对象检测程序将只使用颜色信息。事实上，它更像是一个颜色边界检查程序，而不是严格意义上的对象检测器，因为它不涉及机器学习。这个想法是为了解决我们在本章开始时讨论的问题——找出一个红色球的大致位置，并控制一个简单的轮式机器人拦截它。检测红球最简单的方法是查看图像中像素的 RGB 值是否与红球相对应，这就是我们将要开始的。我们也将在下一章继续学习新技术的同时努力改进这个应用。如果你已经解决了上一章的练习题，你就已经知道使用哪个 OpenCV 函数了。下面是清单 5-7，这是我们在目标检测方面的第一次尝试！

清单 5-7。简单的基于颜色的对象检测器

`// Program to display a video from attached default camera device and detect colored blobs using simple // R G and B thresholding`

`// Author: Samarth Manoj Brahmbhatt, University of Pennsylvania`

`#include <opencv2/opencv.hpp>`

`#include <opencv2/highgui/highgui.hpp>`

`#include <opencv2/imgproc/imgproc.hpp>`

`using namespace cv;`

`using namespace std;`

`Mat frame, frame_thresholded;`

`int rgb_slider = 0, low_slider = 30, high_slider = 100;`

`int low_r = 30, low_g = 30, low_b = 30, high_r = 100, high_g = 100, high_b = 100;`

`void on_rgb_trackbar(int, void *) {`

`switch(rgb_slider) {`

`case 0:`

`setTrackbarPos("Low threshold", "Segmentation", low_r);`

`setTrackbarPos("High threshold", "Segmentation", high_r);`

`break;`

`case 1:`

`setTrackbarPos("Low threshold", "Segmentation", low_g);`

`setTrackbarPos("High threshold", "Segmentation", high_g);`

`break;`

`case 2:`

`setTrackbarPos("Low threshold", "Segmentation", low_b);`

`setTrackbarPos("High threshold", "Segmentation", high_b);`

`break;`

`}`

`}`

`void on_low_thresh_trackbar(int, void *) {`

`switch(rgb_slider) {`

`case 0:`

`low_r = min(high_slider - 1, low_slider);`

`setTrackbarPos("Low threshold", "Segmentation", low_r);`

`break;`

`case 1:`

`low_g = min(high_slider - 1, low_slider);`

`setTrackbarPos("Low threshold", "Segmentation", low_g);`

`break;`

`case 2:`

`low_b = min(high_slider - 1, low_slider);`

`setTrackbarPos("Low threshold", "Segmentation", low_b);`

`break;`

`}`

`}`

`void on_high_thresh_trackbar(int, void *) {`

`switch(rgb_slider) {`

`case 0:`

`high_r = max(low_slider + 1, high_slider);`

`setTrackbarPos("High threshold", "Segmentation", high_r);`

`break;`

`case 1:`

`high_g = max(low_slider + 1, high_slider);`

`setTrackbarPos("High threshold", "Segmentation", high_g);`

`break;`

`case 2:`

`high_b = max(low_slider + 1, high_slider);`

`setTrackbarPos("High threshold", "Segmentation", high_b);`

`break;`

`}`

`}`

`int main()`

`{`

`// Create a VideoCapture object to read from video file`

`// 0 is the ID of the built-in laptop camera, change if you want to use other camera`

`VideoCapture cap(0);`

`//check if the file was opened properly`

`if(!cap.isOpened())`

`{`

`cout << "Capture could not be opened succesfully" << endl;`

`return -1;`

`}`

`namedWindow("Video");`

`namedWindow("Segmentation");`

`createTrackbar("0\. R\n1\. G\n2.B", "Segmentation", &rgb_slider, 2, on_rgb_trackbar);`

`createTrackbar("Low threshold", "Segmentation", &low_slider, 255, on_low_thresh_trackbar);`

`createTrackbar("High threshold", "Segmentation", &high_slider, 255, on_high_thresh_trackbar);`

`while(char(waitKey(1)) != 'q' && cap.isOpened())`

`{`

`cap >> frame;`

`// Check if the video is over`

`if(frame.empty())`

`{`

`cout << "Video over" << endl;`

`break;`

`}`

`inRange(frame, Scalar(low_b, low_g, low_r), Scalar(high_b, high_g, high_r), frame_thresholded);`

`imshow("Video", frame);`

`imshow("Segmentation", frame_thresholded);`

`}`

`return 0;`

`}`

图 [5-12](#Fig12) 显示程序检测一个橙色物体。

![A978-1-4302-6080-6_5_Fig12_HTML.jpg](A978-1-4302-6080-6_5_Fig12_HTML.jpg)

图 5-12。

Color-based object detector

观察我们如何使用锁定机制来确保较低的阈值永远不会高于较高的阈值，反之亦然。要使用此应用，首先将物体放在相机前。然后，将鼠标悬停在名为“视频”的窗口中的对象上，观察 R、G 和 B 值。最后，在“分段”窗口中适当调整范围。这个应用有很多缺点:

*   它不能检测多种颜色的物体
*   它高度依赖于照明
*   它会对相同颜色的其他物体产生误报

但这是一个好的开始！

## 形态学打开和关闭图像以去除噪声

回想一下形态学腐蚀和膨胀的定义。开口是通过腐蚀图像，然后放大图像而获得的。它将具有移除图像中的小白色区域的效果。闭合是通过扩张图像然后腐蚀它来实现的；这将产生相反的效果。这两种操作经常用于从图像中去除噪声。打开会移除白色的小像素，而关闭会移除黑色的小“洞”我们的 object detector 应用是检查这一点的理想平台，因为我们在“分割”窗口中有一些白点和黑点形式的噪声，如图 [5-12](#Fig12) 所示。

OpenCV 函数`morphologyEX()`可用于执行高级形态学操作，如打开和关闭图像。因此，我们可以通过在前面的对象检测器代码的`main()`函数的`while`循环中添加三行来打开和关闭`inRange()`函数的输出，以移除黑点和白点。新的`main()`函数如清单 5-8 所示。

清单 5-8。向对象检测器代码添加打开和关闭步骤

`int main()`

`{`

`// Create a VideoCapture object to read from video file`

`// 0 is the ID of the built-in laptop camera, change if you want to use other camera`

`VideoCapture cap(0);`

`//check if the file was opened properly`

`if(!cap.isOpened())`

`{`

`cout << "Capture could not be opened succesfully" << endl;`

`return -1;`

`}`

`namedWindow("Video");`

`namedWindow("Segmentation");`

`createTrackbar("0\. R\n1\. G\n2.B", "Segmentation", &rgb_slider, 2, on_rgb_trackbar);`

`createTrackbar("Low threshold", "Segmentation", &low_slider, 255, on_low_thresh_trackbar);`

`createTrackbar("High threshold", "Segmentation", &high_slider, 255, on_high_thresh_trackbar);`

`while(char(waitKey(1)) != 'q' && cap.isOpened())`

`{`

`cap >> frame;`

`// Check if the video is over`

`if(frame.empty())`

`{`

`cout << "Video over" << endl;`

`break;`

`}`

`inRange(frame, Scalar(low_b, low_g, low_r), Scalar(high_b, high_g, high_r), frame_thresholded);`

`Mat str_el = getStructuringElement(MORPH_RECT, Size(3, 3));`

`morphologyEx(frame_thresholded, frame_thresholded, MORPH_OPEN, str_el);`

`morphologyEx(frame_thresholded, frame_thresholded, MORPH_CLOSE, str_el);`

`imshow("Video", frame);`

`imshow("Segmentation", frame_thresholded);`

`}`

`return 0;`

`}`

图 [5-13](#Fig13) 显示打开和关闭色彩绑定检查器输出确实可以去除斑点和孔洞。

![A978-1-4302-6080-6_5_Fig13_HTML.jpg](A978-1-4302-6080-6_5_Fig13_HTML.jpg)

图 5-13。

Removing small patches of noisy pixels by opening and closing

## 摘要

图像滤波是所有计算机视觉操作的基础。在抽象的意义上，应用于图像的每一种算法都可以被认为是一种过滤操作，因为您试图从图像中包含的大量不同种类的信息中提取一些相关的信息。在这一章中，你学习了很多基于过滤器的图像操作，这将有助于你开始许多复杂的计算机视觉项目。记住，只有当你从图像中提取出决定性的信息时，计算机视觉才是完整的。你还开发了简单的基于颜色的物体探测器应用，我们将在下一章继续。

本章讨论了许多低级算法，而下一章将更多地关注处理图像中区域的形式和结构的算法。